{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/re-inventing-encoding-techniques?scriptVersionId=136718792\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"651ece14","metadata":{"papermill":{"duration":0.011835,"end_time":"2023-07-14T03:17:53.85006","exception":false,"start_time":"2023-07-14T03:17:53.838225","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FFA500; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FFA500\">One Hot Encoder </p>\n","\n","<div style=\"border-radius:10px; border:#FFA500 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","So what is this One Hot Encoder...?\n","\n","Many a times we find data with non-numerical columns, which needs to be turned into Numerical Columns. we cannot feed str columns to mathematical models. THis is where the Enocding Techniques comes into play\n"]},{"cell_type":"markdown","id":"215390a6","metadata":{"papermill":{"duration":0.008654,"end_time":"2023-07-14T03:17:53.867708","exception":false,"start_time":"2023-07-14T03:17:53.859054","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#00FFFF; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #00FFFF\">1 | Intution + Build ðŸ§°</p>\n","\n","<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets assume we have a data like this "]},{"cell_type":"code","execution_count":1,"id":"1b9a811b","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-14T03:17:53.887335Z","iopub.status.busy":"2023-07-14T03:17:53.886622Z","iopub.status.idle":"2023-07-14T03:17:53.898293Z","shell.execute_reply":"2023-07-14T03:17:53.897223Z"},"papermill":{"duration":0.024548,"end_time":"2023-07-14T03:17:53.901072","exception":false,"start_time":"2023-07-14T03:17:53.876524","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/playground-series-s3e19/sample_submission.csv\n","/kaggle/input/playground-series-s3e19/train.csv\n","/kaggle/input/playground-series-s3e19/test.csv\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":2,"id":"b5407100","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-14T03:17:53.921059Z","iopub.status.busy":"2023-07-14T03:17:53.920451Z","iopub.status.idle":"2023-07-14T03:17:54.219495Z","shell.execute_reply":"2023-07-14T03:17:54.218234Z"},"papermill":{"duration":0.312246,"end_time":"2023-07-14T03:17:54.222417","exception":false,"start_time":"2023-07-14T03:17:53.910171","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>country</th>\n","      <th>store</th>\n","      <th>product</th>\n","      <th>num_sold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2017-01-01</td>\n","      <td>Argentina</td>\n","      <td>Kaggle Learn</td>\n","      <td>Using LLMs to Improve Your Coding</td>\n","      <td>63</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2017-01-01</td>\n","      <td>Argentina</td>\n","      <td>Kaggle Learn</td>\n","      <td>Using LLMs to Train More LLMs</td>\n","      <td>66</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2017-01-01</td>\n","      <td>Argentina</td>\n","      <td>Kaggle Learn</td>\n","      <td>Using LLMs to Win Friends and Influence People</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2017-01-01</td>\n","      <td>Argentina</td>\n","      <td>Kaggle Learn</td>\n","      <td>Using LLMs to Win More Kaggle Competitions</td>\n","      <td>59</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2017-01-01</td>\n","      <td>Argentina</td>\n","      <td>Kaggle Learn</td>\n","      <td>Using LLMs to Write Better</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>136945</th>\n","      <td>136945</td>\n","      <td>2021-12-31</td>\n","      <td>Spain</td>\n","      <td>Kagglazon</td>\n","      <td>Using LLMs to Improve Your Coding</td>\n","      <td>700</td>\n","    </tr>\n","    <tr>\n","      <th>136946</th>\n","      <td>136946</td>\n","      <td>2021-12-31</td>\n","      <td>Spain</td>\n","      <td>Kagglazon</td>\n","      <td>Using LLMs to Train More LLMs</td>\n","      <td>752</td>\n","    </tr>\n","    <tr>\n","      <th>136947</th>\n","      <td>136947</td>\n","      <td>2021-12-31</td>\n","      <td>Spain</td>\n","      <td>Kagglazon</td>\n","      <td>Using LLMs to Win Friends and Influence People</td>\n","      <td>111</td>\n","    </tr>\n","    <tr>\n","      <th>136948</th>\n","      <td>136948</td>\n","      <td>2021-12-31</td>\n","      <td>Spain</td>\n","      <td>Kagglazon</td>\n","      <td>Using LLMs to Win More Kaggle Competitions</td>\n","      <td>641</td>\n","    </tr>\n","    <tr>\n","      <th>136949</th>\n","      <td>136949</td>\n","      <td>2021-12-31</td>\n","      <td>Spain</td>\n","      <td>Kagglazon</td>\n","      <td>Using LLMs to Write Better</td>\n","      <td>539</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>136950 rows Ã— 6 columns</p>\n","</div>"],"text/plain":["            id        date    country         store  \\\n","0            0  2017-01-01  Argentina  Kaggle Learn   \n","1            1  2017-01-01  Argentina  Kaggle Learn   \n","2            2  2017-01-01  Argentina  Kaggle Learn   \n","3            3  2017-01-01  Argentina  Kaggle Learn   \n","4            4  2017-01-01  Argentina  Kaggle Learn   \n","...        ...         ...        ...           ...   \n","136945  136945  2021-12-31      Spain     Kagglazon   \n","136946  136946  2021-12-31      Spain     Kagglazon   \n","136947  136947  2021-12-31      Spain     Kagglazon   \n","136948  136948  2021-12-31      Spain     Kagglazon   \n","136949  136949  2021-12-31      Spain     Kagglazon   \n","\n","                                               product  num_sold  \n","0                    Using LLMs to Improve Your Coding        63  \n","1                        Using LLMs to Train More LLMs        66  \n","2       Using LLMs to Win Friends and Influence People         9  \n","3           Using LLMs to Win More Kaggle Competitions        59  \n","4                           Using LLMs to Write Better        49  \n","...                                                ...       ...  \n","136945               Using LLMs to Improve Your Coding       700  \n","136946                   Using LLMs to Train More LLMs       752  \n","136947  Using LLMs to Win Friends and Influence People       111  \n","136948      Using LLMs to Win More Kaggle Competitions       641  \n","136949                      Using LLMs to Write Better       539  \n","\n","[136950 rows x 6 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv(\"/kaggle/input/playground-series-s3e19/train.csv\")\n","\n","data"]},{"cell_type":"markdown","id":"b54756b0","metadata":{"papermill":{"duration":0.013751,"end_time":"2023-07-14T03:17:54.248433","exception":false,"start_time":"2023-07-14T03:17:54.234682","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets for now just focus on column `country`"]},{"cell_type":"code","execution_count":3,"id":"cfedd752","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.271145Z","iopub.status.busy":"2023-07-14T03:17:54.270686Z","iopub.status.idle":"2023-07-14T03:17:54.280038Z","shell.execute_reply":"2023-07-14T03:17:54.278945Z"},"papermill":{"duration":0.023839,"end_time":"2023-07-14T03:17:54.28255","exception":false,"start_time":"2023-07-14T03:17:54.258711","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0         Argentina\n","1         Argentina\n","2         Argentina\n","3         Argentina\n","4         Argentina\n","            ...    \n","136945        Spain\n","136946        Spain\n","136947        Spain\n","136948        Spain\n","136949        Spain\n","Name: country, Length: 136950, dtype: object"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["sample_data = data[\"country\"]\n","\n","sample_data"]},{"cell_type":"markdown","id":"922d370c","metadata":{"papermill":{"duration":0.009327,"end_time":"2023-07-14T03:17:54.301534","exception":false,"start_time":"2023-07-14T03:17:54.292207","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets see what are the Unique values in this "]},{"cell_type":"code","execution_count":4,"id":"b9a7c4c6","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.322076Z","iopub.status.busy":"2023-07-14T03:17:54.321639Z","iopub.status.idle":"2023-07-14T03:17:54.347169Z","shell.execute_reply":"2023-07-14T03:17:54.346286Z"},"papermill":{"duration":0.038343,"end_time":"2023-07-14T03:17:54.349322","exception":false,"start_time":"2023-07-14T03:17:54.310979","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["numpy.ndarray"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["sample_data.unique()\n","\n","type(sample_data.unique())"]},{"cell_type":"markdown","id":"db20ce78","metadata":{"papermill":{"duration":0.008975,"end_time":"2023-07-14T03:17:54.367893","exception":false,"start_time":"2023-07-14T03:17:54.358918","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","This is a `numpy array` of objects as you can see\n","\n","But there is a problem with this array or `unique` function, it is not sorted, nor it provided any functionality or any lead to sort these values according to the number of occurecnes in the dataset. So we will be rather using `pd.DataFrame().value_counts()` function to both access the values as well as there number of ocruncess in the dataset"]},{"cell_type":"code","execution_count":5,"id":"cdc538ea","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.388675Z","iopub.status.busy":"2023-07-14T03:17:54.388264Z","iopub.status.idle":"2023-07-14T03:17:54.415142Z","shell.execute_reply":"2023-07-14T03:17:54.413733Z"},"papermill":{"duration":0.040165,"end_time":"2023-07-14T03:17:54.417424","exception":false,"start_time":"2023-07-14T03:17:54.377259","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["pandas.core.series.Series"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["sample_data.value_counts()\n","\n","type(sample_data.value_counts())"]},{"cell_type":"markdown","id":"dd98986f","metadata":{"papermill":{"duration":0.010724,"end_time":"2023-07-14T03:17:54.438662","exception":false,"start_time":"2023-07-14T03:17:54.427938","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","We can see this is a `pandas.core.series.Series`. We can access only the categories by adding the `index` as `pd.DataFrame().value_counts().index` and the ocurrences by specifying the index normally, like this"]},{"cell_type":"code","execution_count":6,"id":"b510aecd","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.460875Z","iopub.status.busy":"2023-07-14T03:17:54.459591Z","iopub.status.idle":"2023-07-14T03:17:54.562388Z","shell.execute_reply":"2023-07-14T03:17:54.561252Z"},"papermill":{"duration":0.117023,"end_time":"2023-07-14T03:17:54.565554","exception":false,"start_time":"2023-07-14T03:17:54.448531","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["([27390, 27390, 27390, 27390, 27390],\n"," ['Argentina', 'Canada', 'Estonia', 'Japan', 'Spain'])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["ocurrences = [sample_data.value_counts()[x] for x in range(len(sample_data.value_counts()))]\n","categories = [sample_data.value_counts().index[x] for x in range(len(sample_data.value_counts()))]\n","\n","ocurrences , categories"]},{"cell_type":"markdown","id":"6125f71c","metadata":{"papermill":{"duration":0.010963,"end_time":"2023-07-14T03:17:54.588585","exception":false,"start_time":"2023-07-14T03:17:54.577622","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","We could also had used `to_dict()` function to make a dictionary of these `key = categories` and `value = occurences` and then do the further processing. I have not considered that method here. Will update in the newer versions of this notebook\n","\n","So we will be using this list to make new columns in our dataset, we will simply run a for loop iterating over the every values, and using the `np.where` function to make a new column in the end with the binary digits specifying wether the particular category occured in the dataset or not at a specified position. But lets try to do this for on, and then we will apply the for loop"]},{"cell_type":"code","execution_count":7,"id":"0b859a2b","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.611459Z","iopub.status.busy":"2023-07-14T03:17:54.611051Z","iopub.status.idle":"2023-07-14T03:17:54.62349Z","shell.execute_reply":"2023-07-14T03:17:54.622364Z"},"papermill":{"duration":0.027554,"end_time":"2023-07-14T03:17:54.626432","exception":false,"start_time":"2023-07-14T03:17:54.598878","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Argentina</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Argentina</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Argentina</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Argentina</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Argentina</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>136945</th>\n","      <td>Spain</td>\n","    </tr>\n","    <tr>\n","      <th>136946</th>\n","      <td>Spain</td>\n","    </tr>\n","    <tr>\n","      <th>136947</th>\n","      <td>Spain</td>\n","    </tr>\n","    <tr>\n","      <th>136948</th>\n","      <td>Spain</td>\n","    </tr>\n","    <tr>\n","      <th>136949</th>\n","      <td>Spain</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>136950 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["          country\n","0       Argentina\n","1       Argentina\n","2       Argentina\n","3       Argentina\n","4       Argentina\n","...           ...\n","136945      Spain\n","136946      Spain\n","136947      Spain\n","136948      Spain\n","136949      Spain\n","\n","[136950 rows x 1 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["sample_data = pd.DataFrame(sample_data)\n","\n","sample_data"]},{"cell_type":"markdown","id":"0003851a","metadata":{"papermill":{"duration":0.011653,"end_time":"2023-07-14T03:17:54.649119","exception":false,"start_time":"2023-07-14T03:17:54.637466","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Here the magic starts"]},{"cell_type":"code","execution_count":8,"id":"94373733","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.672316Z","iopub.status.busy":"2023-07-14T03:17:54.67192Z","iopub.status.idle":"2023-07-14T03:17:54.690663Z","shell.execute_reply":"2023-07-14T03:17:54.689579Z"},"papermill":{"duration":0.033315,"end_time":"2023-07-14T03:17:54.693022","exception":false,"start_time":"2023-07-14T03:17:54.659707","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([1, 1, 1, ..., 0, 0, 0])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["np.where(sample_data == \"Argentina\" , 1 , 0).squeeze()"]},{"cell_type":"code","execution_count":9,"id":"61e4c5bd","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.716536Z","iopub.status.busy":"2023-07-14T03:17:54.715336Z","iopub.status.idle":"2023-07-14T03:17:54.739204Z","shell.execute_reply":"2023-07-14T03:17:54.738334Z"},"papermill":{"duration":0.037718,"end_time":"2023-07-14T03:17:54.741451","exception":false,"start_time":"2023-07-14T03:17:54.703733","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>country</th>\n","      <th>Argentina</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>136945</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>136946</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>136947</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>136948</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>136949</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>136950 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["          country  Argentina\n","0       Argentina          1\n","1       Argentina          1\n","2       Argentina          1\n","3       Argentina          1\n","4       Argentina          1\n","...           ...        ...\n","136945      Spain          0\n","136946      Spain          0\n","136947      Spain          0\n","136948      Spain          0\n","136949      Spain          0\n","\n","[136950 rows x 2 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["sample_data[\"Argentina\"] = np.where(sample_data == \"Argentina\" , 1 , 0).squeeze()\n","sample_data"]},{"cell_type":"markdown","id":"11176822","metadata":{"papermill":{"duration":0.010415,"end_time":"2023-07-14T03:17:54.76233","exception":false,"start_time":"2023-07-14T03:17:54.751915","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As we can see our most of the work is done, now we just need to apply the loops"]},{"cell_type":"code","execution_count":10,"id":"84b91eb8","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.785215Z","iopub.status.busy":"2023-07-14T03:17:54.784493Z","iopub.status.idle":"2023-07-14T03:17:54.873041Z","shell.execute_reply":"2023-07-14T03:17:54.871832Z"},"papermill":{"duration":0.102961,"end_time":"2023-07-14T03:17:54.875432","exception":false,"start_time":"2023-07-14T03:17:54.772471","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>country</th>\n","      <th>Argentina</th>\n","      <th>country_Argentina</th>\n","      <th>country_Canada</th>\n","      <th>country_Estonia</th>\n","      <th>country_Japan</th>\n","      <th>country_Spain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Argentina</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>136945</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>136946</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>136947</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>136948</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>136949</th>\n","      <td>Spain</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>136950 rows Ã— 7 columns</p>\n","</div>"],"text/plain":["          country  Argentina  country_Argentina  country_Canada  \\\n","0       Argentina          1                  1               0   \n","1       Argentina          1                  1               0   \n","2       Argentina          1                  1               0   \n","3       Argentina          1                  1               0   \n","4       Argentina          1                  1               0   \n","...           ...        ...                ...             ...   \n","136945      Spain          0                  0               0   \n","136946      Spain          0                  0               0   \n","136947      Spain          0                  0               0   \n","136948      Spain          0                  0               0   \n","136949      Spain          0                  0               0   \n","\n","        country_Estonia  country_Japan  country_Spain  \n","0                     0              0              0  \n","1                     0              0              0  \n","2                     0              0              0  \n","3                     0              0              0  \n","4                     0              0              0  \n","...                 ...            ...            ...  \n","136945                0              0              1  \n","136946                0              0              1  \n","136947                0              0              1  \n","136948                0              0              1  \n","136949                0              0              1  \n","\n","[136950 rows x 7 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["for i in sample_data.value_counts().index:\n","    sample_data[\"country\" + \"_\" + i[0]] = np.where(sample_data[\"country\"] == i[0] , 1 , 0)\n","\n","sample_data"]},{"cell_type":"markdown","id":"9320673d","metadata":{"papermill":{"duration":0.010203,"end_time":"2023-07-14T03:17:54.896273","exception":false,"start_time":"2023-07-14T03:17:54.88607","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we dont need the Original column, so we will jsut remove it "]},{"cell_type":"code","execution_count":11,"id":"467fadbd","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.920333Z","iopub.status.busy":"2023-07-14T03:17:54.919917Z","iopub.status.idle":"2023-07-14T03:17:54.931494Z","shell.execute_reply":"2023-07-14T03:17:54.930134Z"},"papermill":{"duration":0.026741,"end_time":"2023-07-14T03:17:54.93409","exception":false,"start_time":"2023-07-14T03:17:54.907349","status":"completed"},"tags":[]},"outputs":[],"source":["sample_data.drop(\"country\" , axis = 1 , inplace = True)"]},{"cell_type":"code","execution_count":12,"id":"83ad9ce7","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:54.957716Z","iopub.status.busy":"2023-07-14T03:17:54.957268Z","iopub.status.idle":"2023-07-14T03:17:54.970281Z","shell.execute_reply":"2023-07-14T03:17:54.96939Z"},"papermill":{"duration":0.027474,"end_time":"2023-07-14T03:17:54.972196","exception":false,"start_time":"2023-07-14T03:17:54.944722","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Argentina</th>\n","      <th>country_Argentina</th>\n","      <th>country_Canada</th>\n","      <th>country_Estonia</th>\n","      <th>country_Japan</th>\n","      <th>country_Spain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>136945</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>136946</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>136947</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>136948</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>136949</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>136950 rows Ã— 6 columns</p>\n","</div>"],"text/plain":["        Argentina  country_Argentina  country_Canada  country_Estonia  \\\n","0               1                  1               0                0   \n","1               1                  1               0                0   \n","2               1                  1               0                0   \n","3               1                  1               0                0   \n","4               1                  1               0                0   \n","...           ...                ...             ...              ...   \n","136945          0                  0               0                0   \n","136946          0                  0               0                0   \n","136947          0                  0               0                0   \n","136948          0                  0               0                0   \n","136949          0                  0               0                0   \n","\n","        country_Japan  country_Spain  \n","0                   0              0  \n","1                   0              0  \n","2                   0              0  \n","3                   0              0  \n","4                   0              0  \n","...               ...            ...  \n","136945              0              1  \n","136946              0              1  \n","136947              0              1  \n","136948              0              1  \n","136949              0              1  \n","\n","[136950 rows x 6 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["sample_data"]},{"cell_type":"markdown","id":"7d52d938","metadata":{"papermill":{"duration":0.010421,"end_time":"2023-07-14T03:17:54.993442","exception":false,"start_time":"2023-07-14T03:17:54.983021","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will make a defined function for this, so that we can use that easily "]},{"cell_type":"code","execution_count":13,"id":"31ddd552","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:55.016922Z","iopub.status.busy":"2023-07-14T03:17:55.016192Z","iopub.status.idle":"2023-07-14T03:17:55.021452Z","shell.execute_reply":"2023-07-14T03:17:55.020647Z"},"papermill":{"duration":0.019273,"end_time":"2023-07-14T03:17:55.023488","exception":false,"start_time":"2023-07-14T03:17:55.004215","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_func(dataframe , columns):\n","    \n","    for i in columns:\n","                \n","        for j in dataframe[i].value_counts().index[0]:\n","                \n","            dataframe[i + \"_\" + j[0]] = np.where(dataframe[i] == j[0] , 1 , 0)\n","                \n","        dataframe.drop(i , axis = 1 , inplace = True)"]},{"cell_type":"markdown","id":"6563bdc9","metadata":{"papermill":{"duration":0.011026,"end_time":"2023-07-14T03:17:55.045455","exception":false,"start_time":"2023-07-14T03:17:55.034429","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","This is velnurable to one risk, That is if user enters one column, I dont know why, but numpy is treating the single column as tuple and list of columns as list, We will be adding a if condition to surpass this. **ANY LEADS TO THIS IS HIGHLY APPRICEATED, COMMENT, IF YOU KNOW HOW TO FIX THIS**"]},{"cell_type":"code","execution_count":14,"id":"1ea1085f","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:55.069512Z","iopub.status.busy":"2023-07-14T03:17:55.068734Z","iopub.status.idle":"2023-07-14T03:17:55.075628Z","shell.execute_reply":"2023-07-14T03:17:55.074726Z"},"papermill":{"duration":0.021517,"end_time":"2023-07-14T03:17:55.07797","exception":false,"start_time":"2023-07-14T03:17:55.056453","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_func(dataframe , columns):\n","    \n","    if len(columns) == 1 :\n","        \n","        for i in columns:\n","                \n","            for j in dataframe[i].value_counts().index[0]:\n","                \n","                dataframe[i + \"_\" + j[0]] = np.where(dataframe[i] == j[0] , 1 , 0)\n","                \n","            dataframe.drop(i , axis = 1 , inplace = True)\n","\n","    else : \n","        \n","        for i in columns:\n","                \n","            for j in dataframe[i].value_counts().index[0]:\n","                \n","                dataframe[i + \"_\" + j] = np.where(dataframe[i] == j , 1 , 0)\n","                \n","            dataframe.drop(i , axis = 1 , inplace = True)"]},{"cell_type":"markdown","id":"e05801ab","metadata":{"papermill":{"duration":0.010623,"end_time":"2023-07-14T03:17:55.099714","exception":false,"start_time":"2023-07-14T03:17:55.089091","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#86242A; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #86242A\">2 | Functionalities ðŸ”¨</p>\n","\n","<div style=\"border-radius:10px; border:#86242A solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Our goal is to make a replica of **[sklearn.preprocessing.onehotencoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)**\n","\n","Now we will add some functionalities to make it easier to use our function\n","\n","|Name|Attribute|Accepted Values|Deafult|Information|Applied\n","|---|---|---|---|---|---|\n","|Drop|`drop`|`{â€˜firstâ€™, â€˜if_binaryâ€™ , 'None'}`|`None`|Specifies a methodology to use to drop one of the categories per feature|âœ…\n","|Dtype|`dtype`|`int`|`float`|Desired dtype of output|âœ…\n","|Min Frequency|`min_frequency`|`int`/`float`|`None`|Specifies the minimum frequency below which a category will be considered infrequent|âœ…\n","|Max Categories|`max_categories`|`int`|`None`|Specifies an upper limit to the number of output features for each input feature when considering infrequent categories. If there are infrequent categories, `max_categories` includes the category representing the infrequent categories along with the frequent categories. If `None`, there is no limit to the number of output features|âœ…\n","## 2.1 | Drop\n","\n","This is useful in situations where `perfectly collinear features` cause problems, such as when feeding the resulting data into an unregularized linear regression model. However, dropping one category breaks the symmetry of the original representation and can therefore induce a bias in downstream models, for instance for penalized linear classification or regression models.\n","\n","First we will shorten our scope to only `first` \n","Here we just need to chek for a condition and do the work accordingly "]},{"cell_type":"code","execution_count":15,"id":"24f3cafc","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:55.123212Z","iopub.status.busy":"2023-07-14T03:17:55.122506Z","iopub.status.idle":"2023-07-14T03:17:55.13077Z","shell.execute_reply":"2023-07-14T03:17:55.129966Z"},"papermill":{"duration":0.022642,"end_time":"2023-07-14T03:17:55.133105","exception":false,"start_time":"2023-07-14T03:17:55.110463","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_func(dataframe , columns , drop = None):\n","    \n","    if len(columns) == 1 :\n","        \n","        for j in dataframe[columne[0]].value_counts().index[0]:\n","\n","            dataframe[columns[0] + \"_\" + j[0]] = np.where(dataframe[columns[0]] == j[0] \n","                                                          , 1 , 0)\n","        if drop == \"first\" :\n","            \n","            dataframe.drop(str(columns[0]) + \"_\" + sample_data[columne[0]].value_counts.index[0] , \n","                          axis = 1 , inplace = True)\n","\n","        dataframe.drop(columns[0] , axis = 1 , inplace = True)\n","\n","    else : \n","        \n","        for i in columns:\n","                \n","            for j in dataframe[i].value_counts().index[0]:\n","                \n","                dataframe[i + \"_\" + j] = np.where(dataframe[i] == j , 1 , 0)\n","            if drop == \"first\" :\n","            \n","                dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] , \n","                               axis = 1 , inplace = True)\n","            \n","            dataframe.drop(i , axis = 1 , inplace = True)"]},{"cell_type":"markdown","id":"df81c424","metadata":{"papermill":{"duration":0.01051,"end_time":"2023-07-14T03:17:55.154428","exception":false,"start_time":"2023-07-14T03:17:55.143918","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#86242A solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now for doing for the `drop = \"if_binary\"`.\n","\n","Now lets try to take a overview of what the function is doing.\n","* if we choose `drop = None` , then it retains all columns\n","* if we choose `drop = \"first\"` , then it removes the first feature\n","* if we choose `drop = if_binary` , then it removes the first feature\n","\n","Notice both at `drop = \"first\"` and `drop = \"if_binary\"`, it removes the first feature. Then we can just combine these functions and do the things."]},{"cell_type":"code","execution_count":16,"id":"c78356d3","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:55.178195Z","iopub.status.busy":"2023-07-14T03:17:55.177444Z","iopub.status.idle":"2023-07-14T03:17:55.186133Z","shell.execute_reply":"2023-07-14T03:17:55.185253Z"},"papermill":{"duration":0.022692,"end_time":"2023-07-14T03:17:55.188251","exception":false,"start_time":"2023-07-14T03:17:55.165559","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_func(dataframe , columns , drop = None):\n","    \n","    if len(columns) == 1 :\n","        \n","        for j in dataframe[columne[0]].value_counts().index[0]:\n","\n","            dataframe[columns[0] + \"_\" + j[0]] = np.where(dataframe[columns[0]] == j[0] \n","                                                          , 1 , 0)\n","        if drop == \"first\" or drop == \"if_binary\":\n","            \n","            dataframe.drop(str(columns[0]) + \"_\" + sample_data[columne[0]].value_counts.index[0] , \n","                          axis = 1 , inplace = True)\n","\n","        dataframe.drop(columns[0] , axis = 1 , inplace = True)\n","\n","    else : \n","        \n","        for i in columns:\n","                \n","            for j in dataframe[i].value_counts().index[0]:\n","                \n","                dataframe[i + \"_\" + j] = np.where(dataframe[i] == j , 1 , 0)\n","            if drop == \"first\" or drop == \"if_binary\" :\n","            \n","                dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] , \n","                               axis = 1 , inplace = True)\n","            \n","            dataframe.drop(i , axis = 1 , inplace = True)"]},{"cell_type":"markdown","id":"0344f92c","metadata":{"papermill":{"duration":0.010452,"end_time":"2023-07-14T03:17:55.21001","exception":false,"start_time":"2023-07-14T03:17:55.199558","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#86242A solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## 2.2 | Dtype\n","\n","Here we know that the dtype of numerical in the simplest format can be only either `int` or `float`. So we just need to add an `if-else` condtion to do this."]},{"cell_type":"code","execution_count":17,"id":"ab890b8a","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:55.233849Z","iopub.status.busy":"2023-07-14T03:17:55.23321Z","iopub.status.idle":"2023-07-14T03:17:55.242256Z","shell.execute_reply":"2023-07-14T03:17:55.241337Z"},"papermill":{"duration":0.023807,"end_time":"2023-07-14T03:17:55.244528","exception":false,"start_time":"2023-07-14T03:17:55.220721","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_func(dataframe , columns , min_frequency = None , dtype = float):\n","    \n","    if len(columns) == 1:\n","\n","        for j in dataframe[columne[0]].value_counts().index[0]:\n","\n","            dataframe[columne[0] + \"_\" + j[0]] = np.where(dataframe[columne[0]] == j[0] ,\n","                                                    dtype(1) , dtype(0))\n","        if drop == \"first\" or drop == \"if_binary\" :\n","                    dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                   axis = 1 , inplace = True)\n","        dataframe.drop(columne[0] , axis = 1 , inplace = True)\n","\n","    else :\n","\n","        for i in columns:\n","\n","            for j in dataframe[i].value_counts().index[0]:\n","\n","                dataframe[i + \"_\" + j] = np.where(dataframe[i] == j ,\n","                                                  dtype(1) , dtype(0))\n","            if drop == \"first\" or drop == \"if_binary\" :\n","                    dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                   axis = 1 , inplace = True)\n","            dataframe.drop(i , axis = 1 , inplace = True)\n"]},{"cell_type":"markdown","id":"70e9c684","metadata":{"papermill":{"duration":0.010993,"end_time":"2023-07-14T03:17:55.266487","exception":false,"start_time":"2023-07-14T03:17:55.255494","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#86242A solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## 2.3 | Min_Frequency\n","For this we will\n","\n","* just create a list containing those who do not have the minimum number of occurences\n","* then check if the category do not exist in the list or not\n","* * if True ,\n","* * make the respective column\n","* * else\n","* * make another column as other and put all of the list into that column, For this we will be using the pd.DataFrame().isin(list) function"]},{"cell_type":"code","execution_count":18,"id":"3adf4f45","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:55.29087Z","iopub.status.busy":"2023-07-14T03:17:55.289937Z","iopub.status.idle":"2023-07-14T03:17:55.305439Z","shell.execute_reply":"2023-07-14T03:17:55.304497Z"},"papermill":{"duration":0.030394,"end_time":"2023-07-14T03:17:55.308017","exception":false,"start_time":"2023-07-14T03:17:55.277623","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_func(dataframe , columns , min_frequency = None , dtype = float):\n","\n","    if not min_frequency == None:\n","\n","        if len(columns) == 1 :\n","\n","            inf = [j\n","                for j in dataframe[columne[0]].value_counts().index\n","                if dataframe[columne[0]].value_counts()[j] > min_frequency]\n","\n","            for j in dataframe[columne[0]].value_counts().index:\n","\n","                if not j in inf:\n","\n","                    dataframe[columne[0] + \"_\" + j[0]] = np.where(dataframe[columne[0]] == j[0] ,\n","                                                                  dtype(1) , dtype(0))\n","\n","                else:\n","\n","                    dataframe[columne[0] + \"_other\"] = np.where(dataframe[columne[0]].isin(inf) ,\n","                                                                dtype(1) , dtype(0))\n","                if drop == \"first\" or drop == \"if_binary\":\n","                    dataframe.drop(str(columns[0]) + \"_\" + sample_data[columne[0]].value_counts.index[0] ,\n","                                   axis = 1 , inplace = True)\n","            dataframe.drop(i , axis = 1 , inplace = True)\n","        else :\n","            for i in columns:\n","\n","                inf = [j\n","                    for j in dataframe[i].value_counts().index\n","                    if dataframe[i].value_counts()[j] > min_frequency]\n","\n","                for j in dataframe[i].value_counts().index:\n","\n","                    if not j in inf:\n","\n","                        dataframe[i + \"_\" + j] = np.where(dataframe[i] == j ,\n","                                                          dtype(1) , dtype(0))\n","\n","                    else:\n","\n","                        dataframe[i + \"_other\"] = np.where(dataframe[i].isin(inf) ,\n","                                                           dtype(1) , dtype(0))\n","                    if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                dataframe.drop(i , axis = 1 , inplace = True)\n","    else :\n","\n","        if len(columns) == 1:\n","\n","            for j in dataframe[columne[0]].value_counts().index[0]:\n","\n","                dataframe[columne[0] + \"_\" + j[0]] = np.where(dataframe[columne[0]] == j[0] ,\n","                                                        dtype(1) , dtype(0))\n","            if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","            dataframe.drop(columne[0] , axis = 1 , inplace = True)\n","\n","        else :\n","\n","            for i in columns:\n","\n","                for j in dataframe[i].value_counts().index[0]:\n","\n","                    dataframe[i + \"_\" + j] = np.where(dataframe[i] == j ,\n","                                                      dtype(1) , dtype(0))\n","                if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                dataframe.drop(i , axis = 1 , inplace = True)\n"]},{"cell_type":"markdown","id":"e5971114","metadata":{"papermill":{"duration":0.010951,"end_time":"2023-07-14T03:17:55.33036","exception":false,"start_time":"2023-07-14T03:17:55.319409","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#86242A solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","This was for when `min_frequecy = int`, for `float`, we need to multipy this number by `n_samples`"]},{"cell_type":"code","execution_count":19,"id":"0e05d51e","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:55.354417Z","iopub.status.busy":"2023-07-14T03:17:55.353721Z","iopub.status.idle":"2023-07-14T03:17:55.370524Z","shell.execute_reply":"2023-07-14T03:17:55.369142Z"},"papermill":{"duration":0.031842,"end_time":"2023-07-14T03:17:55.373021","exception":false,"start_time":"2023-07-14T03:17:55.341179","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_func(dataframe , columns , min_frequency = None , dtype = float):\n","    if type(min_frquency) == int:\n","        pass\n","    else :\n","        min_frequnecy *= len(columns)\n","\n","    if not min_frequency == None:\n","\n","        if len(columns) == 1 :\n","\n","            inf = [j\n","                for j in dataframe[columne[0]].value_counts().index\n","                if dataframe[columne[0]].value_counts()[j] > min_frequency]\n","\n","            for j in dataframe[columne[0]].value_counts().index:\n","\n","                if not j in inf:\n","\n","                    dataframe[columne[0] + \"_\" + j[0]] = np.where(dataframe[columne[0]] == j[0] ,\n","                                                                  dtype(1) , dtype(0))\n","\n","                else:\n","\n","                    dataframe[columne[0] + \"_other\"] = np.where(dataframe[columne[0]].isin(inf) ,\n","                                                                dtype(1) , dtype(0))\n","                if drop == \"first\" or drop == \"if_binary\":\n","                    dataframe.drop(str(columns[0]) + \"_\" + sample_data[columne[0]].value_counts.index[0] ,\n","                                   axis = 1 , inplace = True)\n","            dataframe.drop(i , axis = 1 , inplace = True)\n","        else :\n","            for i in columns:\n","\n","                inf = [j\n","                    for j in dataframe[i].value_counts().index\n","                    if dataframe[i].value_counts()[j] > min_frequency]\n","\n","                for j in dataframe[i].value_counts().index:\n","\n","                    if not j in inf:\n","\n","                        dataframe[i + \"_\" + j] = np.where(dataframe[i] == j ,\n","                                                          dtype(1) , dtype(0))\n","\n","                    else:\n","\n","                        dataframe[i + \"_other\"] = np.where(dataframe[i].isin(inf) ,\n","                                                           dtype(1) , dtype(0))\n","                    if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                dataframe.drop(i , axis = 1 , inplace = True)\n","    else :\n","\n","        if len(columns) == 1:\n","\n","            for j in dataframe[columne[0]].value_counts().index[0]:\n","\n","                dataframe[columne[0] + \"_\" + j[0]] = np.where(dataframe[columne[0]] == j[0] ,\n","                                                        dtype(1) , dtype(0))\n","            if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","            dataframe.drop(columne[0] , axis = 1 , inplace = True)\n","\n","        else :\n","\n","            for i in columns:\n","\n","                for j in dataframe[i].value_counts().index[0]:\n","\n","                    dataframe[i + \"_\" + j] = np.where(dataframe[i] == j ,\n","                                                      dtype(1) , dtype(0))\n","                if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                dataframe.drop(i , axis = 1 , inplace = True)"]},{"cell_type":"markdown","id":"7128a1f3","metadata":{"papermill":{"duration":0.010952,"end_time":"2023-07-14T03:17:55.395187","exception":false,"start_time":"2023-07-14T03:17:55.384235","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#86242A solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## 2.4 | Max_categories\n","\n","For this we will just access the original list of categores and place a kink at the hyperparameter(max_categories) and apply the same implemntation as we did for the the min_frequency"]},{"cell_type":"code","execution_count":20,"id":"b8746dd1","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:55.420268Z","iopub.status.busy":"2023-07-14T03:17:55.419679Z","iopub.status.idle":"2023-07-14T03:17:55.443152Z","shell.execute_reply":"2023-07-14T03:17:55.442015Z"},"papermill":{"duration":0.03874,"end_time":"2023-07-14T03:17:55.445401","exception":false,"start_time":"2023-07-14T03:17:55.406661","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_func(dataframe , columns , min_frequency = None , max_categories = None , dtype = float):\n","    if type(min_frquency) == int:\n","        pass\n","    else :\n","        min_frequnecy *= len(columns)\n","\n","    if not min_frequency == None:\n","\n","        if len(columns) == 1 :\n","\n","            inf = [j\n","                for j in dataframe[columns[0]].value_counts().index\n","                if dataframe[columns[0]].value_counts()[j] > min_frequency]\n","\n","            for j in dataframe[columns[0]].value_counts().index:\n","\n","                if not j in inf:\n","\n","                    dataframe[columns[0] + \"_\" + j[0]] = np.where(dataframe[columns[0]] == j[0] , dtype(1) , dtype(0))\n","\n","                else:\n","\n","                    dataframe[columns[0] + \"_other\"] = np.where(dataframe[columns[0]].isin(inf) , dtype(1) , dtype(0))\n","                if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(columne[0]) + \"_\" + sample_data[columne[0]].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                dataframe.drop(columne[0] , axis = 1 , inplace = True)\n","        else :\n","            for i in columns:\n","\n","                inf = [j\n","                    for j in dataframe[i].value_counts().index\n","                    if dataframe[i].value_counts()[j] > min_frequency]\n","\n","                for j in dataframe[i].value_counts().index:\n","\n","                    if not j in inf:\n","\n","                        dataframe[i + \"_\" + j] = np.where(dataframe[i] == j , dtype(1) , dtype(0))\n","\n","                    else:\n","\n","                        dataframe[i + \"_other\"] = np.where(dataframe[i].isin(inf) , dtype(1) , dtype(0))\n","                    if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                dataframe.drop(i , axis = 1 , inplace = True)\n","\n","    elif not max_categories == None:\n","\n","        if len(columns) == 1:\n","\n","            inf = dataframe[columnes[0]].value_counts().index[max_categories : ]\n","\n","            for j in dataframe[columnes[0]].value_counts().index[: max_categories]:\n","\n","                dataframe[columnes[0] + \"_\" + j[0]] = np.where(dataframe[columnes[0]] == j[0] , dtype(1) , dtype(0))\n","\n","            dataframe[columnes[0] + \"_other\"] = np.where(dataframe[columnes[0]].isin(inf) , dtype(1) , dtype(0))\n","            if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(columne[0]) + \"_\" + sample_data[columne[0]].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","            dataframe.drop(columnes[0] , axis = 1 , inplace = True)\n","\n","        else :\n","\n","            for i in columns:\n","\n","                inf = dataframe[i].value_counts().index[max_categories : ]\n","\n","                for j in dataframe[i].value_counts().index[: max_categories]:\n","\n","                    dataframe[i + \"_\" + j] = np.where(dataframe[i] == j , dtype(1) , dtype(0))\n","\n","                dataframe[i + \"_other\"] = np.where(dataframe[i].isin(inf) , dtype(1) , dtype(0))\n","                if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                dataframe.drop(i , axis = 1 , inplace = True)\n","\n","    else :\n","\n","        if len(columns) == 1:\n","\n","            for j in dataframe[columns[0]].value_counts().index[0]:\n","\n","                dataframe[columns[0] + \"_\" + j[0]] = np.where(dataframe[columns[0]] == j[0] , dtype(1) , dtype(0))\n","            if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(columns[0]) + \"_\" + sample_data[columns[0]].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","            dataframe.drop(columns[0] , axis = 1 , inplace = True)\n","\n","        else :\n","\n","            for i in columns:\n","\n","                for j in dataframe[i].value_counts().index[0]:\n","\n","                    dataframe[i + \"_\" + j] = np.where(dataframe[i] == j , dtype(1) , dtype(0))\n","                if drop == \"first\" or drop == \"if_binary\" :\n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                dataframe.drop(i , axis = 1 , inplace = True)\n"]},{"cell_type":"markdown","id":"cffbc5ab","metadata":{"papermill":{"duration":0.010651,"end_time":"2023-07-14T03:17:55.467857","exception":false,"start_time":"2023-07-14T03:17:55.457206","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#964B00; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #964B00\">3 | Final Code ðŸ’¡</p>\n","\n","<div style=\"border-radius:10px; border:#964B00 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","This is the final code"]},{"cell_type":"code","execution_count":21,"id":"6b92fbc3","metadata":{"execution":{"iopub.execute_input":"2023-07-14T03:17:55.491081Z","iopub.status.busy":"2023-07-14T03:17:55.490678Z","iopub.status.idle":"2023-07-14T03:17:55.512333Z","shell.execute_reply":"2023-07-14T03:17:55.511155Z"},"papermill":{"duration":0.036221,"end_time":"2023-07-14T03:17:55.514889","exception":false,"start_time":"2023-07-14T03:17:55.478668","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_func(dataframe , columns , min_frequency = None , max_categories = None , dtype = float):\n","    \n","    if type(min_frquency) == int:pass\n","    else :min_frequnecy *= len(columns)\n","\n","    if not min_frequency == None:\n","\n","        if len(columns) == 1 :\n","\n","            inf = [j\n","                for j in dataframe[columns[0]].value_counts().index\n","                if dataframe[columns[0]].value_counts()[j] > min_frequency]\n","\n","            for j in dataframe[columns[0]].value_counts().index:\n","\n","                if not j in inf:\n","\n","                    dataframe[columns[0] + \"_\" + j[0]] = np.where(dataframe[columns[0]] == j[0] , dtype(1) , dtype(0))\n","\n","                else:\n","\n","                    dataframe[columns[0] + \"_other\"] = np.where(dataframe[columns[0]].isin(inf) , dtype(1) , dtype(0))\n","                \n","                if drop == \"first\" or drop == \"if_binary\" :\n","                        \n","                        dataframe.drop(str(columne[0]) + \"_\" + sample_data[columne[0]].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                \n","                dataframe.drop(columne[0] , axis = 1 , inplace = True)\n","        \n","        else :\n","            \n","            for i in columns:\n","\n","                inf = [j\n","                    for j in dataframe[i].value_counts().index\n","                    if dataframe[i].value_counts()[j] > min_frequency]\n","\n","                for j in dataframe[i].value_counts().index:\n","\n","                    if not j in inf:\n","\n","                        dataframe[i + \"_\" + j] = np.where(dataframe[i] == j , dtype(1) , dtype(0))\n","\n","                    else:\n","\n","                        dataframe[i + \"_other\"] = np.where(dataframe[i].isin(inf) , dtype(1) , dtype(0))\n","                    \n","                    if drop == \"first\" or drop == \"if_binary\" :\n","                        \n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                \n","                dataframe.drop(i , axis = 1 , inplace = True)\n","\n","    elif not max_categories == None:\n","\n","        if len(columns) == 1:\n","\n","            inf = dataframe[columnes[0]].value_counts().index[max_categories : ]\n","\n","            for j in dataframe[columnes[0]].value_counts().index[: max_categories]:\n","\n","                dataframe[columnes[0] + \"_\" + j[0]] = np.where(dataframe[columnes[0]] == j[0] , dtype(1) , dtype(0))\n","\n","            dataframe[columnes[0] + \"_other\"] = np.where(dataframe[columnes[0]].isin(inf) , dtype(1) , dtype(0))\n","            \n","            if drop == \"first\" or drop == \"if_binary\" :\n","                        \n","                    dataframe.drop(str(columne[0]) + \"_\" + sample_data[columne[0]].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","            \n","            dataframe.drop(columnes[0] , axis = 1 , inplace = True)\n","\n","        else :\n","\n","            for i in columns:\n","\n","                inf = dataframe[i].value_counts().index[max_categories : ]\n","\n","                for j in dataframe[i].value_counts().index[: max_categories]:\n","\n","                    dataframe[i + \"_\" + j] = np.where(dataframe[i] == j , dtype(1) , dtype(0))\n","\n","                dataframe[i + \"_other\"] = np.where(dataframe[i].isin(inf) , dtype(1) , dtype(0))\n","                \n","                if drop == \"first\" or drop == \"if_binary\" :\n","                        \n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                \n","                dataframe.drop(i , axis = 1 , inplace = True)\n","\n","    else :\n","\n","        if len(columns) == 1:\n","\n","            for j in dataframe[columns[0]].value_counts().index[0]:\n","\n","                dataframe[columns[0] + \"_\" + j[0]] = np.where(dataframe[columns[0]] == j[0] , dtype(1) , dtype(0))\n","            \n","            if drop == \"first\" or drop == \"if_binary\" :\n","                        \n","                    dataframe.drop(str(columns[0]) + \"_\" + sample_data[columns[0]].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","            \n","            dataframe.drop(columns[0] , axis = 1 , inplace = True)\n","\n","        else :\n","\n","            for i in columns:\n","\n","                for j in dataframe[i].value_counts().index[0]:\n","\n","                    dataframe[i + \"_\" + j] = np.where(dataframe[i] == j , dtype(1) , dtype(0))\n","                \n","                if drop == \"first\" or drop == \"if_binary\" :\n","                        \n","                        dataframe.drop(str(i) + \"_\" + sample_data[i].value_counts.index[0] ,\n","                                       axis = 1 , inplace = True)\n","                \n","                dataframe.drop(i , axis = 1 , inplace = True)\n"]},{"cell_type":"markdown","id":"395efef1","metadata":{"papermill":{"duration":0.010854,"end_time":"2023-07-14T03:17:55.536705","exception":false,"start_time":"2023-07-14T03:17:55.525851","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#800080; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #800080\">4 | Ending ðŸ¤ž</p>\n","\n","<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","**THIS IS NOT THE FULL IMPLEMENTATION, IT STILL LACKS MANY FUNCTIONALITIES AND IS VULENRABLE TO MANY EDGE CASES, WE WILL IMPROVE THIS IN THE UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT DOWN IF I DID ANY MISTAKES, OR IF CAN MAKE THIS MORE CONNECTED TO THE GROUND, OR SUGGESTIONS. YOUR ASSISTS ARE HIGHLY APPRECIABLE**\n","\n","**THATS IT FOR TODAY GUYS**\n","\n","**HOPE YOU UNDERSTOOD AND LIKED MY WORK**\n","\n","**DONT FORGET TO MAKE AN UPVOTE  $:)$**\n","\n","<img src = \"https://i.imgflip.com/19aadg.jpg\">\n","\n","**PEACE OUT**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":12.537371,"end_time":"2023-07-14T03:17:56.370799","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-14T03:17:43.833428","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}