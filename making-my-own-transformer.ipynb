{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/making-my-own-transformer?scriptVersionId=138762526\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"4c52f936","metadata":{"papermill":{"duration":0.014611,"end_time":"2023-08-03T07:11:46.733153","exception":false,"start_time":"2023-08-03T07:11:46.718542","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#00B9F7; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #00B9F7\">Transformers</p>"]},{"cell_type":"code","execution_count":1,"id":"5e4f159b","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-08-03T07:11:46.75939Z","iopub.status.busy":"2023-08-03T07:11:46.758979Z","iopub.status.idle":"2023-08-03T07:11:46.770006Z","shell.execute_reply":"2023-08-03T07:11:46.769217Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.028107,"end_time":"2023-08-03T07:11:46.773741","exception":false,"start_time":"2023-08-03T07:11:46.745634","status":"completed"},"tags":[]},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"2fedb3ee","metadata":{"papermill":{"duration":0.012166,"end_time":"2023-08-03T07:11:46.798426","exception":false,"start_time":"2023-08-03T07:11:46.78626","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00B9F7 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = 'https://media.tenor.com/LStfD5yI5SsAAAAC/transformers-darkofthemoon.gif'>\n","    \n","## So what the hell is this **`Transformers`** $...?$\n","    \n","Yes we have been asking this question from an whole eternity. When we search on $Google$/or any other search engine, we find the same answer\n","```\n","A transformer is a type of neural network architecture that is blah blah blah blah\n","```\n","But what it actually is and why do we even need this \n","    \n","<img src = 'https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png' width = 400>"]},{"cell_type":"markdown","id":"355d6c4c","metadata":{"papermill":{"duration":0.011785,"end_time":"2023-08-03T07:11:46.822577","exception":false,"start_time":"2023-08-03T07:11:46.810792","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#8E24AA; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #8E24AA\">1 | Self Attention 👀</p>"]},{"cell_type":"code","execution_count":2,"id":"b2ed033d","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:46.848963Z","iopub.status.busy":"2023-08-03T07:11:46.848025Z","iopub.status.idle":"2023-08-03T07:11:50.313148Z","shell.execute_reply":"2023-08-03T07:11:50.311948Z"},"papermill":{"duration":3.481133,"end_time":"2023-08-03T07:11:50.315963","exception":false,"start_time":"2023-08-03T07:11:46.83483","status":"completed"},"tags":[]},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","id":"125c8585","metadata":{"papermill":{"duration":0.011755,"end_time":"2023-08-03T07:11:50.339799","exception":false,"start_time":"2023-08-03T07:11:50.328044","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<IMG SRC = 'https://media.tenor.com/AleRU5nZSasAAAAC/attention-notice-me.gif' WIDTH = 400>\n","    \n","Society says that the best way to understand `Transformer Architechture`, is to first understand `Self-Attention Mechanism`. \n","\n","I dont know who are the actual people in society, and why do these people do not show up individually, why they cover up themselves with the word `Society`\n","\n","**LEAVE IT !!!**\n","\n","Lets assume we have this sentence `Radhe Krishn`\n","\n","Lets assume we pass this to an `Embedding Layer` to get `Embeddings`. These `Embeddings` will be `Random`, but lets dive it in "]},{"cell_type":"code","execution_count":3,"id":"d44c9b2a","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:50.366352Z","iopub.status.busy":"2023-08-03T07:11:50.365678Z","iopub.status.idle":"2023-08-03T07:11:50.402057Z","shell.execute_reply":"2023-08-03T07:11:50.400969Z"},"papermill":{"duration":0.052651,"end_time":"2023-08-03T07:11:50.404596","exception":false,"start_time":"2023-08-03T07:11:50.351945","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Embedding(2, 12)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["Embedding_Layer = nn.Embedding(2 , 12)\n","Embedding_Layer"]},{"cell_type":"markdown","id":"87455c37","metadata":{"papermill":{"duration":0.011353,"end_time":"2023-08-03T07:11:50.427799","exception":false,"start_time":"2023-08-03T07:11:50.416446","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As our corpus only consists of $2$ distinct words, we can label them as `[0,1]`\n","\n","Passing this to an Embedding Layer, "]},{"cell_type":"code","execution_count":4,"id":"26a1877b","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:50.454552Z","iopub.status.busy":"2023-08-03T07:11:50.453322Z","iopub.status.idle":"2023-08-03T07:11:50.533555Z","shell.execute_reply":"2023-08-03T07:11:50.532427Z"},"papermill":{"duration":0.096022,"end_time":"2023-08-03T07:11:50.535846","exception":false,"start_time":"2023-08-03T07:11:50.439824","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[ 0.7209,  0.4126, -0.4243, -2.6927, -0.9098, -1.1106,  0.0666, -0.3723,\n","           0.2370,  0.5469,  0.4355, -1.3716],\n","         [ 0.2793, -1.5726,  0.0105,  0.5368, -0.1770, -0.8131,  0.2853, -0.5327,\n","          -0.2775, -0.7644,  2.3227, -0.2532]], grad_fn=<EmbeddingBackward0>),\n"," torch.Size([2, 12]))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["inputs = Embedding_Layer(torch.tensor([0 , 1] , dtype = torch.long))\n","inputs , inputs.shape"]},{"cell_type":"markdown","id":"a24dddcf","metadata":{"papermill":{"duration":0.012048,"end_time":"2023-08-03T07:11:50.559952","exception":false,"start_time":"2023-08-03T07:11:50.547904","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Suppose we could be able to know, how much these words affect each other "]},{"cell_type":"code","execution_count":5,"id":"f17a7d33","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-08-03T07:11:50.58682Z","iopub.status.busy":"2023-08-03T07:11:50.586227Z","iopub.status.idle":"2023-08-03T07:11:50.84813Z","shell.execute_reply":"2023-08-03T07:11:50.847068Z"},"papermill":{"duration":0.278209,"end_time":"2023-08-03T07:11:50.850545","exception":false,"start_time":"2023-08-03T07:11:50.572336","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x7b3e2ce8b9a0>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAhYAAAB+CAYAAAB4f1jNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAMg0lEQVR4nO3df0yVdcPH8c/hIAewIz3oBM/jgeFuNkzKDOqZiGmr2Mixu7X1W2OztptHLIh7TY02m3uEssXaInGnP+qPbhd/VGZ7auusGuhckwjKWcu5mJwixqNrgJgHPee6/2iy8ajBwS98z6Xv13b9cb7nsOuz79Hr+vA91+HyOI7jCAAAwIAU2wEAAMD1g2IBAACMoVgAAABjKBYAAMAYigUAADCGYgEAAIyhWAAAAGMoFgAAwJjUud5hPB7XwMCA/H6/PB7PXO8eAADMgOM4Gh0dVSAQUErK1dcl5rxYDAwMKBgMzvVuAQCAAZFIREuXLr3q83NeLPx+vySp5F//UGqmb653P22nR+fbjjAtzombbEeYUt7/HLUdYUr/94//sh1hWlLHkv8v8J+566LtCFOad2bOD30zEvvP87YjTMm/IPkzRi94bUeYlv/4ILnPO7EL5/Xt/+6eOI9fzZz/77r08Udqpk+p85O3WHhj6bYjTEs8Pflzpnrm2Y4wJW9a8s+jJHkvJH+xSMlI/mKRku6OYuFk2k4wNW9m8v+b9F5wx/udOs8dx6GpLmPg4k0AAGAMxQIAABhDsQAAAMZQLAAAgDEUCwAAYAzFAgAAGEOxAAAAxlAsAACAMRQLAABgDMUCAAAYQ7EAAADGUCwAAIAxFAsAAGDMjIrF3r17VVBQoPT0dJWUlOjQoUOmcwEAABdKuFi0t7ervr5ejY2N6unp0dq1a1VZWan+/v7ZyAcAAFwk4WLR0tKip59+Ws8884yWL1+uN954Q8FgUG1tbbORDwAAuEhCxWJ8fFzd3d2qqKiYNF5RUaEjR45c8Wei0ahGRkYmbQAA4PqUULE4ffq0YrGYcnJyJo3n5ORocHDwij/T3NysrKysiS0YDM48LQAASGozunjT4/FMeuw4zmVjl+zYsUPDw8MTWyQSmckuAQCAC6Qm8uJFixbJ6/VetjoxNDR02SrGJT6fTz6fb+YJAQCAayS0YpGWlqaSkhKFw+FJ4+FwWGVlZUaDAQAA90loxUKSGhoatGnTJpWWlmr16tUKhULq7+9XTU3NbOQDAAAuknCxePTRR3XmzBnt2rVLv/32m4qLi/Xpp58qPz9/NvIBAAAXSbhYSNKWLVu0ZcsW01kAAIDLca8QAABgDMUCAAAYQ7EAAADGUCwAAIAxFAsAAGAMxQIAABhDsQAAAMZQLAAAgDEUCwAAYAzFAgAAGEOxAAAAxlAsAACAMRQLAABgzIzubmrC4JkspfyRbmv3U1r6nrWpScipv8dsR5jS4IHltiNM6Wxf3HaEabnpVPL/LuC96YLtCFPy/jLPdoRpcX5L3mPkJbHeDNsRpvTDP/fajjAtf+v7b9sR/lL8fIp0YOrXJf9RCgAAuAbFAgAAGEOxAAAAxlAsAACAMRQLAABgDMUCAAAYQ7EAAADGUCwAAIAxFAsAAGAMxQIAABhDsQAAAMZQLAAAgDEUCwAAYAzFAgAAGEOxAAAAxlAsAACAMRQLAABgTMLForOzU1VVVQoEAvJ4PDpw4MAsxAIAAG6UcLEYGxvTypUr1draOht5AACAi6Um+gOVlZWqrKycjSwAAMDlEi4WiYpGo4pGoxOPR0ZGZnuXAADAklm/eLO5uVlZWVkTWzAYnO1dAgAAS2a9WOzYsUPDw8MTWyQSme1dAgAAS2b9oxCfzyefzzfbuwEAAEmAv2MBAACMSXjF4uzZszp58uTE476+PvX29io7O1t5eXlGwwEAAHdJuFh88803uueeeyYeNzQ0SJKqq6v17rvvGgsGAADcJ+FisX79ejmOMxtZAACAy3GNBQAAMIZiAQAAjKFYAAAAYygWAADAGIoFAAAwhmIBAACMoVgAAABjKBYAAMAYigUAADCGYgEAAIyhWAAAAGMoFgAAwJiEb0J2rS7dwCz+R3Sud52QixfmfGpmJP6Hx3aEKcXOJfd7LUnx8+dtR5iWWDT5fxeIn0v+uXTDPEpSPDX5b/gYiyb/MWhkNG47wrQk+3HoUr6pbkTqceb4VqW//PKLgsHgXO4SAAAYEolEtHTp0qs+P+fFIh6Pa2BgQH6/Xx7PtTfdkZERBYNBRSIRLViwwEDCGxdzaQ5zaQbzaA5zac6NOpeO42h0dFSBQEApKVdf9Zvz9f6UlJS/bDoztWDBghvqDZ5NzKU5zKUZzKM5zKU5N+JcZmVlTfkad3zQCAAAXIFiAQAAjHF9sfD5fNq5c6d8Pp/tKK7HXJrDXJrBPJrDXJrDXP61Ob94EwAAXL9cv2IBAACSB8UCAAAYQ7EAAADGUCwAAIAxri8We/fuVUFBgdLT01VSUqJDhw7ZjuQqzc3NuvPOO+X3+7V48WI9+OCD+umnn2zHui40NzfL4/Govr7edhRX+vXXX7Vx40YtXLhQmZmZuv3229Xd3W07lqtcvHhRL730kgoKCpSRkaFly5Zp165disfdce8Mmzo7O1VVVaVAICCPx6MDBw5Met5xHL388ssKBALKyMjQ+vXrdfz4cTthk4yri0V7e7vq6+vV2Nionp4erV27VpWVlerv77cdzTU6OjpUW1urr7/+WuFwWBcvXlRFRYXGxsZsR3O1rq4uhUIh3XbbbbajuNLvv/+uNWvWaN68efrss8/0ww8/6PXXX9fNN99sO5qrvPrqq9q3b59aW1v1448/as+ePXrttdf05ptv2o6W9MbGxrRy5Uq1trZe8fk9e/aopaVFra2t6urqUm5uru6//36Njo7OcdIk5LjYXXfd5dTU1EwaKyoqcrZv324pkfsNDQ05kpyOjg7bUVxrdHTUKSwsdMLhsLNu3Tqnrq7OdiTX2bZtm1NeXm47hutt2LDB2bx586Sxhx56yNm4caOlRO4kyfnoo48mHsfjcSc3N9d55ZVXJsbOnz/vZGVlOfv27bOQMLm4dsVifHxc3d3dqqiomDReUVGhI0eOWErlfsPDw5Kk7Oxsy0ncq7a2Vhs2bNB9991nO4prHTx4UKWlpXr44Ye1ePFirVq1Sm+//bbtWK5TXl6uL774QidOnJAkfffddzp8+LAeeOABy8ncra+vT4ODg5POPz6fT+vWreP8Iws3ITPl9OnTisViysnJmTSek5OjwcFBS6nczXEcNTQ0qLy8XMXFxbbjuNL777+vb7/9Vl1dXbajuNrPP/+strY2NTQ06MUXX9TRo0f13HPPyefz6amnnrIdzzW2bdum4eFhFRUVyev1KhaLaffu3Xr88cdtR3O1S+eYK51/Tp06ZSNSUnFtsbjk/9963XEcI7djvxFt3bpV33//vQ4fPmw7iitFIhHV1dXp888/V3p6uu04rhaPx1VaWqqmpiZJ0qpVq3T8+HG1tbVRLBLQ3t6u9957T/v379eKFSvU29ur+vp6BQIBVVdX247nepx/rsy1xWLRokXyer2XrU4MDQ1d1iIxtWeffVYHDx5UZ2fnrNzW/kbQ3d2toaEhlZSUTIzFYjF1dnaqtbVV0WhUXq/XYkL3WLJkiW655ZZJY8uXL9cHH3xgKZE7vfDCC9q+fbsee+wxSdKtt96qU6dOqbm5mWJxDXJzcyX9uXKxZMmSiXHOP39y7TUWaWlpKikpUTgcnjQeDodVVlZmKZX7OI6jrVu36sMPP9SXX36pgoIC25Fc695779WxY8fU29s7sZWWlurJJ59Ub28vpSIBa9asuexrzydOnFB+fr6lRO507tw5paRMPsx7vV6+bnqNCgoKlJubO+n8Mz4+ro6ODs4/cvGKhSQ1NDRo06ZNKi0t1erVqxUKhdTf36+amhrb0VyjtrZW+/fv18cffyy/3z+xApSVlaWMjAzL6dzF7/dfdm3K/PnztXDhQq5ZSdDzzz+vsrIyNTU16ZFHHtHRo0cVCoUUCoVsR3OVqqoq7d69W3l5eVqxYoV6enrU0tKizZs3246W9M6ePauTJ09OPO7r61Nvb6+ys7OVl5en+vp6NTU1qbCwUIWFhWpqalJmZqaeeOIJi6mThN0vpVy7t956y8nPz3fS0tKcO+64g69JJkjSFbd33nnHdrTrAl83nblPPvnEKS4udnw+n1NUVOSEQiHbkVxnZGTEqaurc/Ly8pz09HRn2bJlTmNjoxONRm1HS3pfffXVFY+N1dXVjuP8+ZXTnTt3Orm5uY7P53Puvvtu59ixY3ZDJwlumw4AAIxx7TUWAAAg+VAsAACAMRQLAABgDMUCAAAYQ7EAAADGUCwAAIAxFAsAAGAMxQIAABhDsQAAAMZQLAAAgDEUCwAAYAzFAgAAGPNvhwojSzrYUhcAAAAASUVORK5CYII=","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.imshow(inputs.detach().numpy())"]},{"cell_type":"markdown","id":"c9ea0b8c","metadata":{"papermill":{"duration":0.01228,"end_time":"2023-08-03T07:11:50.875821","exception":false,"start_time":"2023-08-03T07:11:50.863541","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","By human instincts we know that these $2$ words highle corresponds to each other\n","\n","But how can we make a machine understand this \n","\n","So how can we do this$...?$\n","\n","The whole concept, where `distinct words` of a `chunk of text` show some `focus`/`effect`/`attention` to `other words` is called `Self Attention`\n","\n","We do this by using $3$ $Major$ $Neural$ $Networks$. For making things more complicated we give them names\n","* $Query$ - What I am Looking for\n","* $Key$ - What I can offer\n","* $Value$ - What I actually offer(I was bluffing before)\n","\n","We will think of these as $3$ $Linear$ $Layers$\n","\n","We know that at the starting $Linear$ $Layers$ are just bunch of random numbers hanging out together like this\n","    \n","<img src = 'https://i.scdn.co/image/ab67616d0000b2732a517799858bf32fe736c2ca' width = 300>\n","\n","So lets just intialize some random $Linear$ $Layers$"]},{"cell_type":"markdown","id":"09337cd2","metadata":{"papermill":{"duration":0.011921,"end_time":"2023-08-03T07:11:50.900147","exception":false,"start_time":"2023-08-03T07:11:50.888226","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As we have $2$ characters, so our `sequence_len == 2`/`vocab_size == 2`"]},{"cell_type":"code","execution_count":6,"id":"87be3eb6","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:50.926165Z","iopub.status.busy":"2023-08-03T07:11:50.925786Z","iopub.status.idle":"2023-08-03T07:11:50.931525Z","shell.execute_reply":"2023-08-03T07:11:50.930765Z"},"papermill":{"duration":0.020961,"end_time":"2023-08-03T07:11:50.93345","exception":false,"start_time":"2023-08-03T07:11:50.912489","status":"completed"},"tags":[]},"outputs":[],"source":["sequence_len , vocab_size = 2 , 2\n","embed_layer = nn.Embedding(sequence_len , vocab_size)\n","\n","inputs = embed_layer(torch.tensor([0 , 1]))"]},{"cell_type":"code","execution_count":7,"id":"b3ee6a74","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:50.959736Z","iopub.status.busy":"2023-08-03T07:11:50.958976Z","iopub.status.idle":"2023-08-03T07:11:50.966274Z","shell.execute_reply":"2023-08-03T07:11:50.965535Z"},"papermill":{"duration":0.02293,"end_time":"2023-08-03T07:11:50.96844","exception":false,"start_time":"2023-08-03T07:11:50.94551","status":"completed"},"tags":[]},"outputs":[],"source":["queries = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)\n","keys = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)\n","values = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)"]},{"cell_type":"markdown","id":"9eb13a30","metadata":{"papermill":{"duration":0.011744,"end_time":"2023-08-03T07:11:50.992519","exception":false,"start_time":"2023-08-03T07:11:50.980775","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","So what we do is we simply multiply `queries` and `keys`"]},{"cell_type":"code","execution_count":8,"id":"c774980f","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.018589Z","iopub.status.busy":"2023-08-03T07:11:51.018173Z","iopub.status.idle":"2023-08-03T07:11:51.025402Z","shell.execute_reply":"2023-08-03T07:11:51.024669Z"},"papermill":{"duration":0.022857,"end_time":"2023-08-03T07:11:51.027425","exception":false,"start_time":"2023-08-03T07:11:51.004568","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.0895, 0.1060],\n","        [0.1281, 0.4218]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["queries * keys"]},{"cell_type":"markdown","id":"50577d89","metadata":{"papermill":{"duration":0.012545,"end_time":"2023-08-03T07:11:51.052804","exception":false,"start_time":"2023-08-03T07:11:51.040259","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","So why we did this$...?$\n","\n","Think it like this. We have to complete the sentence `He became ___ Universe`. Now we need to fill in the blank. Lets assume we have the information of future tokens. A model when searches for information in the back-tokens, it needs `He` to be highlighted. That what `queries * keys` do. When the \n","* Queries - What you want\n","* Key - What I can offer\n","\n","When these $2$(Question and answer) meet they show `high iffinity`. Thats why we multiply both of them\n","\n","But how can we get the index with `highest iffinity` $...?$\n","\n","One way is to do a `Softmax` on all of these"]},{"cell_type":"code","execution_count":9,"id":"63c5a660","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.080804Z","iopub.status.busy":"2023-08-03T07:11:51.079741Z","iopub.status.idle":"2023-08-03T07:11:51.091605Z","shell.execute_reply":"2023-08-03T07:11:51.090555Z"},"papermill":{"duration":0.028102,"end_time":"2023-08-03T07:11:51.093848","exception":false,"start_time":"2023-08-03T07:11:51.065746","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.4959, 0.5041],\n","        [0.4271, 0.5729]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["softmax = nn.Softmax()\n","\n","softmax(queries * keys)"]},{"cell_type":"markdown","id":"7c504abf","metadata":{"papermill":{"duration":0.012058,"end_time":"2023-08-03T07:11:51.118276","exception":false,"start_time":"2023-08-03T07:11:51.106218","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","But these values are very huge and thus can make big variations in the model, thus we will divide them with something"]},{"cell_type":"code","execution_count":10,"id":"63e52852","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.145251Z","iopub.status.busy":"2023-08-03T07:11:51.144624Z","iopub.status.idle":"2023-08-03T07:11:51.149527Z","shell.execute_reply":"2023-08-03T07:11:51.148753Z"},"papermill":{"duration":0.021065,"end_time":"2023-08-03T07:11:51.151591","exception":false,"start_time":"2023-08-03T07:11:51.130526","status":"completed"},"tags":[]},"outputs":[],"source":["weights = softmax((queries * keys) / keys.shape[-1])"]},{"cell_type":"markdown","id":"013de295","metadata":{"papermill":{"duration":0.012491,"end_time":"2023-08-03T07:11:51.176946","exception":false,"start_time":"2023-08-03T07:11:51.164455","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now this is kind of good \n","\n","We then multiply this with our `values` to get outputs"]},{"cell_type":"code","execution_count":11,"id":"a33899f6","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.203847Z","iopub.status.busy":"2023-08-03T07:11:51.203452Z","iopub.status.idle":"2023-08-03T07:11:51.217372Z","shell.execute_reply":"2023-08-03T07:11:51.216387Z"},"papermill":{"duration":0.02966,"end_time":"2023-08-03T07:11:51.21955","exception":false,"start_time":"2023-08-03T07:11:51.18989","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.6588, 0.5159],\n","        [0.6565, 0.5085]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["torch.matmul(weights , values)"]},{"cell_type":"markdown","id":"6b2a128c","metadata":{"papermill":{"duration":0.012349,"end_time":"2023-08-03T07:11:51.244389","exception":false,"start_time":"2023-08-03T07:11:51.23204","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","And these are our final output from `Self-Attention`."]},{"cell_type":"markdown","id":"e38e645e","metadata":{"papermill":{"duration":0.012343,"end_time":"2023-08-03T07:11:51.269541","exception":false,"start_time":"2023-08-03T07:11:51.257198","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#F2C464; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #F2C464\">2 | Multi Head Attention 🧠‍🧠‍🧠</p>\n","\n","<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","What we did is a implimaentation of `Single Head`. We use multiple heads to gather multiple information of the corpus\n","\n","So how do we handle `Multiple Heads`$...?$\n","\n","Assume we have the same sentence but this time we have increased our Output of Embedding Layer"]},{"cell_type":"code","execution_count":12,"id":"8f104be6","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.296989Z","iopub.status.busy":"2023-08-03T07:11:51.296627Z","iopub.status.idle":"2023-08-03T07:11:51.304716Z","shell.execute_reply":"2023-08-03T07:11:51.30372Z"},"papermill":{"duration":0.024373,"end_time":"2023-08-03T07:11:51.306876","exception":false,"start_time":"2023-08-03T07:11:51.282503","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[ 1.3944,  0.4526, -0.5583, -0.3978, -0.7806,  1.1587, -0.0141, -0.4937,\n","         -0.4388,  0.5218],\n","        [ 0.5472, -1.4818,  1.2683,  1.7026,  0.3606, -0.2355,  0.7674, -0.7715,\n","          0.3193,  0.9241]], grad_fn=<EmbeddingBackward0>)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["Embedding_Layer = nn.Embedding(2 , 10)\n","\n","inputs = Embedding_Layer(torch.tensor([0 , 1]))\n","inputs"]},{"cell_type":"markdown","id":"dd0dd50d","metadata":{"papermill":{"duration":0.013133,"end_time":"2023-08-03T07:11:51.33367","exception":false,"start_time":"2023-08-03T07:11:51.320537","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets assume we are making $5$ Heads. \n","\n","What we do is we break this matrix into $5$ parts and then seperately work on them. Lets assume the indices of our matrix is like\n","```\n","[(0 , 0) , (0 , 1) , (0 , 2) , (0 , 3) , (0 , 4) , (0 , 5) , (0 , 6) , (0 , 7) , (0 , 8) , (0 , 9) , \n","(1 , 0) , (1 , 1) , (1 , 2) , (1 , 3) , (1 , 4) , (1 , 5) , (1 , 6) , (1 , 7) , (1 . 8) , (1 , 9)]\n","```\n","By breaking it in $5$ parts \n","```\n","[(0 , 0) , (0 , 1) , \n","(1 , 0) , (1 , 1)]\n","\n","[(0 , 2) , (0 , 3) ,\n","(1 , 2) , (1 , 3)]\n","\n","[(0 , 4) , (0 , 5) ,\n","(1 , 4) , (1 , 5)]\n","\n","[(0 , 6) , (0 , 7) ,\n","(1 , 6) , (1 , 7)]\n","\n","[(0 , 8) , (0 , 9) , \n","(1 . 8) , (1 , 9)]\n","```\n","\n","So how do we do this$...?$\n","\n","One way is to make $5$ different `Linear Layers` and compute them, which can be expensive\n","\n","One way is somehow we can break this thing up, pass into Neural Networks and then re-concatenate them. This can be computationaly expensive "]},{"cell_type":"markdown","id":"246d12ef","metadata":{"papermill":{"duration":0.012993,"end_time":"2023-08-03T07:11:51.359909","exception":false,"start_time":"2023-08-03T07:11:51.346916","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","First we will `reshape` this array"]},{"cell_type":"code","execution_count":13,"id":"4e1cae9b","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.388035Z","iopub.status.busy":"2023-08-03T07:11:51.387593Z","iopub.status.idle":"2023-08-03T07:11:51.395371Z","shell.execute_reply":"2023-08-03T07:11:51.394601Z"},"papermill":{"duration":0.023848,"end_time":"2023-08-03T07:11:51.397324","exception":false,"start_time":"2023-08-03T07:11:51.373476","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[[[ 1.3944,  0.4526],\n","          [-0.5583, -0.3978],\n","          [-0.7806,  1.1587],\n","          [-0.0141, -0.4937],\n","          [-0.4388,  0.5218]],\n","\n","         [[ 0.5472, -1.4818],\n","          [ 1.2683,  1.7026],\n","          [ 0.3606, -0.2355],\n","          [ 0.7674, -0.7715],\n","          [ 0.3193,  0.9241]]]], grad_fn=<ReshapeAliasBackward0>)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["inputs = torch.reshape(inputs, (1, 2 , 5 , 2))\n","inputs"]},{"cell_type":"markdown","id":"9d4c8cf0","metadata":{"papermill":{"duration":0.012815,"end_time":"2023-08-03T07:11:51.42364","exception":false,"start_time":"2023-08-03T07:11:51.410825","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we need to `permute` this "]},{"cell_type":"code","execution_count":14,"id":"0f293de1","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.453445Z","iopub.status.busy":"2023-08-03T07:11:51.45301Z","iopub.status.idle":"2023-08-03T07:11:51.46178Z","shell.execute_reply":"2023-08-03T07:11:51.460669Z"},"papermill":{"duration":0.026518,"end_time":"2023-08-03T07:11:51.463897","exception":false,"start_time":"2023-08-03T07:11:51.437379","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[[[ 1.3944,  0.4526]],\n","\n","         [[ 0.5472, -1.4818]]],\n","\n","\n","        [[[-0.5583, -0.3978]],\n","\n","         [[ 1.2683,  1.7026]]],\n","\n","\n","        [[[-0.7806,  1.1587]],\n","\n","         [[ 0.3606, -0.2355]]],\n","\n","\n","        [[[-0.0141, -0.4937]],\n","\n","         [[ 0.7674, -0.7715]]],\n","\n","\n","        [[[-0.4388,  0.5218]],\n","\n","         [[ 0.3193,  0.9241]]]], grad_fn=<PermuteBackward0>)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["inputs = inputs.permute(2 , 1 , 0 , 3)\n","inputs"]},{"cell_type":"markdown","id":"d3ff4411","metadata":{"papermill":{"duration":0.013093,"end_time":"2023-08-03T07:11:51.491099","exception":false,"start_time":"2023-08-03T07:11:51.478006","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","And this is the same as we wanted"]},{"cell_type":"markdown","id":"26cea2ec","metadata":{"papermill":{"duration":0.013037,"end_time":"2023-08-03T07:11:51.517696","exception":false,"start_time":"2023-08-03T07:11:51.504659","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets now start connecting things up \n","\n","<img src = 'https://production-media.paperswithcode.com/methods/Screen_Shot_2020-07-08_at_12.17.05_AM_st5S0XV.png' width = 400>\n","\n","* We first intialize $3$ $Linear$ $Layers$ \n","* * $Query$ - What I am looking for\n","* * $Key$ - What I can offer\n","* * $Values$ - What I actually offer\n","* We pass the $Query$ and $Keys$ into a dot product\n","* We then calculate the softmax of the product\n","* Then we dot product with $Values$\n","* Then we concatenate \n","* (We have left the Linear Layers for this time)\n","\n","We do the same thing for a number of heads"]},{"cell_type":"markdown","id":"31613068","metadata":{"papermill":{"duration":0.013046,"end_time":"2023-08-03T07:11:51.544559","exception":false,"start_time":"2023-08-03T07:11:51.531513","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF69B4; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF69B4\">3 | Mutli Head Self Attention Class 🌎</p>\n","\n","<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<IMG SRC = 'https://cleanmemes.files.wordpress.com/2014/10/35multiheaddog1.jpg?w=640' WIDTH = 400>\n","    \n","Now lets just make a simple class for this\n","    \n","A really great explanantion to the code by **[Hugging Chat](https://huggingface.co/chat/)**\n","\n","### __init__\n","```\n","def __init__(self , vocab_size , num_heads):\n","\n","    super(MultiHeadSelfAttention , self).__init__()\n","\n","    self.num_heads = num_heads\n","    self.vocab_size = vocab_size\n","\n","    self.queries = nn.Linear(self.vocab_size , self.vocab_size)\n","    self.keys = nn.Linear(self.vocab_size , self.vocab_size)\n","    self.values = nn.Linear(self.vocab_size , self.vocab_size)\n","\n","    self.softmax = torch.nn.Softmax()\n","```\n","\n","The `Constructor` takes two arguments\n","* $Vocablary$ $Size$ `vocab_size` - Size of the Vocablury\n","* $Number$ $of$ $Heads$ `num_heads`\n","\n","It `initializes` the `instance variables` `num_heads`/`vocab_size`, and $3$ $Linear$ $Layers$ - `queries`/`keys`/`values`. The linear layers have a `single hidden layer` with a `dimensionality` of `vocab_size`.\n","\n","### Split Heads\n","```\n","def split_heads(self , gate):\n","\n","#         batch_size = gate.shape[0]\n","\n","    split_gates = torch.reshape(gate, (1 , \n","                                    self.num_heads , \n","                                    int(self.vocab_size / self.num_heads) , \n","                                    self.num_heads)).permute(2 , 1 , 0 , 3)\n","\n","    return split_gates\n","```\n","\n","This method takes a `gate` `(a tensor of shape (batch_size, vocab_size))` and `splits` it into `multiple heads`, each with a `size` of `(batch_size, vocab_size // num_heads)`. It does this by `reshaping` the gate into a $4D$ `tensor`, `permuting the dimensions`, and then `splitting` it along the `second dimension`.\n","\n","### Forward\n","```\n","def forward(self , key , query , value , mask = None):\n","\n","    query_output = self.queries(query)\n","    key_output = self.keys(key)\n","    value_output = self.values(value)\n","\n","    query_output = self.split_heads(query_output)\n","    key_output = self.split_heads(key_output)\n","    value_output = self.split_heads(value_output)\n","\n","    attention = (query_output * key_output) / (key_output.shape[-1] ** (1/2)) \n","\n","    if mask : attention = tf.where(mask == 0 , float('-inf') , attention)\n","\n","    weights = self.softmax(attention)\n","    weights = torch.reshape(weights , (weights.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                       self.num_heads , self.num_heads))\n","    value_output = torch.reshape(value_output , (value_output.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                                 self.num_heads , self.num_heads))\n","    output = torch.matmul(weights , value_output)\n","\n","    output = torch.reshape(output , (self.num_heads , self.vocab_size))\n","\n","    return output , weights\n","```\n","\n","This `method` `computes` the `attention scores` and `outputs` the final output. It takes four arguments - `key`/`query`/`value`/`mask` (an optional binary mask indicating which elements should be ignored).\n","* `Pass` the `query`/`key`/`value` tensors through their `corresponding linear layers` to get the `query`/`key`/`value` `embeddings`.\n","* `Split` the `query`/`key` `embeddings` into `multiple heads` using the `split_heads method`.\n","* `Compute` the `attention` scores by taking the `dot product` of the `query`/`key` `embeddings` and `dividing` the result by the `square root` of the `key embedding's dimensionality`.\n","* If a `mask` is `provided`, `zero` out the `attention scores` for the `masked elements`.\n","* `Apply` a `Softmax function` to the `attention scores` to get the weights.\n","* `Compute` the `output` by taking the `weighted sum` of the `value embeddings` using the weights computed earlier.\n","* `Reshape` the `output tensor` to have the `original vocabulary size`."]},{"cell_type":"code","execution_count":15,"id":"7023d66c","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.573629Z","iopub.status.busy":"2023-08-03T07:11:51.572964Z","iopub.status.idle":"2023-08-03T07:11:51.587753Z","shell.execute_reply":"2023-08-03T07:11:51.586538Z"},"papermill":{"duration":0.032011,"end_time":"2023-08-03T07:11:51.590053","exception":false,"start_time":"2023-08-03T07:11:51.558042","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiHeadSelfAttention(nn.Module):\n","    \n","    def __init__(self , vocab_size , num_heads):\n","        \n","        super(MultiHeadSelfAttention , self).__init__()\n","    \n","        self.num_heads = num_heads\n","        self.vocab_size = vocab_size\n","        \n","        self.queries = nn.Linear(self.vocab_size , self.vocab_size)\n","        self.keys = nn.Linear(self.vocab_size , self.vocab_size)\n","        self.values = nn.Linear(self.vocab_size , self.vocab_size)\n","        \n","        self.softmax = torch.nn.Softmax()\n","        \n","    def split_heads(self , gate):\n","        \n","#         batch_size = gate.shape[0]\n","        \n","        split_gates = torch.reshape(gate, (1 , # -----> batch_size \n","                                        self.num_heads , \n","                                        int(self.vocab_size / self.num_heads) , \n","                                        self.num_heads)).permute(2 , 1 , 0 , 3)\n","        \n","        return split_gates\n","    \n","    def forward(self , key , query , value , mask = None):\n","        \n","        query_output = self.queries(query)\n","        key_output = self.keys(key)\n","        value_output = self.values(value)\n","\n","        query_output = self.split_heads(query_output)\n","        key_output = self.split_heads(key_output)\n","        value_output = self.split_heads(value_output)\n","\n","        attention = (query_output * key_output) / (key_output.shape[-1] ** (1/2)) \n","        \n","        if mask : attention = tf.where(mask == 0 , float('-inf') , attention)\n","\n","        weights = self.softmax(attention)\n","        weights = torch.reshape(weights , (weights.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                           self.num_heads , self.num_heads))\n","        value_output = torch.reshape(value_output , (value_output.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                                     self.num_heads , self.num_heads))\n","        output = torch.matmul(weights , value_output)\n","        \n","        output = torch.reshape(output , (self.num_heads , self.vocab_size))\n","\n","        return output , weights"]},{"cell_type":"markdown","id":"dfa267b6","metadata":{"execution":{"iopub.execute_input":"2023-08-02T15:01:59.721131Z","iopub.status.busy":"2023-08-02T15:01:59.720628Z","iopub.status.idle":"2023-08-02T15:01:59.73755Z","shell.execute_reply":"2023-08-02T15:01:59.736092Z","shell.execute_reply.started":"2023-08-02T15:01:59.721095Z"},"papermill":{"duration":0.012991,"end_time":"2023-08-03T07:11:51.616571","exception":false,"start_time":"2023-08-03T07:11:51.60358","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","If we pass a sample input like this "]},{"cell_type":"code","execution_count":16,"id":"0623b074","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.644802Z","iopub.status.busy":"2023-08-03T07:11:51.644413Z","iopub.status.idle":"2023-08-03T07:11:51.666176Z","shell.execute_reply":"2023-08-03T07:11:51.665402Z"},"papermill":{"duration":0.038371,"end_time":"2023-08-03T07:11:51.668317","exception":false,"start_time":"2023-08-03T07:11:51.629946","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[ 0.4862,  0.1052,  0.4948,  0.1071, -0.4120, -0.3251, -0.4405, -0.3091,\n","           0.2622,  0.4089],\n","         [ 0.1556,  0.3888,  0.4309, -0.2600,  0.2488, -0.1046,  0.5554, -0.5310,\n","           0.7257, -0.6390]], grad_fn=<ReshapeAliasBackward0>),\n"," tensor([[[[0.4912, 0.4673],\n","           [0.5088, 0.5327]],\n"," \n","          [[0.5360, 0.4771],\n","           [0.4640, 0.5229]],\n"," \n","          [[0.4938, 0.6754],\n","           [0.5062, 0.3246]],\n"," \n","          [[0.7153, 0.6164],\n","           [0.2847, 0.3836]],\n"," \n","          [[0.4096, 0.4856],\n","           [0.5904, 0.5144]]]], grad_fn=<ReshapeAliasBackward0>))"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["mhsa = MultiHeadSelfAttention(vocab_size = 10 , num_heads = 2)\n","inputs = Embedding_Layer(torch.tensor([0 , 1]))\n","mhsa(inputs , inputs , inputs , None)"]},{"cell_type":"markdown","id":"b73a61fe","metadata":{"papermill":{"duration":0.012936,"end_time":"2023-08-03T07:11:51.695105","exception":false,"start_time":"2023-08-03T07:11:51.682169","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","What we just made is the small part in this diagram\n","\n","$Multi$ $Head$ $Self$ $Attention$ (Orange Part )\n","\n","<img src = 'https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png' width = 300>"]},{"cell_type":"markdown","id":"a7469838","metadata":{"papermill":{"duration":0.01323,"end_time":"2023-08-03T07:11:51.721919","exception":false,"start_time":"2023-08-03T07:11:51.708689","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF0000; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF0000\">4 | Encoder Block</p>\n","\n","<div style=\"border-radius:10px; border:#FF0000 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","### __init__\n","```\n","def __init__(self , vocab_size , num_heads):\n","\n","    super(Encoder , self).__init__()\n","\n","    self.vocab_size = vocab_size\n","    self.num_heads = num_heads\n","\n","    self.mhsa = MultiHeadSelfAttention(self.vocab_size , self.num_heads)\n","\n","    self.layer_norm_1 = nn.LayerNorm(self.vocab_size)\n","    self.layer_norm_2 = nn.LayerNorm(self.vocab_size)\n","\n","    self.dropout_1 = nn.Dropout(0.05)\n","    self.dropout_2 = nn.Dropout(0.05)\n","\n","    self.linear_1 = nn.Linear(self.vocab_size , self.vocab_size)\n","```\n","\n","The `constructor` function takes $2$ `arguments`\n","* $Vocabluray$ $Size$ `vocab_size` - size of the vocablury\n","* $Num$ $Heads$ `num_heads` - number of heads\n","\n","It then creates the following layers\n","* $Multi$ $Heads$ $Self$ $Attention$ `mhsa` layer with the `vocab_size` and `num_heads` parameters. \n","* $Layer$ $Normalization$ `layer_norm_1`/`layer_norm_2`  with the same dimension as the `vocab_size`. \n","* $Droput$ `dropout_1`/`dropout_2` with a `dropout rate` of $0.05$. \n","* $Linaer$ `linear_1` with an `input dimension` equal to the `vocab_size` and an `output dimension` also equal to the `vocab_size`\n","\n","### Forward \n","```\n","def forward(self , inps):\n","\n","    attention , weights = self.mhsa(inps , inps , inps , mask = None)\n","\n","    attention = self.dropout_1(attention)\n","    attention = self.layer_norm_1(inps + attention)\n","\n","    linear_attention = self.linear_1(attention)\n","\n","    linear_attention = self.layer_norm_2(linear_attention)\n","    attention = self.dropout_2(linear_attention + attention)\n","\n","    return attention , weights\n","```\n","The `forward function` takes an `input tensor inps` and passes it through the `MultiHeadSelfAttention layer`=>, $2$ `Layer Normalization layers` => $2$ `Dropout layers` => `Linear layer`"]},{"cell_type":"code","execution_count":17,"id":"4170d9ea","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.753175Z","iopub.status.busy":"2023-08-03T07:11:51.752526Z","iopub.status.idle":"2023-08-03T07:11:51.762532Z","shell.execute_reply":"2023-08-03T07:11:51.761593Z"},"papermill":{"duration":0.029031,"end_time":"2023-08-03T07:11:51.76478","exception":false,"start_time":"2023-08-03T07:11:51.735749","status":"completed"},"tags":[]},"outputs":[],"source":["class Encoder(nn.Module):\n","    \n","    def __init__(self , vocab_size , num_heads):\n","        \n","        super(Encoder , self).__init__()\n","        \n","        self.vocab_size = vocab_size\n","        self.num_heads = num_heads\n","        \n","        self.mhsa = MultiHeadSelfAttention(self.vocab_size , self.num_heads)\n","        \n","        self.layer_norm_1 = nn.LayerNorm(self.vocab_size)\n","        self.layer_norm_2 = nn.LayerNorm(self.vocab_size)\n","        \n","        self.dropout_1 = nn.Dropout(0.05)\n","        self.dropout_2 = nn.Dropout(0.05)\n","        \n","        self.linear_1 = nn.Linear(self.vocab_size , self.vocab_size)\n","        \n","    def forward(self , inps):\n","        \n","        attention , weights = self.mhsa(inps , inps , inps , mask = None)\n","\n","        attention = self.dropout_1(attention)\n","        attention = self.layer_norm_1(inps + attention)\n","        \n","        linear_attention = self.linear_1(attention)\n","        \n","        linear_attention = self.layer_norm_2(linear_attention)\n","        attention = self.dropout_2(linear_attention + attention)\n","        \n","        return attention , weights "]},{"cell_type":"code","execution_count":18,"id":"28ae3d80","metadata":{"execution":{"iopub.execute_input":"2023-08-03T07:11:51.795695Z","iopub.status.busy":"2023-08-03T07:11:51.794568Z","iopub.status.idle":"2023-08-03T07:11:51.818108Z","shell.execute_reply":"2023-08-03T07:11:51.817101Z"},"papermill":{"duration":0.041135,"end_time":"2023-08-03T07:11:51.820126","exception":false,"start_time":"2023-08-03T07:11:51.778991","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[ 1.5637,  1.0619,  0.4790, -2.6777, -0.0883,  0.6342, -1.1792, -0.5177,\n","          -0.9047,  1.6289],\n","         [-0.7144, -3.1763,  0.5627,  2.7788,  0.2011, -2.0062,  0.0000, -2.5095,\n","           1.2002,  2.3786]], grad_fn=<MulBackward0>),\n"," tensor([[[[0.5262, 0.5035],\n","           [0.4738, 0.4965]],\n"," \n","          [[0.4614, 0.3551],\n","           [0.5386, 0.6449]],\n"," \n","          [[0.5475, 0.4952],\n","           [0.4525, 0.5048]],\n"," \n","          [[0.4697, 0.4036],\n","           [0.5303, 0.5964]],\n"," \n","          [[0.4279, 0.4949],\n","           [0.5721, 0.5051]]]], grad_fn=<ReshapeAliasBackward0>))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["Enc = Encoder(vocab_size = 10 , num_heads = 2)\n","Enc(inputs)"]},{"cell_type":"markdown","id":"a51840a1","metadata":{"papermill":{"duration":0.012748,"end_time":"2023-08-03T07:11:51.84629","exception":false,"start_time":"2023-08-03T07:11:51.833542","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF0000 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","What we just did was this \n","\n","<img src = 'https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-13.png' width = 400>"]},{"cell_type":"markdown","id":"cff4b6ab","metadata":{"papermill":{"duration":0.013384,"end_time":"2023-08-03T07:11:51.87351","exception":false,"start_time":"2023-08-03T07:11:51.860126","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#E77200; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #E77200\">5 | TO DO LIST 📑</p>\n","\n","<div style=\"border-radius:10px; border:#E77200 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","* $TO$ $DO$ $1$ $:$ $MAKE$ $ENCODER$ $BLOCK$\n","* $TO$ $DO$ $2$ $:$ $MAKE$ $DECODER$ $BLOCK$\n","* $TO$ $DO$ $3$ $:$ $MAKE$ $TRANSFORER$ $BLOCK$\n","* $TO$ $DO$ $4$ $:$ $TRAIN$ $TRANSFORER$\n","* $TO$ $DO$ $5$ $:$ $DANCE$"]},{"cell_type":"markdown","id":"0da78d8a","metadata":{"papermill":{"duration":0.013222,"end_time":"2023-08-03T07:11:51.900321","exception":false,"start_time":"2023-08-03T07:11:51.887099","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF9980; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF9980\">6 | Ending 🎭</p>\n","\n","<div style=\"border-radius:10px; border:#FF9980 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","**THAT IT FOR TODAY GUYS**\n","\n","**WE WILL GO DEEPER INTO THE DATA IN THE UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT YOUR THOUGHTS, HIHGLY APPRICIATED**\n","\n","**DONT FORGET TO MAKE AN UPVOTE, IF YOU LIKED MY WORK $:)$**\n","    \n","<img src = \"https://i.imgflip.com/19aadg.jpg\">\n","    \n","**PEACE OUT $!!!$**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":17.235909,"end_time":"2023-08-03T07:11:53.136721","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-08-03T07:11:35.900812","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}