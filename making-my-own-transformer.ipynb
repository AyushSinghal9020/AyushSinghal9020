{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/making-my-own-transformer?scriptVersionId=138745290\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"de3f4b28","metadata":{"papermill":{"duration":0.013716,"end_time":"2023-08-03T03:28:37.066016","exception":false,"start_time":"2023-08-03T03:28:37.0523","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#00B9F7; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #00B9F7\">Transformers</p>"]},{"cell_type":"code","execution_count":1,"id":"cd5a0291","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-08-03T03:28:37.089824Z","iopub.status.busy":"2023-08-03T03:28:37.089265Z","iopub.status.idle":"2023-08-03T03:28:37.103376Z","shell.execute_reply":"2023-08-03T03:28:37.102316Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.028888,"end_time":"2023-08-03T03:28:37.105851","exception":false,"start_time":"2023-08-03T03:28:37.076963","status":"completed"},"tags":[]},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"cde8e587","metadata":{"papermill":{"duration":0.011241,"end_time":"2023-08-03T03:28:37.127993","exception":false,"start_time":"2023-08-03T03:28:37.116752","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00B9F7 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = 'https://media.tenor.com/LStfD5yI5SsAAAAC/transformers-darkofthemoon.gif'>\n","    \n","## So what the hell is this **`Transformers`** $...?$\n","    \n","Yes we have been asking this question from an whole eternity. When we search on $Google$/or any other search engine, we find the same answer\n","```\n","A transformer is a type of neural network architecture that is blah blah blah blah\n","```\n","But what it actually is and why do we even need this \n","    \n","<img src = 'https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png' width = 400>"]},{"cell_type":"markdown","id":"818539a5","metadata":{"papermill":{"duration":0.010408,"end_time":"2023-08-03T03:28:37.14953","exception":false,"start_time":"2023-08-03T03:28:37.139122","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#8E24AA; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #8E24AA\">1 | Self Attention üëÄ</p>"]},{"cell_type":"code","execution_count":2,"id":"78088771","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:37.172376Z","iopub.status.busy":"2023-08-03T03:28:37.171996Z","iopub.status.idle":"2023-08-03T03:28:40.937943Z","shell.execute_reply":"2023-08-03T03:28:40.936755Z"},"papermill":{"duration":3.780663,"end_time":"2023-08-03T03:28:40.940791","exception":false,"start_time":"2023-08-03T03:28:37.160128","status":"completed"},"tags":[]},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","id":"a2a1acac","metadata":{"papermill":{"duration":0.012076,"end_time":"2023-08-03T03:28:40.96375","exception":false,"start_time":"2023-08-03T03:28:40.951674","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<IMG SRC = 'https://media.tenor.com/AleRU5nZSasAAAAC/attention-notice-me.gif' WIDTH = 400>\n","    \n","Society says that the best way to understand `Transformer Architechture`, is to first understand `Self-Attention Mechanism`. \n","\n","I dont know who are the actual people in society, and why do these people do not show up individually, why they cover up themselves with the word `Society`\n","\n","**LEAVE IT !!!**\n","\n","Lets assume we have this sentence `Radhe Krishn`\n","\n","Lets assume we pass this to an `Embedding Layer` to get `Embeddings`. These `Embeddings` will be `Random`, but lets dive it in "]},{"cell_type":"code","execution_count":3,"id":"e44671c0","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:40.987516Z","iopub.status.busy":"2023-08-03T03:28:40.986563Z","iopub.status.idle":"2023-08-03T03:28:41.028719Z","shell.execute_reply":"2023-08-03T03:28:41.027599Z"},"papermill":{"duration":0.057032,"end_time":"2023-08-03T03:28:41.031561","exception":false,"start_time":"2023-08-03T03:28:40.974529","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Embedding(2, 12)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["Embedding_Layer = nn.Embedding(2 , 12)\n","Embedding_Layer"]},{"cell_type":"markdown","id":"0da1cf54","metadata":{"papermill":{"duration":0.010786,"end_time":"2023-08-03T03:28:41.053324","exception":false,"start_time":"2023-08-03T03:28:41.042538","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As our corpus only consists of $2$ distinct words, we can label them as `[0,1]`\n","\n","Passing this to an Embedding Layer, "]},{"cell_type":"code","execution_count":4,"id":"79891f57","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:41.077002Z","iopub.status.busy":"2023-08-03T03:28:41.076367Z","iopub.status.idle":"2023-08-03T03:28:41.169937Z","shell.execute_reply":"2023-08-03T03:28:41.168924Z"},"papermill":{"duration":0.107995,"end_time":"2023-08-03T03:28:41.17211","exception":false,"start_time":"2023-08-03T03:28:41.064115","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[ 0.2470,  0.9079, -0.5475, -2.2082, -0.4687,  1.4864,  1.4017,  0.1217,\n","          -0.5274, -0.2559, -0.0345,  0.7122],\n","         [ 0.0638, -0.1584,  0.6136,  1.3810,  0.1499,  0.2394,  1.6117,  0.4893,\n","          -0.9418, -0.8806,  0.4990,  2.0161]], grad_fn=<EmbeddingBackward0>),\n"," torch.Size([2, 12]))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["inputs = Embedding_Layer(torch.tensor([0 , 1] , dtype = torch.long))\n","inputs , inputs.shape"]},{"cell_type":"markdown","id":"d7e64886","metadata":{"papermill":{"duration":0.010722,"end_time":"2023-08-03T03:28:41.194073","exception":false,"start_time":"2023-08-03T03:28:41.183351","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Suppose we could be able to know, how much these words affect each other "]},{"cell_type":"code","execution_count":5,"id":"11475cf4","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-08-03T03:28:41.217831Z","iopub.status.busy":"2023-08-03T03:28:41.217389Z","iopub.status.idle":"2023-08-03T03:28:41.484427Z","shell.execute_reply":"2023-08-03T03:28:41.482958Z"},"papermill":{"duration":0.281843,"end_time":"2023-08-03T03:28:41.486969","exception":false,"start_time":"2023-08-03T03:28:41.205126","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x7dd97a9dfd60>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.imshow(inputs.detach().numpy())"]},{"cell_type":"markdown","id":"a0e7cbea","metadata":{"papermill":{"duration":0.011102,"end_time":"2023-08-03T03:28:41.509715","exception":false,"start_time":"2023-08-03T03:28:41.498613","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","By human instincts we know that these $2$ words highle corresponds to each other\n","\n","But how can we make a machine understand this \n","\n","So how can we do this$...?$\n","\n","The whole concept, where `distinct words` of a `chunk of text` show some `focus`/`effect`/`attention` to `other words` is called `Self Attention`\n","\n","We do this by using $3$ $Major$ $Neural$ $Networks$. For making things more complicated we give them names\n","* $Query$ - What I am Looking for\n","* $Key$ - What I can offer\n","* $Value$ - What I actually offer(I was bluffing before)\n","\n","We will think of these as $3$ $Linear$ $Layers$\n","\n","We know that at the starting $Linear$ $Layers$ are just bunch of random numbers hanging out together like this\n","    \n","<img src = 'https://i.scdn.co/image/ab67616d0000b2732a517799858bf32fe736c2ca' width = 300>\n","\n","So lets just intialize some random $Linear$ $Layers$"]},{"cell_type":"markdown","id":"53fb3c36","metadata":{"papermill":{"duration":0.011109,"end_time":"2023-08-03T03:28:41.532143","exception":false,"start_time":"2023-08-03T03:28:41.521034","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As we have $2$ characters, so our `sequence_len == 2`/`vocab_size == 2`"]},{"cell_type":"code","execution_count":6,"id":"3ec42042","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:41.556459Z","iopub.status.busy":"2023-08-03T03:28:41.556037Z","iopub.status.idle":"2023-08-03T03:28:41.562892Z","shell.execute_reply":"2023-08-03T03:28:41.561892Z"},"papermill":{"duration":0.021747,"end_time":"2023-08-03T03:28:41.565303","exception":false,"start_time":"2023-08-03T03:28:41.543556","status":"completed"},"tags":[]},"outputs":[],"source":["sequence_len , vocab_size = 2 , 2\n","embed_layer = nn.Embedding(sequence_len , vocab_size)\n","\n","inputs = embed_layer(torch.tensor([0 , 1]))"]},{"cell_type":"code","execution_count":7,"id":"05bbbc3c","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:41.590143Z","iopub.status.busy":"2023-08-03T03:28:41.589764Z","iopub.status.idle":"2023-08-03T03:28:41.597767Z","shell.execute_reply":"2023-08-03T03:28:41.596705Z"},"papermill":{"duration":0.022901,"end_time":"2023-08-03T03:28:41.600225","exception":false,"start_time":"2023-08-03T03:28:41.577324","status":"completed"},"tags":[]},"outputs":[],"source":["queries = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)\n","keys = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)\n","values = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)"]},{"cell_type":"markdown","id":"86bd97b0","metadata":{"papermill":{"duration":0.011418,"end_time":"2023-08-03T03:28:41.623669","exception":false,"start_time":"2023-08-03T03:28:41.612251","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","So what we do is we simply multiply `queries` and `keys`"]},{"cell_type":"code","execution_count":8,"id":"ec4e20ba","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:41.648783Z","iopub.status.busy":"2023-08-03T03:28:41.648322Z","iopub.status.idle":"2023-08-03T03:28:41.656829Z","shell.execute_reply":"2023-08-03T03:28:41.655635Z"},"papermill":{"duration":0.023553,"end_time":"2023-08-03T03:28:41.659226","exception":false,"start_time":"2023-08-03T03:28:41.635673","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.0796, 0.6294],\n","        [0.3020, 0.0793]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["queries * keys"]},{"cell_type":"markdown","id":"783f6125","metadata":{"papermill":{"duration":0.011078,"end_time":"2023-08-03T03:28:41.681831","exception":false,"start_time":"2023-08-03T03:28:41.670753","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","So why we did this$...?$\n","\n","Think it like this. We have to complete the sentence `He became ___ Universe`. Now we need to fill in the blank. Lets assume we have the information of future tokens. A model when searches for information in the back-tokens, it needs `He` to be highlighted. That what `queries * keys` do. When the \n","* Queries - What you want\n","* Key - What I can offer\n","\n","When these $2$(Question and answer) meet they show `high iffinity`. Thats why we multiply both of them\n","\n","But how can we get the index with `highest iffinity` $...?$\n","\n","One way is to do a `Softmax` on all of these"]},{"cell_type":"code","execution_count":9,"id":"25f232cc","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:41.706388Z","iopub.status.busy":"2023-08-03T03:28:41.705981Z","iopub.status.idle":"2023-08-03T03:28:41.719256Z","shell.execute_reply":"2023-08-03T03:28:41.718271Z"},"papermill":{"duration":0.02813,"end_time":"2023-08-03T03:28:41.721375","exception":false,"start_time":"2023-08-03T03:28:41.693245","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.3659, 0.6341],\n","        [0.5554, 0.4446]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["softmax = nn.Softmax()\n","\n","softmax(queries * keys)"]},{"cell_type":"markdown","id":"8e0d8545","metadata":{"papermill":{"duration":0.011237,"end_time":"2023-08-03T03:28:41.74416","exception":false,"start_time":"2023-08-03T03:28:41.732923","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","But these values are very huge and thus can make big variations in the model, thus we will divide them with something"]},{"cell_type":"code","execution_count":10,"id":"734f589a","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:41.769238Z","iopub.status.busy":"2023-08-03T03:28:41.768532Z","iopub.status.idle":"2023-08-03T03:28:41.773229Z","shell.execute_reply":"2023-08-03T03:28:41.772377Z"},"papermill":{"duration":0.019554,"end_time":"2023-08-03T03:28:41.77527","exception":false,"start_time":"2023-08-03T03:28:41.755716","status":"completed"},"tags":[]},"outputs":[],"source":["weights = softmax((queries * keys) / keys.shape[-1])"]},{"cell_type":"markdown","id":"b6fa2bae","metadata":{"papermill":{"duration":0.01106,"end_time":"2023-08-03T03:28:41.797931","exception":false,"start_time":"2023-08-03T03:28:41.786871","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now this is kind of good \n","\n","We then multiply this with our `values` to get outputs"]},{"cell_type":"code","execution_count":11,"id":"31339517","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:41.82323Z","iopub.status.busy":"2023-08-03T03:28:41.822076Z","iopub.status.idle":"2023-08-03T03:28:41.838368Z","shell.execute_reply":"2023-08-03T03:28:41.837228Z"},"papermill":{"duration":0.031499,"end_time":"2023-08-03T03:28:41.840903","exception":false,"start_time":"2023-08-03T03:28:41.809404","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.7036, 0.2934],\n","        [0.6978, 0.2552]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["torch.matmul(weights , values)"]},{"cell_type":"markdown","id":"91d31ec0","metadata":{"papermill":{"duration":0.011877,"end_time":"2023-08-03T03:28:41.864775","exception":false,"start_time":"2023-08-03T03:28:41.852898","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","And these are our final output from `Self-Attention`."]},{"cell_type":"markdown","id":"240346a1","metadata":{"papermill":{"duration":0.011362,"end_time":"2023-08-03T03:28:41.887971","exception":false,"start_time":"2023-08-03T03:28:41.876609","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#F2C464; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #F2C464\">2 | Multi Head Attention üß†‚Äçüß†‚Äçüß†</p>\n","\n","<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","What we did is a implimaentation of `Single Head`. We use multiple heads to gather multiple information of the corpus\n","\n","So how do we handle `Multiple Heads`$...?$\n","\n","Assume we have the same sentence but this time we have increased our Output of Embedding Layer"]},{"cell_type":"code","execution_count":12,"id":"dfcc6691","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:41.913123Z","iopub.status.busy":"2023-08-03T03:28:41.912694Z","iopub.status.idle":"2023-08-03T03:28:41.923768Z","shell.execute_reply":"2023-08-03T03:28:41.922358Z"},"papermill":{"duration":0.026634,"end_time":"2023-08-03T03:28:41.926229","exception":false,"start_time":"2023-08-03T03:28:41.899595","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[-0.5204, -1.0458, -1.6739,  0.8963, -1.9782, -0.2311,  0.1427, -0.0284,\n","         -0.4013, -0.2466],\n","        [-0.0624, -1.3993, -0.0921, -0.4546, -2.4029, -1.1404,  0.0885,  0.9480,\n","         -0.7675, -1.7463]], grad_fn=<EmbeddingBackward0>)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["Embedding_Layer = nn.Embedding(2 , 10)\n","\n","inputs = Embedding_Layer(torch.tensor([0 , 1]))\n","inputs"]},{"cell_type":"markdown","id":"ece9b416","metadata":{"papermill":{"duration":0.011592,"end_time":"2023-08-03T03:28:41.949844","exception":false,"start_time":"2023-08-03T03:28:41.938252","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets assume we are making $5$ Heads. \n","\n","What we do is we break this matrix into $5$ parts and then seperately work on them. Lets assume the indices of our matrix is like\n","```\n","[(0 , 0) , (0 , 1) , (0 , 2) , (0 , 3) , (0 , 4) , (0 , 5) , (0 , 6) , (0 , 7) , (0 , 8) , (0 , 9) , \n","(1 , 0) , (1 , 1) , (1 , 2) , (1 , 3) , (1 , 4) , (1 , 5) , (1 , 6) , (1 , 7) , (1 . 8) , (1 , 9)]\n","```\n","By breaking it in $5$ parts \n","```\n","[(0 , 0) , (0 , 1) , \n","(1 , 0) , (1 , 1)]\n","\n","[(0 , 2) , (0 , 3) ,\n","(1 , 2) , (1 , 3)]\n","\n","[(0 , 4) , (0 , 5) ,\n","(1 , 4) , (1 , 5)]\n","\n","[(0 , 6) , (0 , 7) ,\n","(1 , 6) , (1 , 7)]\n","\n","[(0 , 8) , (0 , 9) , \n","(1 . 8) , (1 , 9)]\n","```\n","\n","So how do we do this$...?$\n","\n","One way is to make $5$ different `Linear Layers` and compute them, which can be expensive\n","\n","One way is somehow we can break this thing up, pass into Neural Networks and then re-concatenate them. This can be computationaly expensive "]},{"cell_type":"markdown","id":"b0a41ff8","metadata":{"papermill":{"duration":0.011443,"end_time":"2023-08-03T03:28:41.97323","exception":false,"start_time":"2023-08-03T03:28:41.961787","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","First we will `reshape` this array"]},{"cell_type":"code","execution_count":13,"id":"41638892","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:41.99884Z","iopub.status.busy":"2023-08-03T03:28:41.998409Z","iopub.status.idle":"2023-08-03T03:28:42.00804Z","shell.execute_reply":"2023-08-03T03:28:42.006906Z"},"papermill":{"duration":0.025205,"end_time":"2023-08-03T03:28:42.010372","exception":false,"start_time":"2023-08-03T03:28:41.985167","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[[[-0.5204, -1.0458],\n","          [-1.6739,  0.8963],\n","          [-1.9782, -0.2311],\n","          [ 0.1427, -0.0284],\n","          [-0.4013, -0.2466]],\n","\n","         [[-0.0624, -1.3993],\n","          [-0.0921, -0.4546],\n","          [-2.4029, -1.1404],\n","          [ 0.0885,  0.9480],\n","          [-0.7675, -1.7463]]]], grad_fn=<ReshapeAliasBackward0>)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["inputs = torch.reshape(inputs, (1, 2 , 5 , 2))\n","inputs"]},{"cell_type":"markdown","id":"98931b9d","metadata":{"papermill":{"duration":0.012287,"end_time":"2023-08-03T03:28:42.035414","exception":false,"start_time":"2023-08-03T03:28:42.023127","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we need to `permute` this "]},{"cell_type":"code","execution_count":14,"id":"2a295514","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:42.063816Z","iopub.status.busy":"2023-08-03T03:28:42.062438Z","iopub.status.idle":"2023-08-03T03:28:42.071876Z","shell.execute_reply":"2023-08-03T03:28:42.070716Z"},"papermill":{"duration":0.025983,"end_time":"2023-08-03T03:28:42.074284","exception":false,"start_time":"2023-08-03T03:28:42.048301","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[[[-0.5204, -1.0458]],\n","\n","         [[-0.0624, -1.3993]]],\n","\n","\n","        [[[-1.6739,  0.8963]],\n","\n","         [[-0.0921, -0.4546]]],\n","\n","\n","        [[[-1.9782, -0.2311]],\n","\n","         [[-2.4029, -1.1404]]],\n","\n","\n","        [[[ 0.1427, -0.0284]],\n","\n","         [[ 0.0885,  0.9480]]],\n","\n","\n","        [[[-0.4013, -0.2466]],\n","\n","         [[-0.7675, -1.7463]]]], grad_fn=<PermuteBackward0>)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["inputs = inputs.permute(2 , 1 , 0 , 3)\n","inputs"]},{"cell_type":"markdown","id":"7f07a38d","metadata":{"papermill":{"duration":0.011927,"end_time":"2023-08-03T03:28:42.09905","exception":false,"start_time":"2023-08-03T03:28:42.087123","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","And this is the same as we wanted"]},{"cell_type":"markdown","id":"9ff34077","metadata":{"papermill":{"duration":0.012028,"end_time":"2023-08-03T03:28:42.123543","exception":false,"start_time":"2023-08-03T03:28:42.111515","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF69B4; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF69B4\">3 | Mutli Head Self Attention Class üåé</p>\n","\n","<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<IMG SRC = 'https://cleanmemes.files.wordpress.com/2014/10/35multiheaddog1.jpg?w=640' WIDTH = 400>\n","    \n","Now lets just make a simple class for this\n","    \n","A really great explanantion to the code by **[Hugging Chat](https://huggingface.co/chat/)**\n","\n","### __init__\n","```\n","def __init__(self , vocab_size , num_heads):\n","\n","    super(MultiHeadSelfAttention , self).__init__()\n","\n","    self.num_heads = num_heads\n","    self.vocab_size = vocab_size\n","\n","    self.queries = nn.Linear(self.vocab_size , self.vocab_size)\n","    self.keys = nn.Linear(self.vocab_size , self.vocab_size)\n","    self.values = nn.Linear(self.vocab_size , self.vocab_size)\n","\n","    self.softmax = torch.nn.Softmax()\n","```\n","\n","The `Constructor` takes two arguments\n","* $Vocablary$ $Size$ `vocab_size` - Size of the Vocablury\n","* $Number$ $of$ $Heads$ `num_heads`\n","\n","It `initializes` the `instance variables` `num_heads`/`vocab_size`, and $3$ $Linear$ $Layers$ - `queries`/`keys`/`values`. The linear layers have a `single hidden layer` with a `dimensionality` of `vocab_size`.\n","\n","### Split Heads\n","```\n","def split_heads(self , gate):\n","\n","#         batch_size = gate.shape[0]\n","\n","    split_gates = torch.reshape(gate, (1 , \n","                                    self.num_heads , \n","                                    int(self.vocab_size / self.num_heads) , \n","                                    self.num_heads)).permute(2 , 1 , 0 , 3)\n","\n","    return split_gates\n","```\n","\n","This method takes a `gate` `(a tensor of shape (batch_size, vocab_size))` and `splits` it into `multiple heads`, each with a `size` of `(batch_size, vocab_size // num_heads)`. It does this by `reshaping` the gate into a $4D$ `tensor`, `permuting the dimensions`, and then `splitting` it along the `second dimension`.\n","\n","### Forward\n","```\n","def forward(self , key , query , value , mask = None):\n","\n","    query_output = self.queries(query)\n","    key_output = self.keys(key)\n","    value_output = self.values(value)\n","\n","    query_output = self.split_heads(query_output)\n","    key_output = self.split_heads(key_output)\n","    value_output = self.split_heads(value_output)\n","\n","    attention = (query_output * key_output) / (key_output.shape[-1] ** (1/2)) \n","\n","    if mask : attention = tf.where(mask == 0 , float('-inf') , attention)\n","\n","    weights = self.softmax(attention)\n","    weights = torch.reshape(weights , (weights.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                       self.num_heads , self.num_heads))\n","    value_output = torch.reshape(value_output , (value_output.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                                 self.num_heads , self.num_heads))\n","    output = torch.matmul(weights , value_output)\n","\n","    output = torch.reshape(output , (self.num_heads , self.vocab_size))\n","\n","    return output , weights\n","```\n","\n","This `method` `computes` the `attention scores` and `outputs` the final output. It takes four arguments - `key`/`query`/`value`/`mask` (an optional binary mask indicating which elements should be ignored).\n","* `Pass` the `query`/`key`/`value` tensors through their `corresponding linear layers` to get the `query`/`key`/`value` `embeddings`.\n","* `Split` the `query`/`key` `embeddings` into `multiple heads` using the `split_heads method`.\n","* `Compute` the `attention` scores by taking the `dot product` of the `query`/`key` `embeddings` and `dividing` the result by the `square root` of the `key embedding's dimensionality`.\n","* If a `mask` is `provided`, `zero` out the `attention scores` for the `masked elements`.\n","* `Apply` a `Softmax function` to the `attention scores` to get the weights.\n","* `Compute` the `output` by taking the `weighted sum` of the `value embeddings` using the weights computed earlier.\n","* `Reshape` the `output tensor` to have the `original vocabulary size`."]},{"cell_type":"code","execution_count":15,"id":"7edf2409","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:42.150138Z","iopub.status.busy":"2023-08-03T03:28:42.14974Z","iopub.status.idle":"2023-08-03T03:28:42.1647Z","shell.execute_reply":"2023-08-03T03:28:42.163734Z"},"papermill":{"duration":0.031453,"end_time":"2023-08-03T03:28:42.167285","exception":false,"start_time":"2023-08-03T03:28:42.135832","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiHeadSelfAttention(nn.Module):\n","    \n","    def __init__(self , vocab_size , num_heads):\n","        \n","        super(MultiHeadSelfAttention , self).__init__()\n","    \n","        self.num_heads = num_heads\n","        self.vocab_size = vocab_size\n","        \n","        self.queries = nn.Linear(self.vocab_size , self.vocab_size)\n","        self.keys = nn.Linear(self.vocab_size , self.vocab_size)\n","        self.values = nn.Linear(self.vocab_size , self.vocab_size)\n","        \n","        self.softmax = torch.nn.Softmax()\n","        \n","    def split_heads(self , gate):\n","        \n","#         batch_size = gate.shape[0]\n","        \n","        split_gates = torch.reshape(gate, (1 , \n","                                        self.num_heads , \n","                                        int(self.vocab_size / self.num_heads) , \n","                                        self.num_heads)).permute(2 , 1 , 0 , 3)\n","        \n","        return split_gates\n","    \n","    def forward(self , key , query , value , mask = None):\n","        \n","        query_output = self.queries(query)\n","        key_output = self.keys(key)\n","        value_output = self.values(value)\n","\n","        query_output = self.split_heads(query_output)\n","        key_output = self.split_heads(key_output)\n","        value_output = self.split_heads(value_output)\n","\n","        attention = (query_output * key_output) / (key_output.shape[-1] ** (1/2)) \n","        \n","        if mask : attention = tf.where(mask == 0 , float('-inf') , attention)\n","\n","        weights = self.softmax(attention)\n","        weights = torch.reshape(weights , (weights.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                           self.num_heads , self.num_heads))\n","        value_output = torch.reshape(value_output , (value_output.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                                     self.num_heads , self.num_heads))\n","        output = torch.matmul(weights , value_output)\n","        \n","        output = torch.reshape(output , (self.num_heads , self.vocab_size))\n","\n","        return output , weights"]},{"cell_type":"markdown","id":"27607dc1","metadata":{"execution":{"iopub.execute_input":"2023-08-02T15:01:59.721131Z","iopub.status.busy":"2023-08-02T15:01:59.720628Z","iopub.status.idle":"2023-08-02T15:01:59.73755Z","shell.execute_reply":"2023-08-02T15:01:59.736092Z","shell.execute_reply.started":"2023-08-02T15:01:59.721095Z"},"papermill":{"duration":0.011852,"end_time":"2023-08-03T03:28:42.191528","exception":false,"start_time":"2023-08-03T03:28:42.179676","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","If we pass a sample input like this "]},{"cell_type":"code","execution_count":16,"id":"f3541246","metadata":{"execution":{"iopub.execute_input":"2023-08-03T03:28:42.217952Z","iopub.status.busy":"2023-08-03T03:28:42.217577Z","iopub.status.idle":"2023-08-03T03:28:42.23998Z","shell.execute_reply":"2023-08-03T03:28:42.238846Z"},"papermill":{"duration":0.038542,"end_time":"2023-08-03T03:28:42.242342","exception":false,"start_time":"2023-08-03T03:28:42.2038","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[-0.4734, -0.1610, -0.4177, -0.1210, -0.0037, -0.0275,  0.0578,  0.0524,\n","           0.2926,  0.4606],\n","         [ 0.3153,  0.5002,  0.9431,  0.0602,  1.2150,  0.1576, -0.6426,  0.2148,\n","          -0.6461,  0.2333]], grad_fn=<ReshapeAliasBackward0>),\n"," tensor([[[[0.4889, 0.5536],\n","           [0.5111, 0.4464]],\n"," \n","          [[0.5025, 0.4270],\n","           [0.4975, 0.5730]],\n"," \n","          [[0.4769, 0.4867],\n","           [0.5231, 0.5133]],\n"," \n","          [[0.4620, 0.4007],\n","           [0.5380, 0.5993]],\n"," \n","          [[0.5203, 0.4647],\n","           [0.4797, 0.5353]]]], grad_fn=<ReshapeAliasBackward0>))"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["mhsa = MultiHeadSelfAttention(vocab_size = 10 , num_heads = 2)\n","inputs = Embedding_Layer(torch.tensor([0 , 1]))\n","mhsa(inputs , inputs , inputs , None)"]},{"cell_type":"markdown","id":"040455a8","metadata":{"papermill":{"duration":0.012078,"end_time":"2023-08-03T03:28:42.267893","exception":false,"start_time":"2023-08-03T03:28:42.255815","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#E77200; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #E77200\">3 | TO DO LIST üìë</p>\n","\n","<div style=\"border-radius:10px; border:#E77200 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","* $TO$ $DO$ $1$ $:$ $MAKE$ $ENCODER$ $BLOCK$\n","* $TO$ $DO$ $2$ $:$ $MAKE$ $DECODER$ $BLOCK$\n","* $TO$ $DO$ $3$ $:$ $MAKE$ $TRANSFORER$ $BLOCK$\n","* $TO$ $DO$ $4$ $:$ $TRAIN$ $TRANSFORER$\n","* $TO$ $DO$ $5$ $:$ $DANCE$"]},{"cell_type":"markdown","id":"8c21fb07","metadata":{"papermill":{"duration":0.012001,"end_time":"2023-08-03T03:28:42.292287","exception":false,"start_time":"2023-08-03T03:28:42.280286","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF9980; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF9980\">4 | Ending üé≠</p>\n","\n","<div style=\"border-radius:10px; border:#FF9980 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","**THAT IT FOR TODAY GUYS**\n","\n","**WE WILL GO DEEPER INTO THE DATA IN THE UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT YOUR THOUGHTS, HIHGLY APPRICIATED**\n","\n","**DONT FORGET TO MAKE AN UPVOTE, IF YOU LIKED MY WORK $:)$**\n","    \n","<img src = \"https://i.imgflip.com/19aadg.jpg\">\n","    \n","**PEACE OUT $!!!$**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":18.067693,"end_time":"2023-08-03T03:28:43.628951","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-08-03T03:28:25.561258","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}