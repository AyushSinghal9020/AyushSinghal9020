{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/making-my-own-transformer?scriptVersionId=138713233\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"3385d581","metadata":{"papermill":{"duration":0.013635,"end_time":"2023-08-02T17:24:59.172348","exception":false,"start_time":"2023-08-02T17:24:59.158713","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#00B9F7; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #00B9F7\">Transformers</p>"]},{"cell_type":"code","execution_count":1,"id":"bc5865f8","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-08-02T17:24:59.197336Z","iopub.status.busy":"2023-08-02T17:24:59.196768Z","iopub.status.idle":"2023-08-02T17:24:59.213751Z","shell.execute_reply":"2023-08-02T17:24:59.212505Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.032763,"end_time":"2023-08-02T17:24:59.216466","exception":false,"start_time":"2023-08-02T17:24:59.183703","status":"completed"},"tags":[]},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"5f8d633e","metadata":{"papermill":{"duration":0.010505,"end_time":"2023-08-02T17:24:59.23809","exception":false,"start_time":"2023-08-02T17:24:59.227585","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00B9F7 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = 'https://media.tenor.com/LStfD5yI5SsAAAAC/transformers-darkofthemoon.gif'>\n","    \n","## So what the hell is this **`Transformers`** $...?$\n","    \n","Yes we have been asking this question from an whole eternity. When we search on $Google$/or any other search engine, we find the same answer\n","```\n","A transformer is a type of neural network architecture that is blah blah blah blah\n","```\n","But what it actually is and why do we even need this \n","    \n","<img src = 'https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png' width = 400>"]},{"cell_type":"markdown","id":"b98310cb","metadata":{"papermill":{"duration":0.010606,"end_time":"2023-08-02T17:24:59.260067","exception":false,"start_time":"2023-08-02T17:24:59.249461","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#8E24AA; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #8E24AA\">1 | Self Attention üß†‚Äçüß†‚Äçüß†</p>"]},{"cell_type":"code","execution_count":2,"id":"f3be1dcd","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:24:59.285068Z","iopub.status.busy":"2023-08-02T17:24:59.284217Z","iopub.status.idle":"2023-08-02T17:25:03.587754Z","shell.execute_reply":"2023-08-02T17:25:03.586007Z"},"papermill":{"duration":4.319061,"end_time":"2023-08-02T17:25:03.590736","exception":false,"start_time":"2023-08-02T17:24:59.271675","status":"completed"},"tags":[]},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","id":"d1ba001c","metadata":{"papermill":{"duration":0.010567,"end_time":"2023-08-02T17:25:03.61334","exception":false,"start_time":"2023-08-02T17:25:03.602773","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<IMG SRC = 'https://media.tenor.com/AleRU5nZSasAAAAC/attention-notice-me.gif' WIDTH = 400>\n","    \n","Society says that the best way to understand `Transformer Architechture`, is to first understand `Self-Attention Mechanism`. \n","\n","I dont know who are the actual people in society, and why do these people do not show up individually, why they cover up themselves with the word `Society`\n","\n","**LEAVE IT !!!**\n","\n","Lets assume we have this sentence `Radhe Krishn`\n","\n","Lets assume we pass this to an `Embedding Layer` to get `Embeddings`. These `Embeddings` will be `Random`, but lets dive it in "]},{"cell_type":"code","execution_count":3,"id":"b84ff9dc","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:03.637285Z","iopub.status.busy":"2023-08-02T17:25:03.636612Z","iopub.status.idle":"2023-08-02T17:25:03.67973Z","shell.execute_reply":"2023-08-02T17:25:03.678493Z"},"papermill":{"duration":0.058412,"end_time":"2023-08-02T17:25:03.682558","exception":false,"start_time":"2023-08-02T17:25:03.624146","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Embedding(2, 12)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["Embedding_Layer = nn.Embedding(2 , 12)\n","Embedding_Layer"]},{"cell_type":"markdown","id":"702e9747","metadata":{"papermill":{"duration":0.010716,"end_time":"2023-08-02T17:25:03.704679","exception":false,"start_time":"2023-08-02T17:25:03.693963","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As our corpus only consists of $2$ distinct words, we can label them as `[0,1]`\n","\n","Passing this to an Embedding Layer, "]},{"cell_type":"code","execution_count":4,"id":"b6619dd0","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:03.728791Z","iopub.status.busy":"2023-08-02T17:25:03.728383Z","iopub.status.idle":"2023-08-02T17:25:03.81898Z","shell.execute_reply":"2023-08-02T17:25:03.817579Z"},"papermill":{"duration":0.106163,"end_time":"2023-08-02T17:25:03.821836","exception":false,"start_time":"2023-08-02T17:25:03.715673","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[ 0.6647,  1.0404,  1.8777, -0.2429, -0.8466,  0.6838, -0.1548,  0.4535,\n","          -0.6739, -1.2547, -1.6579,  1.6100],\n","         [ 0.0415,  0.0324, -0.1148,  0.7800,  0.1516,  0.5193,  0.4753,  1.0215,\n","           0.8109,  0.1070, -1.2987,  0.4303]], grad_fn=<EmbeddingBackward0>),\n"," torch.Size([2, 12]))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["inputs = Embedding_Layer(torch.tensor([0 , 1] , dtype = torch.long))\n","inputs , inputs.shape"]},{"cell_type":"markdown","id":"77e77384","metadata":{"papermill":{"duration":0.010914,"end_time":"2023-08-02T17:25:03.844437","exception":false,"start_time":"2023-08-02T17:25:03.833523","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Suppose we could be able to know, how much these words affect each other "]},{"cell_type":"code","execution_count":5,"id":"8bfaef2e","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:03.869109Z","iopub.status.busy":"2023-08-02T17:25:03.868699Z","iopub.status.idle":"2023-08-02T17:25:04.111374Z","shell.execute_reply":"2023-08-02T17:25:04.11023Z"},"papermill":{"duration":0.257952,"end_time":"2023-08-02T17:25:04.113994","exception":false,"start_time":"2023-08-02T17:25:03.856042","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<matplotlib.image.AxesImage at 0x7bd07fd6bca0>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.imshow(inputs.detach().numpy())"]},{"cell_type":"markdown","id":"5c1dc8c5","metadata":{"papermill":{"duration":0.011981,"end_time":"2023-08-02T17:25:04.137791","exception":false,"start_time":"2023-08-02T17:25:04.12581","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","But by human instincts we know that these $2$ words highle corresponds to each other\n","\n","So how can we do this$...?$\n","\n","The whole concept, where `distinct words` of a `chunk of text` show some `focus`/`effect`/`attention` to `other words` is called `Self Attention`\n","\n","We do this by using $3$ $Major$ $Neural$ $Networks$. For making things more complicated we give them names\n","* $Query$ - What I am Looking for\n","* $Key$ - What I can offer\n","* $Value$ - What I actually offer(I was bluffing before)\n","\n","We will think of these as $3$ $Linear$ $Layers$\n","\n","We know that at the starting $Linear$ $Layers$ are just bunch of random numbers hanging out together like this\n","    \n","<img src = 'https://i.scdn.co/image/ab67616d0000b2732a517799858bf32fe736c2ca' width = 300>\n","\n","So lets just intialize some random $Linear$ $Layers$"]},{"cell_type":"markdown","id":"ce8c2d00","metadata":{"papermill":{"duration":0.012147,"end_time":"2023-08-02T17:25:04.163051","exception":false,"start_time":"2023-08-02T17:25:04.150904","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","As we have $2$ characters, so our `sequence_len == 2`/`vocab_size == 2`"]},{"cell_type":"code","execution_count":6,"id":"8827757a","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.190613Z","iopub.status.busy":"2023-08-02T17:25:04.189926Z","iopub.status.idle":"2023-08-02T17:25:04.198021Z","shell.execute_reply":"2023-08-02T17:25:04.196733Z"},"papermill":{"duration":0.025287,"end_time":"2023-08-02T17:25:04.200638","exception":false,"start_time":"2023-08-02T17:25:04.175351","status":"completed"},"tags":[]},"outputs":[],"source":["sequence_len , vocab_size = 2 , 2\n","embed_layer = nn.Embedding(sequence_len , vocab_size)\n","\n","inputs = embed_layer(torch.tensor([0 , 1]))"]},{"cell_type":"code","execution_count":7,"id":"f6a3a4f1","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.226541Z","iopub.status.busy":"2023-08-02T17:25:04.225778Z","iopub.status.idle":"2023-08-02T17:25:04.234929Z","shell.execute_reply":"2023-08-02T17:25:04.233961Z"},"papermill":{"duration":0.024669,"end_time":"2023-08-02T17:25:04.237492","exception":false,"start_time":"2023-08-02T17:25:04.212823","status":"completed"},"tags":[]},"outputs":[],"source":["queries = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)\n","keys = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)\n","values = torch.rand((sequence_len , vocab_size) , dtype = torch.float32)"]},{"cell_type":"markdown","id":"8bd721e1","metadata":{"papermill":{"duration":0.011315,"end_time":"2023-08-02T17:25:04.260895","exception":false,"start_time":"2023-08-02T17:25:04.24958","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","So what we do is we simply multiply `queries` and `keys`"]},{"cell_type":"code","execution_count":8,"id":"db9a17f4","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.286494Z","iopub.status.busy":"2023-08-02T17:25:04.286063Z","iopub.status.idle":"2023-08-02T17:25:04.295607Z","shell.execute_reply":"2023-08-02T17:25:04.294615Z"},"papermill":{"duration":0.025723,"end_time":"2023-08-02T17:25:04.298469","exception":false,"start_time":"2023-08-02T17:25:04.272746","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.5208, 0.0303],\n","        [0.0623, 0.0398]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["queries * keys"]},{"cell_type":"markdown","id":"4c9b8159","metadata":{"papermill":{"duration":0.011948,"end_time":"2023-08-02T17:25:04.322441","exception":false,"start_time":"2023-08-02T17:25:04.310493","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","So why we did this$...?$\n","\n","Think it like this. We have to complete the sentence `He became ___ Universe`. Now we need to fill in the blank. Lets assume we have the information of future tokens. A model when searches for information in the back-tokens, it needs `He` to be highlighted. That what `queries * keys` do. When the \n","* Queries - What you want\n","* Key - What I can offer\n","\n","When these $2$(Question and answer) meet they show `high iffinity`. Thats why we multiply both of them\n","\n","But how can we get the index with `highest iffinity` $...?$\n","\n","One way is to do a `Softmax` on all of these"]},{"cell_type":"code","execution_count":9,"id":"01c643f9","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.348744Z","iopub.status.busy":"2023-08-02T17:25:04.347912Z","iopub.status.idle":"2023-08-02T17:25:04.362277Z","shell.execute_reply":"2023-08-02T17:25:04.360803Z"},"papermill":{"duration":0.030909,"end_time":"2023-08-02T17:25:04.36536","exception":false,"start_time":"2023-08-02T17:25:04.334451","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.6202, 0.3798],\n","        [0.5056, 0.4944]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["softmax = nn.Softmax()\n","\n","softmax(queries * keys)"]},{"cell_type":"markdown","id":"bc5d8059","metadata":{"papermill":{"duration":0.011928,"end_time":"2023-08-02T17:25:04.389684","exception":false,"start_time":"2023-08-02T17:25:04.377756","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","But these values are very huge and thus can make big variations in the model, thus we will divide them with something"]},{"cell_type":"code","execution_count":10,"id":"b1e4c966","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.419754Z","iopub.status.busy":"2023-08-02T17:25:04.419335Z","iopub.status.idle":"2023-08-02T17:25:04.425938Z","shell.execute_reply":"2023-08-02T17:25:04.42461Z"},"papermill":{"duration":0.025663,"end_time":"2023-08-02T17:25:04.429159","exception":false,"start_time":"2023-08-02T17:25:04.403496","status":"completed"},"tags":[]},"outputs":[],"source":["weights = softmax((queries * keys) / keys.shape[-1])"]},{"cell_type":"markdown","id":"75c033ee","metadata":{"papermill":{"duration":0.013808,"end_time":"2023-08-02T17:25:04.457956","exception":false,"start_time":"2023-08-02T17:25:04.444148","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now this is kind of good \n","\n","We then multiply this with our `values` to get outputs"]},{"cell_type":"code","execution_count":11,"id":"4e1c2044","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.484611Z","iopub.status.busy":"2023-08-02T17:25:04.483581Z","iopub.status.idle":"2023-08-02T17:25:04.501476Z","shell.execute_reply":"2023-08-02T17:25:04.500169Z"},"papermill":{"duration":0.034137,"end_time":"2023-08-02T17:25:04.504118","exception":false,"start_time":"2023-08-02T17:25:04.469981","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[0.5828, 0.6144],\n","        [0.6166, 0.5839]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["torch.matmul(weights , values)"]},{"cell_type":"markdown","id":"2603c4c3","metadata":{"papermill":{"duration":0.015823,"end_time":"2023-08-02T17:25:04.532249","exception":false,"start_time":"2023-08-02T17:25:04.516426","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#8E24AA solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","And these are our final output from `Self-Attention`."]},{"cell_type":"markdown","id":"e91b8bd9","metadata":{"papermill":{"duration":0.013033,"end_time":"2023-08-02T17:25:04.560526","exception":false,"start_time":"2023-08-02T17:25:04.547493","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#F2C464; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #F2C464\">2 | Multi Head Attention üß†‚Äçüß†‚Äçüß†</p>\n","\n","<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","What we did is a implimaentation of `Single Head`. We use multiple heads to gather multiple information of the corpus\n","\n","So how do we handle `Multiple Heads`$...?$\n","\n","Assume we have the same sentence but this time we have increased our Output of Embedding Layer"]},{"cell_type":"code","execution_count":12,"id":"09021a9f","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.589572Z","iopub.status.busy":"2023-08-02T17:25:04.588509Z","iopub.status.idle":"2023-08-02T17:25:04.600179Z","shell.execute_reply":"2023-08-02T17:25:04.598874Z"},"papermill":{"duration":0.029877,"end_time":"2023-08-02T17:25:04.602814","exception":false,"start_time":"2023-08-02T17:25:04.572937","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[ 0.0917,  0.4189,  1.7315,  0.3205, -0.3761, -0.7479, -0.1821, -2.1061,\n","         -0.4657, -0.9558],\n","        [-0.8511, -0.0884, -0.3315,  1.4836,  0.4696,  1.7925, -0.0241,  0.6335,\n","         -1.0553, -1.9112]], grad_fn=<EmbeddingBackward0>)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["Embedding_Layer = nn.Embedding(2 , 10)\n","\n","inputs = Embedding_Layer(torch.tensor([0 , 1]))\n","inputs"]},{"cell_type":"markdown","id":"cebba915","metadata":{"papermill":{"duration":0.012475,"end_time":"2023-08-02T17:25:04.627864","exception":false,"start_time":"2023-08-02T17:25:04.615389","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets assume we are making $5$ Heads. \n","\n","What we do is we break this matrix into $5$ parts and then seperately work on them. Lets assume the indices of our matrix is like\n","```\n","[(0 , 0) , (0 , 1) , (0 , 2) , (0 , 3) , (0 , 4) , (0 , 5) , (0 , 6) , (0 , 7) , (0 , 8) , (0 , 9) , \n","(1 , 0) , (1 , 1) , (1 , 2) , (1 , 3) , (1 , 4) , (1 , 5) , (1 , 6) , (1 , 7) , (1 . 8) , (1 , 9)]\n","```\n","By breaking it in $5$ parts \n","```\n","[(0 , 0) , (0 , 1) , \n","(1 , 0) , (1 , 1)]\n","\n","[(0 , 2) , (0 , 3) ,\n","(1 , 2) , (1 , 3)]\n","\n","[(0 , 4) , (0 , 5) ,\n","(1 , 4) , (1 , 5)]\n","\n","[(0 , 6) , (0 , 7) ,\n","(1 , 6) , (1 , 7)]\n","\n","[(0 , 8) , (0 , 9) , \n","(1 . 8) , (1 , 9)]\n","```\n","\n","So how do we do this$...?$\n","\n","One way is to make $5$ different `Linear Layers` and compute them, which can be expensive\n","\n","One way is somehow we can break this thing up, pass into Neural Networks and then re-concatenate them. This can be computationaly expensive "]},{"cell_type":"markdown","id":"1b73e4c6","metadata":{"papermill":{"duration":0.013372,"end_time":"2023-08-02T17:25:04.655081","exception":false,"start_time":"2023-08-02T17:25:04.641709","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","First we will `reshape` this array"]},{"cell_type":"code","execution_count":13,"id":"bd8e9a78","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.690817Z","iopub.status.busy":"2023-08-02T17:25:04.690002Z","iopub.status.idle":"2023-08-02T17:25:04.698178Z","shell.execute_reply":"2023-08-02T17:25:04.697212Z"},"papermill":{"duration":0.030175,"end_time":"2023-08-02T17:25:04.701171","exception":false,"start_time":"2023-08-02T17:25:04.670996","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[[[ 0.0917,  0.4189],\n","          [ 1.7315,  0.3205],\n","          [-0.3761, -0.7479],\n","          [-0.1821, -2.1061],\n","          [-0.4657, -0.9558]],\n","\n","         [[-0.8511, -0.0884],\n","          [-0.3315,  1.4836],\n","          [ 0.4696,  1.7925],\n","          [-0.0241,  0.6335],\n","          [-1.0553, -1.9112]]]], grad_fn=<ReshapeAliasBackward0>)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["inputs = torch.reshape(inputs, (1, 2 , 5 , 2))\n","inputs"]},{"cell_type":"markdown","id":"f6828069","metadata":{"papermill":{"duration":0.018136,"end_time":"2023-08-02T17:25:04.737119","exception":false,"start_time":"2023-08-02T17:25:04.718983","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we need to `permute` this "]},{"cell_type":"code","execution_count":14,"id":"a0060485","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.766712Z","iopub.status.busy":"2023-08-02T17:25:04.765895Z","iopub.status.idle":"2023-08-02T17:25:04.775189Z","shell.execute_reply":"2023-08-02T17:25:04.77389Z"},"papermill":{"duration":0.026564,"end_time":"2023-08-02T17:25:04.777763","exception":false,"start_time":"2023-08-02T17:25:04.751199","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["tensor([[[[ 0.0917,  0.4189]],\n","\n","         [[-0.8511, -0.0884]]],\n","\n","\n","        [[[ 1.7315,  0.3205]],\n","\n","         [[-0.3315,  1.4836]]],\n","\n","\n","        [[[-0.3761, -0.7479]],\n","\n","         [[ 0.4696,  1.7925]]],\n","\n","\n","        [[[-0.1821, -2.1061]],\n","\n","         [[-0.0241,  0.6335]]],\n","\n","\n","        [[[-0.4657, -0.9558]],\n","\n","         [[-1.0553, -1.9112]]]], grad_fn=<PermuteBackward0>)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["inputs = inputs.permute(2 , 1 , 0 , 3)\n","inputs"]},{"cell_type":"markdown","id":"eaeb099c","metadata":{"papermill":{"duration":0.012454,"end_time":"2023-08-02T17:25:04.803545","exception":false,"start_time":"2023-08-02T17:25:04.791091","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#F2C464 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","And this is the same as we wanted"]},{"cell_type":"markdown","id":"44da482b","metadata":{"papermill":{"duration":0.012489,"end_time":"2023-08-02T17:25:04.829124","exception":false,"start_time":"2023-08-02T17:25:04.816635","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF69B4; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF69B4\">3 | Mutli Head Self Attention Class üåé</p>\n","\n","<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<IMG SRC = 'https://cleanmemes.files.wordpress.com/2014/10/35multiheaddog1.jpg?w=640' WIDTH = 400>\n","    \n","Now lets just make a simple class for this \n","\n","### __init__\n","```\n","def __init__(self , vocab_size , num_heads):\n","\n","    super(MultiHeadSelfAttention , self).__init__()\n","\n","    self.num_heads = num_heads\n","    self.vocab_size = vocab_size\n","\n","    self.queries = nn.Linear(self.vocab_size , self.vocab_size)\n","    self.keys = nn.Linear(self.vocab_size , self.vocab_size)\n","    self.values = nn.Linear(self.vocab_size , self.vocab_size)\n","\n","    self.softmax = torch.nn.Softmax()\n","```\n","\n","The `Constructor` takes two arguments\n","* $Vocablary$ $Size$ `vocab_size` - Size of the Vocablury\n","* $Number$ $of$ $Heads$ `num_heads`\n","\n","It `initializes` the `instance variables` `num_heads`/`vocab_size`, and $3$ $Linear$ $Layers$ - `queries`/`keys`/`values`. The linear layers have a `single hidden layer` with a `dimensionality` of `vocab_size`.\n","\n","### Split Heads\n","```\n","def split_heads(self , gate):\n","\n","#         batch_size = gate.shape[0]\n","\n","    split_gates = torch.reshape(gate, (1 , \n","                                    self.num_heads , \n","                                    int(self.vocab_size / self.num_heads) , \n","                                    self.num_heads)).permute(2 , 1 , 0 , 3)\n","\n","    return split_gates\n","```\n","\n","This method takes a `gate` `(a tensor of shape (batch_size, vocab_size))` and `splits` it into `multiple heads`, each with a `size` of `(batch_size, vocab_size // num_heads)`. It does this by `reshaping` the gate into a $4D$ `tensor`, `permuting the dimensions`, and then `splitting` it along the `second dimension`.\n","\n","### Forward\n","```\n","def forward(self , key , query , value , mask = None):\n","\n","    query_output = self.queries(query)\n","    key_output = self.keys(key)\n","    value_output = self.values(value)\n","\n","    query_output = self.split_heads(query_output)\n","    key_output = self.split_heads(key_output)\n","    value_output = self.split_heads(value_output)\n","\n","    attention = (query_output * key_output) / (key_output.shape[-1] ** (1/2)) \n","\n","    if mask : attention = tf.where(mask == 0 , float('-inf') , attention)\n","\n","    weights = self.softmax(attention)\n","    weights = torch.reshape(weights , (weights.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                       self.num_heads , self.num_heads))\n","    value_output = torch.reshape(value_output , (value_output.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                                 self.num_heads , self.num_heads))\n","    output = torch.matmul(weights , value_output)\n","\n","    output = torch.reshape(output , (self.num_heads , self.vocab_size))\n","\n","    return output , weights\n","```\n","\n","This `method` `computes` the `attention scores` and `outputs` the final output. It takes four arguments - `key`/`query`/`value`/`mask` (an optional binary mask indicating which elements should be ignored).\n","* `Pass` the `query`/`key`/`value` tensors through their `corresponding linear layers` to get the `query`/`key`/`value` `embeddings`.\n","* `Split` the `query`/`key` `embeddings` into `multiple heads` using the `split_heads method`.\n","* `Compute` the `attention` scores by taking the `dot product` of the `query`/`key` `embeddings` and `dividing` the result by the `square root` of the `key embedding's dimensionality`.\n","* If a `mask` is `provided`, `zero` out the `attention scores` for the `masked elements`.\n","* `Apply` a `Softmax function` to the `attention scores` to get the weights.\n","* `Compute` the `output` by taking the `weighted sum` of the `value embeddings` using the weights computed earlier.\n","* `Reshape` the `output tensor` to have the `original vocabulary size`."]},{"cell_type":"code","execution_count":15,"id":"cbb5005e","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.864584Z","iopub.status.busy":"2023-08-02T17:25:04.864142Z","iopub.status.idle":"2023-08-02T17:25:04.882477Z","shell.execute_reply":"2023-08-02T17:25:04.881426Z"},"papermill":{"duration":0.040306,"end_time":"2023-08-02T17:25:04.885761","exception":false,"start_time":"2023-08-02T17:25:04.845455","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiHeadSelfAttention(nn.Module):\n","    \n","    def __init__(self , vocab_size , num_heads):\n","        \n","        super(MultiHeadSelfAttention , self).__init__()\n","    \n","        self.num_heads = num_heads\n","        self.vocab_size = vocab_size\n","        \n","        self.queries = nn.Linear(self.vocab_size , self.vocab_size)\n","        self.keys = nn.Linear(self.vocab_size , self.vocab_size)\n","        self.values = nn.Linear(self.vocab_size , self.vocab_size)\n","        \n","        self.softmax = torch.nn.Softmax()\n","        \n","    def split_heads(self , gate):\n","        \n","#         batch_size = gate.shape[0]\n","        \n","        split_gates = torch.reshape(gate, (1 , \n","                                        self.num_heads , \n","                                        int(self.vocab_size / self.num_heads) , \n","                                        self.num_heads)).permute(2 , 1 , 0 , 3)\n","        \n","        return split_gates\n","    \n","    def forward(self , key , query , value , mask = None):\n","        \n","        query_output = self.queries(query)\n","        key_output = self.keys(key)\n","        value_output = self.values(value)\n","\n","        query_output = self.split_heads(query_output)\n","        key_output = self.split_heads(key_output)\n","        value_output = self.split_heads(value_output)\n","\n","        attention = (query_output * key_output) / (key_output.shape[-1] ** (1/2)) \n","        \n","        if mask : attention = tf.where(mask == 0 , float('-inf') , attention)\n","\n","        weights = self.softmax(attention)\n","        weights = torch.reshape(weights , (weights.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                           self.num_heads , self.num_heads))\n","        value_output = torch.reshape(value_output , (value_output.shape[2] , int(self.vocab_size / self.num_heads) , \n","                                                     self.num_heads , self.num_heads))\n","        output = torch.matmul(weights , value_output)\n","        \n","        output = torch.reshape(output , (self.num_heads , self.vocab_size))\n","\n","        return output , weights"]},{"cell_type":"markdown","id":"30412e1f","metadata":{"execution":{"iopub.execute_input":"2023-08-02T15:01:59.721131Z","iopub.status.busy":"2023-08-02T15:01:59.720628Z","iopub.status.idle":"2023-08-02T15:01:59.73755Z","shell.execute_reply":"2023-08-02T15:01:59.736092Z","shell.execute_reply.started":"2023-08-02T15:01:59.721095Z"},"papermill":{"duration":0.013163,"end_time":"2023-08-02T17:25:04.913064","exception":false,"start_time":"2023-08-02T17:25:04.899901","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FF69B4 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","If we pass a sample input like this "]},{"cell_type":"code","execution_count":16,"id":"ab35a244","metadata":{"execution":{"iopub.execute_input":"2023-08-02T17:25:04.941571Z","iopub.status.busy":"2023-08-02T17:25:04.940757Z","iopub.status.idle":"2023-08-02T17:25:04.966385Z","shell.execute_reply":"2023-08-02T17:25:04.96516Z"},"papermill":{"duration":0.043236,"end_time":"2023-08-02T17:25:04.969154","exception":false,"start_time":"2023-08-02T17:25:04.925918","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(tensor([[ 0.4367, -0.1013,  0.5277, -0.1216,  0.4513,  0.1801,  0.5698,  0.1469,\n","          -0.2149, -0.2931],\n","         [-0.2540, -0.3801,  0.5851,  0.1712,  0.9085,  0.2697,  0.0921,  0.1816,\n","          -0.1066, -0.0033]], grad_fn=<ReshapeAliasBackward0>),\n"," tensor([[[[0.4001, 0.4637],\n","           [0.5999, 0.5363]],\n"," \n","          [[0.4511, 0.5131],\n","           [0.5489, 0.4869]],\n"," \n","          [[0.4692, 0.2316],\n","           [0.5308, 0.7684]],\n"," \n","          [[0.3689, 0.4021],\n","           [0.6311, 0.5979]],\n"," \n","          [[0.2842, 0.5408],\n","           [0.7158, 0.4592]]]], grad_fn=<ReshapeAliasBackward0>))"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["mhsa = MultiHeadSelfAttention(vocab_size = 10 , num_heads = 2)\n","inputs = Embedding_Layer(torch.tensor([0 , 1]))\n","mhsa(inputs , inputs , inputs , None)"]},{"cell_type":"markdown","id":"2f5cbc69","metadata":{"papermill":{"duration":0.012382,"end_time":"2023-08-02T17:25:04.9959","exception":false,"start_time":"2023-08-02T17:25:04.983518","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#E77200; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #E77200\">3 | TO DO LIST üìë</p>\n","\n","<div style=\"border-radius:10px; border:#E77200 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","* $TO$ $DO$ $1$ $:$ $MAKE$ $ENCODER$ $BLOCK$\n","* $TO$ $DO$ $2$ $:$ $MAKE$ $DECODER$ $BLOCK$\n","* $TO$ $DO$ $3$ $:$ $MAKE$ $TRANSFORER$ $BLOCK$\n","* $TO$ $DO$ $4$ $:$ $TRAIN$ $TRANSFORER$\n","* $TO$ $DO$ $5$ $:$ $DANCE$"]},{"cell_type":"markdown","id":"51ea2172","metadata":{"papermill":{"duration":0.012445,"end_time":"2023-08-02T17:25:05.021708","exception":false,"start_time":"2023-08-02T17:25:05.009263","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF9980; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF9980\">4 | Ending üé≠</p>\n","\n","<div style=\"border-radius:10px; border:#FF9980 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","**THAT IT FOR TODAY GUYS**\n","\n","**WE WILL GO DEEPER INTO THE DATA IN THE UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT YOUR THOUGHTS, HIHGLY APPRICIATED**\n","\n","**DONT FORGET TO MAKE AN UPVOTE, IF YOU LIKED MY WORK $:)$**\n","    \n","<img src = \"https://i.imgflip.com/19aadg.jpg\">\n","    \n","**PEACE OUT $!!!$**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":22.711621,"end_time":"2023-08-02T17:25:06.561094","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-08-02T17:24:43.849473","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}