{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/utc-training-pytorch-dataloader-cafa?scriptVersionId=135486652\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"35448d09","metadata":{"papermill":{"duration":0.016591,"end_time":"2023-07-02T08:41:58.816426","exception":false,"start_time":"2023-07-02T08:41:58.799835","status":"completed"},"tags":[]},"source":["# CAFA 5 Protein Prediction\n","\n","<img src = \"https://i.pinimg.com/originals/8e/de/73/8ede737acdcf671e000ae0f87a742e40.png\" width = 400>\n","\n","The `goal` of this competition is to `predict the function of a set of proteins`. We will `develop a model trained` on the `amino-acid sequences` of the `proteins and on other data`. Our work `will help researchers` better `understand the function of proteins`, which is `important for discovering` `how cells, tissues, and organs work`.\n","\n","# 1 | Basic Terminologies üíª\n","\n","* $Structure$ $of$ $a$ $Protein$\n","* $Gene$ $Ontology$ $(GO)$\n","\n","## 1.1 | Structure of a Protein\n","\n","So what is a actually a **Protein...?**\n","\n","First of all lets understand the structure of an **Atom**\n","\n","<img src = \"https://www.sciencefacts.net/wp-content/uploads/2020/11/Parts-of-an-Atom-Diagram.jpg\"  width = 300>\n","\n","There is a really good image I found of the `structure of atom`. Though there are many debates on the structure like this, but this `model is accepted universaly at this moment`.\n","\n","In the centre we have the `Neucleus`. The `Neucleus` is made up of $2$ more structures named as `Neutron` and `Proton`. A `Proton` is `positively charged element` and a `Neutron` is a `neutral charged element`. A `Electron`, `negatively charged element`, `orbits` this `Neucleus` at some `distance apart`.\n","\n","The `more we increase the number` of `Electrons` and `Protons`. The `bigger the atoms becomes`.\n","\n","There are `different shells` where the `Electrons reside`. The `more closer the shell` is, the `less Electrons` it contrains. There are mainly $4$ shells. \n","\n","|||\n","|---|---\n","|$K$|$2$\n","|$L$|$8$\n","|$M$|$18$\n","|$N$|$32$\n","\n","Once an atom `fills its outer most shell` with `Electrons`. It becomes `stable atom` and try to `refuse any donation` or `recieve of extra atom`.\n","\n","<img src = \"https://cdn1.byjus.com/wp-content/uploads/2022/01/word-image128.png\" width = 400>\n","\n","`Different atoms combine` to `share Electrons` and become `stable Molecules` \n","\n","<img src = \"https://www.astrochem.org/sci_img/Amino_Acid_Structure.jpg\" width = 300>\n","\n","A `Amino Acid` is made up of mainly $4$ different atoms\n","`[H , C , O , N]`. \n","\n","<img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/L-amino_acid_structure.svg/1200px-L-amino_acid_structure.svg.png\" alt = \"Bro use Light Theme\" width = 300 >\n","\n","We also have a free `Electron Pair` of `Carbon` in this molecule, we call this as a `Side Chain` which can be of different types. Basically this `Side Chain` provide the flexibility to make `different types` of `Amino Acids`. This flexibilty allows for $20$ `different` `Amino Acids` \n","\n","When we join `Amino Acids` with `peptide bonds`, we get `Proteins`. Conncecting different types of `Amino Acids` ends up in different types of `Proteins`.\n","\n","## 1.2 | Gene Ontology (GO)\n","\n","$Gene$ $Ontology$ $(GO)$ is a `controlled vocabulary` that `describes the functions of genes` and gene products. It is constantly being updated as new information becomes available.\n","\n","There are mainly $3$ `Ontologies`\n","\n","||||\n","|---|---|---\n","|$Biological$ $Process$|Describes the `biological processes`|A gene product might be involved in the process of `cell cycle`/`signal transduction.`\n","|$Cellular$ $Component$|Describes the `cellular components`|A gene product might be located in the `nucleus`/`cytoplasm`.\n","|$Molecular$ $Function$|Describes the `molecular functions`|A gene product might be involved in the `catalysis of a reaction`/`binding of a molecule`.\n","\n","**[Gene Ontology Documentation](http://geneontology.org/docs/ontology-documentation/)**"]},{"cell_type":"markdown","id":"298c3e23","metadata":{"papermill":{"duration":0.013742,"end_time":"2023-07-02T08:41:58.844881","exception":false,"start_time":"2023-07-02T08:41:58.831139","status":"completed"},"tags":[]},"source":["# 2 | Data üìä"]},{"cell_type":"code","execution_count":1,"id":"3aca71c8","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-02T08:41:58.875263Z","iopub.status.busy":"2023-07-02T08:41:58.874549Z","iopub.status.idle":"2023-07-02T08:41:58.960365Z","shell.execute_reply":"2023-07-02T08:41:58.959227Z"},"papermill":{"duration":0.104719,"end_time":"2023-07-02T08:41:58.96364","exception":false,"start_time":"2023-07-02T08:41:58.858921","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd \n","import re\n","from Bio.Seq import Seq"]},{"cell_type":"markdown","id":"0e3e7d5c","metadata":{"papermill":{"duration":0.013374,"end_time":"2023-07-02T08:41:58.990689","exception":false,"start_time":"2023-07-02T08:41:58.977315","status":"completed"},"tags":[]},"source":["The $Training$ $Set$ contains all `proteins with annotated terms` that have been validated by \n","* $Experimental$\n","* $High-Throughput$ $Evidence$\n","* [$Traceable$ $Author$ $Statement$](https://wiki.geneontology.org/index.php/Traceable_Author_Statement_(TAS)#:~:text=The%20TAS%20evidence%20code%20covers,annotations%20come%20from%20review%20articles.)\n","* [$Inferred$ $by$ $Curator$ $(IC)$](https://wiki.geneontology.org/Inferred_by_Curator_(IC)) \n","\n","**Any other sources of Data are allowed**\n","\n","### 2.1.1.1 | Go-Basic.obo\n","\n","The $Ontology$ data is in the `file go-basic.obo`. This file is in $OBO$ `Biology-Oriented Language`. The nodes in `the graph are indexed` by the `term name`\n","```\n","subontology_roots = {'BPO':'GO:0008150',\n","                     'CCO':'GO:0005575',\n","                     'MFO':'GO:0003674'}\n","```"]},{"cell_type":"code","execution_count":2,"id":"98e16b54","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-02T08:41:59.021721Z","iopub.status.busy":"2023-07-02T08:41:59.021292Z","iopub.status.idle":"2023-07-02T08:42:03.526843Z","shell.execute_reply":"2023-07-02T08:42:03.525506Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":4.524569,"end_time":"2023-07-02T08:42:03.529939","exception":false,"start_time":"2023-07-02T08:41:59.00537","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[Term]\n","id: GO:0000001\n","name: mitochondrion inheritance\n","namespace: biological_process\n","def: \"The distribution of mitochondria, including the mitochondrial genome, into daughter cells after mitosis or meiosis, mediated by interactions between mitochondria and the cytoskeleton.\" [GOC:mcc, PMID:10873824, PMID:11389764]\n","synonym: \"mitochondrial inheritance\" EXACT []\n","is_a: GO:0048308 ! organelle inheritance\n","is_a: GO:0048311 ! mitochondrion distribution\n","\n"]}],"source":["with open('/kaggle/input/cafa-5-protein-function-prediction/Train/go-basic.obo') as file :\n","    \n","    content = file.read()\n","    stanzas =  re.findall(r'\\[Term\\][\\s\\S]*?(?=\\n\\[|$)' , content)\n","    \n","print(stanzas[0])"]},{"cell_type":"markdown","id":"0de4dd42","metadata":{"papermill":{"duration":0.013717,"end_time":"2023-07-02T08:42:03.557288","exception":false,"start_time":"2023-07-02T08:42:03.543571","status":"completed"},"tags":[]},"source":["### 2.1.1.2 | Training Sequences.fasta\n","\n","This file contains only `sequences` for `proteins` with `annotations` in the dataset `labeled proteins`.\n","\n","This files are in `FASTA` format. \n","\n","This file contains . To obtain the full set of protein sequences for unlabeled proteins, the Swiss-Prot and TrEMBL databases can be found here."]},{"cell_type":"code","execution_count":3,"id":"c705959e","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:03.585707Z","iopub.status.busy":"2023-07-02T08:42:03.585291Z","iopub.status.idle":"2023-07-02T08:42:04.681702Z","shell.execute_reply":"2023-07-02T08:42:04.680443Z"},"papermill":{"duration":1.113654,"end_time":"2023-07-02T08:42:04.684253","exception":false,"start_time":"2023-07-02T08:42:03.570599","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'>P20536 sp|P20536|UNG_VACCC Uracil-DNA glycosylase OS=Vaccinia virus (strain Copenhagen) OX=10249 GN=UNG PE=1 SV=1\\nMNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIPDKFFIQLKQPLRNK\\nRVCVCGIDPYPKDGTGVPFESPNF'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["with open(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_sequences.fasta\" , \"r\") as file:\n","    x = file.read()\n","    \n","x[:200]"]},{"cell_type":"markdown","id":"f36b14fb","metadata":{"papermill":{"duration":0.013329,"end_time":"2023-07-02T08:42:04.711119","exception":false,"start_time":"2023-07-02T08:42:04.69779","status":"completed"},"tags":[]},"source":["### 2.1.1.3 | Train Terms.tsv\n","\n","This file contains the list of annotated terms `ground truth` for the proteins in `train_sequences.fasta`. "]},{"cell_type":"code","execution_count":4,"id":"b4515b70","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-02T08:42:04.740257Z","iopub.status.busy":"2023-07-02T08:42:04.739786Z","iopub.status.idle":"2023-07-02T08:42:08.952827Z","shell.execute_reply":"2023-07-02T08:42:08.951451Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":4.231552,"end_time":"2023-07-02T08:42:08.956117","exception":false,"start_time":"2023-07-02T08:42:04.724565","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EntryID</th>\n","      <th>term</th>\n","      <th>aspect</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A0A009IHW8</td>\n","      <td>GO:0008152</td>\n","      <td>BPO</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A0A009IHW8</td>\n","      <td>GO:0034655</td>\n","      <td>BPO</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A0A009IHW8</td>\n","      <td>GO:0072523</td>\n","      <td>BPO</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A0A009IHW8</td>\n","      <td>GO:0044270</td>\n","      <td>BPO</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A0A009IHW8</td>\n","      <td>GO:0006753</td>\n","      <td>BPO</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5363858</th>\n","      <td>X5L565</td>\n","      <td>GO:0050649</td>\n","      <td>MFO</td>\n","    </tr>\n","    <tr>\n","      <th>5363859</th>\n","      <td>X5L565</td>\n","      <td>GO:0016491</td>\n","      <td>MFO</td>\n","    </tr>\n","    <tr>\n","      <th>5363860</th>\n","      <td>X5M5N0</td>\n","      <td>GO:0005515</td>\n","      <td>MFO</td>\n","    </tr>\n","    <tr>\n","      <th>5363861</th>\n","      <td>X5M5N0</td>\n","      <td>GO:0005488</td>\n","      <td>MFO</td>\n","    </tr>\n","    <tr>\n","      <th>5363862</th>\n","      <td>X5M5N0</td>\n","      <td>GO:0003674</td>\n","      <td>MFO</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5363863 rows √ó 3 columns</p>\n","</div>"],"text/plain":["            EntryID        term aspect\n","0        A0A009IHW8  GO:0008152    BPO\n","1        A0A009IHW8  GO:0034655    BPO\n","2        A0A009IHW8  GO:0072523    BPO\n","3        A0A009IHW8  GO:0044270    BPO\n","4        A0A009IHW8  GO:0006753    BPO\n","...             ...         ...    ...\n","5363858      X5L565  GO:0050649    MFO\n","5363859      X5L565  GO:0016491    MFO\n","5363860      X5M5N0  GO:0005515    MFO\n","5363861      X5M5N0  GO:0005488    MFO\n","5363862      X5M5N0  GO:0003674    MFO\n","\n","[5363863 rows x 3 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv\" , sep = \"\\t\")"]},{"cell_type":"markdown","id":"837b00d2","metadata":{"papermill":{"duration":0.013767,"end_time":"2023-07-02T08:42:08.984309","exception":false,"start_time":"2023-07-02T08:42:08.970542","status":"completed"},"tags":[]},"source":["The first column indicates the `protein's UniProt accession ID`, the second is the `GO term ID`, and the third indicates in which `ontology the term appears`.\n","\n","### 2.1.1.4 | Train Taxonomy.tsv\n","\n","This file contains the list of `proteins and the species to which they belong`, represented by a `taxonomic identifier` `taxon ID` number."]},{"cell_type":"code","execution_count":5,"id":"81c59e7d","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-02T08:42:09.016196Z","iopub.status.busy":"2023-07-02T08:42:09.015812Z","iopub.status.idle":"2023-07-02T08:42:09.141016Z","shell.execute_reply":"2023-07-02T08:42:09.139378Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.145201,"end_time":"2023-07-02T08:42:09.14384","exception":false,"start_time":"2023-07-02T08:42:08.998639","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EntryID</th>\n","      <th>taxonomyID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q8IXT2</td>\n","      <td>9606</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Q04418</td>\n","      <td>559292</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A8DYA3</td>\n","      <td>7227</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Q9UUI3</td>\n","      <td>284812</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Q57ZS4</td>\n","      <td>185431</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>142241</th>\n","      <td>Q5TD07</td>\n","      <td>9606</td>\n","    </tr>\n","    <tr>\n","      <th>142242</th>\n","      <td>A8BB17</td>\n","      <td>7955</td>\n","    </tr>\n","    <tr>\n","      <th>142243</th>\n","      <td>A0A2R8QBB1</td>\n","      <td>7955</td>\n","    </tr>\n","    <tr>\n","      <th>142244</th>\n","      <td>P0CT72</td>\n","      <td>284812</td>\n","    </tr>\n","    <tr>\n","      <th>142245</th>\n","      <td>Q9NZ43</td>\n","      <td>9606</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>142246 rows √ó 2 columns</p>\n","</div>"],"text/plain":["           EntryID  taxonomyID\n","0           Q8IXT2        9606\n","1           Q04418      559292\n","2           A8DYA3        7227\n","3           Q9UUI3      284812\n","4           Q57ZS4      185431\n","...            ...         ...\n","142241      Q5TD07        9606\n","142242      A8BB17        7955\n","142243  A0A2R8QBB1        7955\n","142244      P0CT72      284812\n","142245      Q9NZ43        9606\n","\n","[142246 rows x 2 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv(\"/kaggle/input/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv\" , sep = \"\\t\")"]},{"cell_type":"markdown","id":"2bafdaab","metadata":{"papermill":{"duration":0.013787,"end_time":"2023-07-02T08:42:09.171978","exception":false,"start_time":"2023-07-02T08:42:09.158191","status":"completed"},"tags":[]},"source":["### 2.1.1.5 | IA.txt\n","\n","IA.txt contains the information accretion (weights) for each GO term. These weights are used to compute weighted precision and recall, as described in the Evaluation section. \n","\n","## 2.1.2 | Test Set\n","\n","The $Test$ $Set$ is `unknown at the beginning` of the competition. It will contain `protein sequences` `their functions` from the `test superset` that `gained experimental annotations` between the `submission-deadline` and the `time of evaluation`.\n","\n","# 3 | PyTorch DataLoader ‚öôÔ∏è"]},{"cell_type":"code","execution_count":6,"id":"d20e2fc9","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-02T08:42:09.202114Z","iopub.status.busy":"2023-07-02T08:42:09.201737Z","iopub.status.idle":"2023-07-02T08:42:12.809134Z","shell.execute_reply":"2023-07-02T08:42:12.808262Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":3.626069,"end_time":"2023-07-02T08:42:12.812184","exception":false,"start_time":"2023-07-02T08:42:09.186115","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import tqdm\n","\n","import torch\n","from torch.utils.data import Dataset"]},{"cell_type":"markdown","id":"a54db1d6","metadata":{"papermill":{"duration":0.014418,"end_time":"2023-07-02T08:42:12.841463","exception":false,"start_time":"2023-07-02T08:42:12.827045","status":"completed"},"tags":[]},"source":["The dataloader is highly inspired by **[Henri Upton](https://www.kaggle.com/henriupton)=>[ProteiNet üß¨ PyTorch+EMS2/T5/ProtBERT Embeddings](https://www.kaggle.com/code/henriupton/proteinet-pytorch-ems2-t5-protbert-embeddings)**\n","\n","First we will make a simple class..."]},{"cell_type":"code","execution_count":7,"id":"ccacbe7a","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:12.875201Z","iopub.status.busy":"2023-07-02T08:42:12.873638Z","iopub.status.idle":"2023-07-02T08:42:12.878729Z","shell.execute_reply":"2023-07-02T08:42:12.877928Z"},"papermill":{"duration":0.02457,"end_time":"2023-07-02T08:42:12.881271","exception":false,"start_time":"2023-07-02T08:42:12.856701","status":"completed"},"tags":[]},"outputs":[],"source":["class P_Dataset(Dataset):\n","    pass"]},{"cell_type":"markdown","id":"11cc7b0c","metadata":{"papermill":{"duration":0.014996,"end_time":"2023-07-02T08:42:12.911101","exception":false,"start_time":"2023-07-02T08:42:12.896105","status":"completed"},"tags":[]},"source":["Now we will load the `embeds , id` from the `T5 Embeds`\n","\n","Embeds are like representation of a non-numercial elemenet to a list of numerical elemenet. "]},{"cell_type":"code","execution_count":8,"id":"4e024373","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:12.942588Z","iopub.status.busy":"2023-07-02T08:42:12.942207Z","iopub.status.idle":"2023-07-02T08:42:12.94844Z","shell.execute_reply":"2023-07-02T08:42:12.947147Z"},"papermill":{"duration":0.025629,"end_time":"2023-07-02T08:42:12.951547","exception":false,"start_time":"2023-07-02T08:42:12.925918","status":"completed"},"tags":[]},"outputs":[],"source":["class P_Dataset(Dataset):\n","    \n","    def __init__(self):\n","        \n","        super(P_Dataset).__init__()\n","        \n","        embeds = np.load(\"/kaggle/input/t5embeds/test_embeds.npy\")\n","        ids = np.load(\"/kaggle/input/t5embeds/test_ids.npy\")"]},{"cell_type":"markdown","id":"31ea8488","metadata":{"papermill":{"duration":0.0153,"end_time":"2023-07-02T08:42:12.981789","exception":false,"start_time":"2023-07-02T08:42:12.966489","status":"completed"},"tags":[]},"source":["In case you wanna see, what these `embeds` and `id` looks like, open the below hidden cells"]},{"cell_type":"code","execution_count":9,"id":"650c1f46","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true,"execution":{"iopub.execute_input":"2023-07-02T08:42:13.016852Z","iopub.status.busy":"2023-07-02T08:42:13.015558Z","iopub.status.idle":"2023-07-02T08:42:23.096181Z","shell.execute_reply":"2023-07-02T08:42:23.095297Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"papermill":{"duration":10.101678,"end_time":"2023-07-02T08:42:23.098568","exception":false,"start_time":"2023-07-02T08:42:12.99689","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["(array([[ 0.05470492,  0.06342026, -0.01531996, ..., -0.04331931,\n","          0.03600927,  0.06309301],\n","        [ 0.09037268,  0.08984205, -0.02388695, ..., -0.05335043,\n","          0.01964429,  0.07962959],\n","        [ 0.04358805,  0.03957234, -0.01433173, ..., -0.04446448,\n","          0.03097377,  0.04032155],\n","        ...,\n","        [ 0.03274843,  0.14186755,  0.03414193, ...,  0.0206462 ,\n","          0.05467706, -0.01504807],\n","        [ 0.05271317,  0.15701264,  0.04327936, ...,  0.02159062,\n","          0.0625835 , -0.01490347],\n","        [ 0.04187706,  0.13404095,  0.0790938 , ...,  0.0541121 ,\n","          0.01576663, -0.02881737]]),\n"," (141865, 1024),\n"," array(['Q9CQV8', 'P62259', 'P68510', ..., 'C0HK73', 'C0HK74',\n","        'A0A3G2FQK2'], dtype='<U10'),\n"," (141865,))"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["embeds = np.load(\"/kaggle/input/t5embeds/test_embeds.npy\")\n","ids = np.load(\"/kaggle/input/t5embeds/test_ids.npy\")\n","\n","embeds , embeds.shape , ids , ids.shape"]},{"cell_type":"markdown","id":"23a6c23d","metadata":{"papermill":{"duration":0.01371,"end_time":"2023-07-02T08:42:23.126998","exception":false,"start_time":"2023-07-02T08:42:23.113288","status":"completed"},"tags":[]},"source":["Now we will make the `embeds_list`"]},{"cell_type":"code","execution_count":10,"id":"f5028f62","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:23.158383Z","iopub.status.busy":"2023-07-02T08:42:23.157508Z","iopub.status.idle":"2023-07-02T08:42:23.165081Z","shell.execute_reply":"2023-07-02T08:42:23.163644Z"},"papermill":{"duration":0.026774,"end_time":"2023-07-02T08:42:23.167899","exception":false,"start_time":"2023-07-02T08:42:23.141125","status":"completed"},"tags":[]},"outputs":[],"source":["class P_Dataset(Dataset):\n","    \n","    def __init__(self):\n","        \n","        super(P_Dataset).__init__()\n","        \n","        embeds = np.load(\"/kaggle/input/t5embeds/test_embeds.npy\")\n","        ids = np.load(\"/kaggle/input/t5embeds/test_ids.npy\")\n","        \n","        self.embeds_list = [row for row in embeds]"]},{"cell_type":"markdown","id":"e42761dc","metadata":{"papermill":{"duration":0.013909,"end_time":"2023-07-02T08:42:23.196258","exception":false,"start_time":"2023-07-02T08:42:23.182349","status":"completed"},"tags":[]},"source":["Below is the output for the `embeds_list`"]},{"cell_type":"code","execution_count":11,"id":"0c6c0c09","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-02T08:42:23.227772Z","iopub.status.busy":"2023-07-02T08:42:23.22659Z","iopub.status.idle":"2023-07-02T08:42:23.28816Z","shell.execute_reply":"2023-07-02T08:42:23.28667Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.079875,"end_time":"2023-07-02T08:42:23.290686","exception":false,"start_time":"2023-07-02T08:42:23.210811","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([ 0.05470492,  0.06342026, -0.01531996, ..., -0.04331931,\n","        0.03600927,  0.06309301])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["embeds_list = [row for row in embeds]\n","\n","embeds_list[0]"]},{"cell_type":"markdown","id":"313abb16","metadata":{"papermill":{"duration":0.013957,"end_time":"2023-07-02T08:42:23.319808","exception":false,"start_time":"2023-07-02T08:42:23.305851","status":"completed"},"tags":[]},"source":["For the `training` we need the `targets`, which we will take from the `train_targets_top500.npy`."]},{"cell_type":"code","execution_count":12,"id":"e696f42f","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:23.350525Z","iopub.status.busy":"2023-07-02T08:42:23.350051Z","iopub.status.idle":"2023-07-02T08:42:23.358579Z","shell.execute_reply":"2023-07-02T08:42:23.357032Z"},"papermill":{"duration":0.027045,"end_time":"2023-07-02T08:42:23.361106","exception":false,"start_time":"2023-07-02T08:42:23.334061","status":"completed"},"tags":[]},"outputs":[],"source":["class P_Dataset(Dataset):\n","    \n","    def __init__(self , datatype):\n","        \n","        super(P_Dataset).__init__()\n","        \n","        self.datatype  = datatype\n","        \n","        embeds = np.load(\"/kaggle/input/t5embeds/test_embeds.npy\")\n","        ids = np.load(\"/kaggle/input/t5embeds/test_ids.npy\")\n","        \n","        self.embeds_list = [row for row in embeds]\n","        \n","        if self.datatype == \"train\" : \n","            \n","            targets = np.load(\"/kaggle/input/train-targets-top500/train_targets_top500.npy\")[:len(self.embeds_list)]\n","            self.targets_list = [row for row in targets]"]},{"cell_type":"markdown","id":"02f2e943","metadata":{"papermill":{"duration":0.013922,"end_time":"2023-07-02T08:42:23.389426","exception":false,"start_time":"2023-07-02T08:42:23.375504","status":"completed"},"tags":[]},"source":["These are our targets"]},{"cell_type":"code","execution_count":13,"id":"36a48ea7","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true,"execution":{"iopub.execute_input":"2023-07-02T08:42:23.420637Z","iopub.status.busy":"2023-07-02T08:42:23.420136Z","iopub.status.idle":"2023-07-02T08:42:27.559263Z","shell.execute_reply":"2023-07-02T08:42:27.557908Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"papermill":{"duration":4.157949,"end_time":"2023-07-02T08:42:27.561975","exception":false,"start_time":"2023-07-02T08:42:23.404026","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n","       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n","       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n","       0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n","       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0.])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["targets = np.load(\"/kaggle/input/train-targets-top500/train_targets_top500.npy\")[:len(embeds_list)]\n","targets_list = [row for row in targets]\n","\n","targets_list[0]"]},{"cell_type":"markdown","id":"9527c3f5","metadata":{"papermill":{"duration":0.014258,"end_time":"2023-07-02T08:42:27.590797","exception":false,"start_time":"2023-07-02T08:42:27.576539","status":"completed"},"tags":[]},"source":["Now we will just apply some `Getters` in the class "]},{"cell_type":"code","execution_count":14,"id":"409291d6","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:27.621563Z","iopub.status.busy":"2023-07-02T08:42:27.62119Z","iopub.status.idle":"2023-07-02T08:42:27.631798Z","shell.execute_reply":"2023-07-02T08:42:27.630184Z"},"papermill":{"duration":0.029213,"end_time":"2023-07-02T08:42:27.634405","exception":false,"start_time":"2023-07-02T08:42:27.605192","status":"completed"},"tags":[]},"outputs":[],"source":["class P_Dataset(Dataset):\n","\n","    def __init__(self , datatype ):\n","        super(P_Dataset).__init__()\n","\n","        embeds = np.load(\"/kaggle/input/t5embeds/test_embeds.npy\")\n","        \n","        self.datatype = datatype\n","        self.ids = np.load(\"/kaggle/input/t5embeds/test_ids.npy\")\n","        self.embeds_list = [row for row in embeds]\n","\n","        if datatype == \"train\":\n","\n","            targets = np.load(\"/kaggle/input/train-targets-top500/train_targets_top500.npy\")[:len(self.embeds_list)]\n","            \n","            self.targets_list = [row for row in targets]\n","\n","    def __len__(self):return len(self.targets_list)\n","\n","    def __getitem__(self , index):\n","\n","        embed = torch.tensor(self.embeds_list[index] , dtype = torch.float32)\n","\n","        if self.datatype == \"train\":\n","\n","            targets = torch.tensor(self.targets_list[index], dtype = torch.float32)\n","\n","            return embed, targets\n","\n","        id = self.ids[index]\n","\n","        return embed, id"]},{"cell_type":"code","execution_count":15,"id":"e5b67ef4","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:27.665388Z","iopub.status.busy":"2023-07-02T08:42:27.665026Z","iopub.status.idle":"2023-07-02T08:42:28.629268Z","shell.execute_reply":"2023-07-02T08:42:28.628016Z"},"papermill":{"duration":0.983356,"end_time":"2023-07-02T08:42:28.632334","exception":false,"start_time":"2023-07-02T08:42:27.648978","status":"completed"},"tags":[]},"outputs":[],"source":["train_data = P_Dataset(datatype = \"train\")"]},{"cell_type":"code","execution_count":16,"id":"106507bd","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:28.667516Z","iopub.status.busy":"2023-07-02T08:42:28.667122Z","iopub.status.idle":"2023-07-02T08:42:28.673841Z","shell.execute_reply":"2023-07-02T08:42:28.672247Z"},"papermill":{"duration":0.027636,"end_time":"2023-07-02T08:42:28.676294","exception":false,"start_time":"2023-07-02T08:42:28.648658","status":"completed"},"tags":[]},"outputs":[],"source":["train_dataloader = torch.utils.data.DataLoader(train_data , batch_size = 128 , shuffle = True)"]},{"cell_type":"markdown","id":"fcd00c58","metadata":{"papermill":{"duration":0.014185,"end_time":"2023-07-02T08:42:28.705224","exception":false,"start_time":"2023-07-02T08:42:28.691039","status":"completed"},"tags":[]},"source":["# 4 | Model Setup \n","\n","Now we will train Simple models, and see the results\n","\n","# 4.1 | MultiLayerPerceptron \n","\n","A `MultiLayerPerceptron` is a simple model, which consists of just few perceptrons/nodes/neurons connected with each other. \n","\n","As we have choosen for the `top-500` targets, our last layer of the network will contain 500 perceptrons, "]},{"cell_type":"code","execution_count":17,"id":"9db1e8be","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:28.736376Z","iopub.status.busy":"2023-07-02T08:42:28.735896Z","iopub.status.idle":"2023-07-02T08:42:28.747385Z","shell.execute_reply":"2023-07-02T08:42:28.745932Z"},"papermill":{"duration":0.030333,"end_time":"2023-07-02T08:42:28.750001","exception":false,"start_time":"2023-07-02T08:42:28.719668","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiLayerPerceptron(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(MultiLayerPerceptron, self).__init__()\n","\n","        self.linear1 = torch.nn.Linear(1024 , 1012)\n","        self.activation1 = torch.nn.ReLU()\n","        self.linear2 = torch.nn.Linear(1012 , 712)\n","        self.activation2 = torch.nn.ReLU()\n","        self.linear3 = torch.nn.Linear(712 , 500)\n","\n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.activation1(x)\n","        x = self.linear2(x)\n","        x = self.activation2(x)\n","        x = self.linear3(x)\n","        return x"]},{"cell_type":"markdown","id":"f4084166","metadata":{"papermill":{"duration":0.01516,"end_time":"2023-07-02T08:42:28.780438","exception":false,"start_time":"2023-07-02T08:42:28.765278","status":"completed"},"tags":[]},"source":["I cannot use `Kaggle GPUs` for some reason (I dont know why), so I will be commenting the `cuda` parts "]},{"cell_type":"code","execution_count":18,"id":"8a9762b7","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:28.815903Z","iopub.status.busy":"2023-07-02T08:42:28.814548Z","iopub.status.idle":"2023-07-02T08:42:28.882982Z","shell.execute_reply":"2023-07-02T08:42:28.881526Z"},"papermill":{"duration":0.08916,"end_time":"2023-07-02T08:42:28.886469","exception":false,"start_time":"2023-07-02T08:42:28.797309","status":"completed"},"tags":[]},"outputs":[],"source":["MLP = MultiLayerPerceptron()\n","\n","# MLP = MultiLayerPerceptron().to(\"cuda\")"]},{"cell_type":"markdown","id":"2942ded6","metadata":{"papermill":{"duration":0.015439,"end_time":"2023-07-02T08:42:28.917422","exception":false,"start_time":"2023-07-02T08:42:28.901983","status":"completed"},"tags":[]},"source":["# 5 | Loss Function \n","\n","$Loss$ is a `measure` of `how well a model is performing` on a given task. It is `calculated` by `comparing` the `model's predictions` to the `ground truth labels`. The `lower the loss`, the `better the model` is performing.\n","\n","Here we will be using `Cross Entropy Loss` , a loss function that `measures` the `difference` between the `model's predicted probability distribution` and the `ground truth distribution`."]},{"cell_type":"code","execution_count":19,"id":"d7aacb88","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:28.95017Z","iopub.status.busy":"2023-07-02T08:42:28.949718Z","iopub.status.idle":"2023-07-02T08:42:28.955473Z","shell.execute_reply":"2023-07-02T08:42:28.954142Z"},"papermill":{"duration":0.025566,"end_time":"2023-07-02T08:42:28.958356","exception":false,"start_time":"2023-07-02T08:42:28.93279","status":"completed"},"tags":[]},"outputs":[],"source":["CrossEntropy = torch.nn.CrossEntropyLoss()"]},{"cell_type":"markdown","id":"b1c99208","metadata":{"papermill":{"duration":0.01499,"end_time":"2023-07-02T08:42:28.988108","exception":false,"start_time":"2023-07-02T08:42:28.973118","status":"completed"},"tags":[]},"source":["# 6 | Optimizer \n","\n","An $Optimizer$ is an `algorithm` or function that `updates the weights and biases` of a neural network in order to `minimize a loss function`. \n","\n","Here we will be using the `Adam Optimizer`\n","\n","$Adam$ is an $Adaptive$ $Learning$ $Rate$ method, which works by `maintaining two moving averages of the gradients`\n","* $Mean$ - Calculate the `momentum term`, which helps to `prevent` the `optimizer` from `getting stuck in local minima`\n","* $Variance$ - Calculate the `learning rate`, which is `adjusted based on the magnitude of the gradients`.\n","\n","$$m_t = \\beta_1 * m_{t - 1} + (1 - \\beta_1) * w_t$$\n","\n","$$v_t = \\beta_2 * m_{t - 1} + (1 - \\beta_2) * w_t$$\n","\n","$$m_t = \\frac{m_t}{1 - \\beta_1^t}$$\n","\n","$$v_t = \\frac{v_t}{1 - \\beta_2^t}$$\n","\n","$$w_{t+1} = w_t - \\frac{n}{\\sqrt{v_t + e}} * m_t$$"]},{"cell_type":"code","execution_count":20,"id":"4262ad51","metadata":{"execution":{"iopub.execute_input":"2023-07-02T08:42:29.021938Z","iopub.status.busy":"2023-07-02T08:42:29.021526Z","iopub.status.idle":"2023-07-02T08:42:29.027071Z","shell.execute_reply":"2023-07-02T08:42:29.026102Z"},"papermill":{"duration":0.025959,"end_time":"2023-07-02T08:42:29.029459","exception":false,"start_time":"2023-07-02T08:42:29.0035","status":"completed"},"tags":[]},"outputs":[],"source":["optimizer = torch.optim.Adam(MLP.parameters(), lr = 0.0005)"]},{"cell_type":"markdown","id":"68ed0199","metadata":{"papermill":{"duration":0.015477,"end_time":"2023-07-02T08:42:29.060747","exception":false,"start_time":"2023-07-02T08:42:29.04527","status":"completed"},"tags":[]},"source":["# 7 | Training Loop  "]},{"cell_type":"code","execution_count":21,"id":"e0abfba1","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-02T08:42:29.094235Z","iopub.status.busy":"2023-07-02T08:42:29.093536Z","iopub.status.idle":"2023-07-02T08:42:29.097984Z","shell.execute_reply":"2023-07-02T08:42:29.096914Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.024628,"end_time":"2023-07-02T08:42:29.100457","exception":false,"start_time":"2023-07-02T08:42:29.075829","status":"completed"},"tags":[]},"outputs":[],"source":["from IPython.display import IFrame"]},{"cell_type":"markdown","id":"db30d04e","metadata":{"papermill":{"duration":0.01534,"end_time":"2023-07-02T08:42:29.130912","exception":false,"start_time":"2023-07-02T08:42:29.115572","status":"completed"},"tags":[]},"source":["Now we will start the training loop \n","\n","I dont the exact reason, but everytime I try to access `GPU` for some training in `Kaggle`. `CUDA goes out of memory`. Thus I have trained the model on `Colab` and will imported the results to `Wandb`."]},{"cell_type":"markdown","id":"7542a56d","metadata":{"papermill":{"duration":0.015361,"end_time":"2023-07-02T08:42:29.161484","exception":false,"start_time":"2023-07-02T08:42:29.146123","status":"completed"},"tags":[]},"source":["```\n","los = []\n","\n","for epochs in (range(5)):\n","\n","    losses = []\n","\n","    for x , y in tqdm.tqdm(train_dataloader):\n","        \n","        x = torch.tensor(x , dtype = torch.float32)\n","        y = torch.tensor(x , dtype = troch.float32)\n","        \n","        \n","#         x = torch.tensor(x , dtype = torch.float32).to(\"cuda\")\n","#         y = torch.tensor(y , dtype = torch.float32).to(\"cuda\")\n","\n","        optimizer.zero_grad()\n","        preds = model(x)\n","\n","        loss = CrossEntropy(preds, y)\n","        losses.append(loss)\n","\n","    los.append(losses)\n","```"]},{"cell_type":"markdown","id":"8140ce69","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":0.014427,"end_time":"2023-07-02T08:42:29.191673","exception":false,"start_time":"2023-07-02T08:42:29.177246","status":"completed"},"tags":[]},"source":["```\n","---------------------------------------------------------------------------\n","OutOfMemoryError                          Traceback (most recent call last)\n","Cell In[31], line 15\n","     12 img = img.to(\"cuda\")\n","     13 mask = mask.to(\"cuda\")\n","---> 15 outputs = model(img)  \n","     17 loss =  loss_func(outputs , mask)\n","     19 loss.backward()\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py:29, in SegmentationModel.forward(self, x)\n","     25 \"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\n","     27 self.check_input_shape(x)\n","---> 29 features = self.encoder(x)\n","     30 decoder_output = self.decoder(*features)\n","     32 masks = self.segmentation_head(decoder_output)\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/efficientnet.py:73, in EfficientNetEncoder.forward(self, x)\n","     71             drop_connect = drop_connect_rate * block_number / len(self._blocks)\n","     72             block_number += 1.0\n","---> 73             x = module(x, drop_connect)\n","     75     features.append(x)\n","     77 return features\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/efficientnet_pytorch/model.py:111, in MBConvBlock.forward(self, inputs, drop_connect_rate)\n","    109 x = self._depthwise_conv(x)\n","    110 x = self._bn1(x)\n","--> 111 x = self._swish(x)\n","    113 # Squeeze and Excitation\n","    114 if self.has_se:\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n","   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n","   1497 # this function, and just call forward.\n","   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n","   1499         or _global_backward_pre_hooks or _global_backward_hooks\n","   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n","-> 1501     return forward_call(*args, **kwargs)\n","   1502 # Do not call functions when jit is used\n","   1503 full_backward_hooks, non_full_backward_hooks = [], []\n","\n","File /opt/conda/lib/python3.10/site-packages/efficientnet_pytorch/utils.py:80, in MemoryEfficientSwish.forward(self, x)\n","     79 def forward(self, x):\n","---> 80     return SwishImplementation.apply(x)\n","\n","File /opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:506, in Function.apply(cls, *args, **kwargs)\n","    503 if not torch._C._are_functorch_transforms_active():\n","    504     # See NOTE: [functorch vjp and autograd interaction]\n","    505     args = _functorch.utils.unwrap_dead_wrappers(args)\n","--> 506     return super().apply(*args, **kwargs)  # type: ignore[misc]\n","    508 if cls.setup_context == _SingleLevelFunction.setup_context:\n","    509     raise RuntimeError(\n","    510         'In order to use an autograd.Function with functorch transforms '\n","    511         '(vmap, grad, jvp, jacrev, ...), it must override the setup_context '\n","    512         'staticmethod. For more details, please see '\n","    513         'https://pytorch.org/docs/master/notes/extending.func.html style=\"color:rgb(175,0,0)\">')\n","\n","File /opt/conda/lib/python3.10/site-packages/efficientnet_pytorch/utils.py:67, in SwishImplementation.forward(ctx, i)\n","     65 @staticmethod\n","     66 def forward(ctx, i):\n","---> 67     result = i * torch.sigmoid(i)\n","     68     ctx.save_for_backward(i)\n","     69     return result\n","\n","OutOfMemoryError: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 15.90 GiB total capacity; 319.37 MiB already allocated; 7.75 MiB free; 326.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","```"]},{"cell_type":"code","execution_count":22,"id":"b1d64290","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-02T08:42:29.222838Z","iopub.status.busy":"2023-07-02T08:42:29.222406Z","iopub.status.idle":"2023-07-02T08:42:29.229797Z","shell.execute_reply":"2023-07-02T08:42:29.228492Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.025979,"end_time":"2023-07-02T08:42:29.232241","exception":false,"start_time":"2023-07-02T08:42:29.206262","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["\n","        <iframe\n","            width=\"1300\"\n","            height=\"400\"\n","            src=\"https://wandb.ai//ayushsinghal659/CAFA/reports/CAFA-Multi-Layer-Perceptron--Vmlldzo0NzgyMTgy\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x78c8b7f9e2c0>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["IFrame(\"https://wandb.ai//ayushsinghal659/CAFA/reports/CAFA-Multi-Layer-Perceptron--Vmlldzo0NzgyMTgy\" , 1300 , 400)"]},{"cell_type":"markdown","id":"930d5f57","metadata":{"papermill":{"duration":0.014503,"end_time":"2023-07-02T08:42:29.261485","exception":false,"start_time":"2023-07-02T08:42:29.246982","status":"completed"},"tags":[]},"source":["As we can see we did not get good results, but we will try to omprove our results, by improving the model and by adding new one "]},{"cell_type":"markdown","id":"370220cf","metadata":{"papermill":{"duration":0.014515,"end_time":"2023-07-02T08:42:29.290989","exception":false,"start_time":"2023-07-02T08:42:29.276474","status":"completed"},"tags":[]},"source":["# 8 | TO DO LIST üìÑ\n","\n","```\n","TO DO 1 : VISUALIZE THE DATA\n","\n","TO DO 2 : TRAIN A MODEL\n","\n","TO DO 3 : TRY DIFFERENT MODELS\n","\n","TO DO 4 : ADD WANDB SUPPORT\n","\n","TO DO 5 : ADD TENSORFLOW DATA LOADER\n","\n","TO DO 6 : TRAIN A TF MODEL\n","\n","TO DO 7 : IMPROVE RESULTS\n","\n","TO DO 8 : DECREASE TRAINING TIME\n","\n","TO DO 9 : DANCE \n","```\n","\n","# 9 | Ending üèÅ\n","\n","**THAT'S IT FOR TODAY GUYS**\n","\n","**WE WILL GO DEEPER INTO THE DATA IN THE UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT YOUR THOUGHTS, HIHGLY APPRICIATED**\n","\n","**DONT FORGET TO MAKE AN UPVOTE, IF YOU LIKED MY WORK $:)$**\n","\n","<img src = \"https://i.imgflip.com/19aadg.jpg\">\n","\n","**PEACE OUT $:)$**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"papermill":{"default_parameters":{},"duration":44.400523,"end_time":"2023-07-02T08:42:30.832449","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-02T08:41:46.431926","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}