{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ayushs9020/winning-solution-commonlit-readibility?scriptVersionId=136997398\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"e16c46e9","metadata":{"papermill":{"duration":0.013968,"end_time":"2023-07-17T05:59:51.354834","exception":false,"start_time":"2023-07-17T05:59:51.340866","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FF0000; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FF0000\">1 | Important Points ‚úÖ</p>\n","\n","<div style=\"border-radius:10px; border:#FF0000 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = \"https://media.tenor.com/pfcqgFEp2OsAAAAM/welcome.gif\">\n","    \n","Before we move any further there are some `important points` I want to mention to `avoid` any `misunderstanding`\n","* As the title says, this notebook is a `short implimentation` of **1st Prize Solution of [CommonLit Readability Prize](https://www.kaggle.com/c/commonlitreadabilityprize)**, do not get `confused` between the competition names\n","* I have tried to take a `tutorial based approach` for this notebook, which makes this a `little bit larger`. Use the `table of contents` to switch between `different pannels` of the notebook. \n","* The code used here is a small version of the **[mathislucka](https://github.com/mathislucka/kaggle_clrp_1st_place_solution)**"]},{"cell_type":"markdown","id":"45ef021f","metadata":{"papermill":{"duration":0.012036,"end_time":"2023-07-17T05:59:51.379843","exception":false,"start_time":"2023-07-17T05:59:51.367807","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#006600; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">2 | Basic Terminologies üëã</p>\n","\n","<div style=\"border-radius:10px; border:#DEB887 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = \"https://i.pinimg.com/originals/27/9b/3d/279b3dc2745c014e9c4845a3edf70175.jpg\" width = 400>\n","\n","First lets get through some basic terminologies that are used in the feild\n","* $Tokenization/Embedments$\n","* $Transformers$\n","* $Bidirectional$ $Encoded$ $Representation$ $from$ $Transformers$\n","    \n","## $2.1$ $|$ $Tokenization/Embedments$\n","    \n","Lets assume we have a text like `Gender was the concept introduced by Bathroom companies to sell more Bathrooms`\n","    \n","Lets think that how can we use this `text` as `peice of information` for a digital system. Or in other words. How can we make a `digital system understand this text` \n","    \n","We all know that there $26$, unique alphabets in the `English Language`. Lets assume we are `case-sensetive` and treat `small` and `capital` characters differently, making our known charachters to be $52$, adding special characrers like `. , , , # , {}` and more. Lets assume we reach $70$ characters. \n","    \n","So to crack the problem we had, we map each `distinct character` with a `unique number`. Like for `A` it is $1$, for `B` it is $2$, for `a` to be $27$, and many more. So we kind of mapped our `peice of information` in `numbers`. \n","    \n","In basic terminologies, the \n","\n","|Simple Meaning|Complex Terminology |\n","|---|---|\n","|Universal Set of whole Data|Corpus|\n","|Set of Distinct elements|Vocablury\n","    \n","What we just did was a simple technique called $Bag$ $Of$ $Words$. In this we map each character to a predefined number. One thing to notice here is **Bag of Words do not consider any context**. Bag of words will concider `r` in `racist` and `racer` the same. Just try to remeber this information\n","    \n","Okay so I got an fantastic Idea!!!.\n","\n","Okay so we know that when we `combine characters`, we get `words`. This is called `English Language`. So if we combine the characters `S`/`h`/`r`/`e`/`k`. We will get the word `Shrek`. So the way we know that how many distinct characters are there the `English Language`, what if we somehow get the information of all the distinct `Words` in the `English Language`. Our corpus will increase massively, and so will our size of the `vocublray`. But lets just assume a text (Song **[Choo Lo - The Local Train](https://youtu.be/sFMRqxCexDk)** with English Lyrics)\n","    \n","```\n","I am still standing here today,\n","With hope in my heart.\n","How is this freedom?\n","How is this thirst of the heart?\n","Touch me, whoever you are,\n","I will lose myself day and night.\n","```\n","    \n","Just think a list of numbers representing the `unique characters`/vs, a list of numbers represnting `unique words`. The second list will sure be a smaller one. A smaller list representing the same amount of information will be surely much easier to interpret or apply any mathematical transnformation. The same concept is applied in the **[Sentence Piece by Google](https://github.com/google/sentencepiece)**\n","    \n","But there is a problem with these. The do not retain the contextual meaning of the sentence. Lets assume we have $2$ Sentences like \n","    \n","```\n","Sentence_1 = \"Osama Bin Laden had arms\"\n","Sentence_2 = \"I cut Osama Bin Laden arms\"\n","```\n","Both the sentence contains the word `arms`, but have a very different meaning in both of the Sentence. At first it is in the context of `Weapons` and in other it is in the context of `Hand`. This type of problem is not solved here. \n","    \n","Thats why we use `Neural Networks` to solve this issue. We use different technique like \n","* $Sementic$ $Prediction$\n","* $Next$ $Sentence$ $Prediction$\n","* $Question$ $Answering$\n","\n","to make an Vector Represnetation of Words.\n","    \n","**Wait Wait Wait$!!!$** At `First` we were converting `Words to Numbers`. So now why we are using the `complex word` `Vectors`$...?$ \n","\n","The reason is at `First` we were only `converting words` to **a single number**, but now we are `converting one word` to a `list of numbers`. These numbers try to represent `every possible context` of the word in a corpus. The technique that first used a `Neural Network` is called `Word 2 Vec`. which became very popular. \n","    \n","One thing to notice is that.\n","    \n","* When we are seperating different distinct characters according to the vocablury, we call that `Tokenization`\n","* When we are converting these tokens into numbers, we call that `Embedments`. \n","    \n","Just some wierd word to make us think that $NLP$ is `difficult`.\n","    \n","## $2.2$ $|$ $Transformers$\n","    \n","So `Word 2 Vec` was introduced by `Google` in $2013$ and till then, we have applied different concepts to overcome various difficulties, which include\n","    \n","* $Small$ $Batch$ $Size$\n","* $Small$ $Window$ $Size$\n","* $Small$ $Context$ $Size$\n","* $Large$ $Training$ $Time$\n","* $Less$ $Accuracy$\n","    \n","We introduced different techniques to handle this like $LSTMs$/$GRUs$ and much more, which had their own `cons and pros`. But in $2017$, the whole $NLP$ community was shook, when **[Google](https://i.redd.it/sojit7ho93b31.jpg)** released the paper **[Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf)**, which introduced a `Neural Network Arcthitecture` called `Trasnformers` to get the embeddings for a corpus. The concept was simple \n","    \n","<img src = \"https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png\" width = 400>\n","    \n","\n","Pass the Embeddings to $3$ different `Neural Networks`. Lets for fun call them `Heads` named as `Key`/`Query`/`Value`. These $3$ heads will be reseponsible for different types of information. And then we connect these with a group of different Layers to extract more information. Additionaly to extract information from , we will use a formula $$softmax(\\frac{KQ_T}{\\sqrt{d_k}})$$.\n","\n","Lets seperate this diagram into $2$ parts. \n","* $Encoder$ - `Responsible` for `processing` the `input sequence` and `producing` a `Continuous Representation` of the input. This `representation` is then used by the `decoder` to `generate the output` sequence.\n","\n","The encoder consists of a stack of encoder layers, where each layer is composed of two sublayers:\n","\n","* * $Self-Attention$ $Sublayer$ - This sublayer allows the encoder to `attend to different parts` of the `input sequence` and learn the `relationships between them`.\n","* * $Feed-Forward$ $Sublayer$ - This sublayer applies a `linear transformation` to the `output` of the `self-attention sublayer`, which helps to further refine the representation of the input sequence.\n","\n","* $Decoder$ - The `Decoder` part of a transformer is a `Neural Network Architecture` that is responsible for generating the `output sequence` for `Natural Language Processing tasks`. It takes the `hidden states` generated by the `encoder` and the `previously generated output tokens` as input and uses them to `predict the next output token`.\n","\n","I know this information is kind of wierd at first, but that was the shortest and most to the point I could have gone. The notebook had went really long, if it was from sratch\n","    \n","## $2.3$ $|$ $Bidirectional$ $Encoded$ $Representation$ $from$ $Transformer$ $(BERT)$\n","    \n","$Bidirectional$ $Encoded$ $Representation$ $from$ $Transformer$ $(BERT)$ is like taking the Encoder part of the transformer and stking multiple upon each other. \n","    \n","There is more information on BERT but i think this much information is enough for this notebook"]},{"cell_type":"markdown","id":"c493cc80","metadata":{"papermill":{"duration":0.012131,"end_time":"2023-07-17T05:59:51.404479","exception":false,"start_time":"2023-07-17T05:59:51.392348","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#00FFFF; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #00FFFF\">3 | Data üìä</p>\n","\n","<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = \"https://149695847.v2.pressablecdn.com/wp-content/uploads/2017/06/Trump_Big_Data_Meme.jpg\" width = 400>\n","\n","Now lets dive into the data\n","\n","We will just focus on `Train`"]},{"cell_type":"code","execution_count":1,"id":"fda823f1","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"collapsed":true,"execution":{"iopub.execute_input":"2023-07-17T05:59:51.431326Z","iopub.status.busy":"2023-07-17T05:59:51.430583Z","iopub.status.idle":"2023-07-17T05:59:51.503648Z","shell.execute_reply":"2023-07-17T05:59:51.502168Z"},"jupyter":{"outputs_hidden":true},"papermill":{"duration":0.090023,"end_time":"2023-07-17T05:59:51.506749","exception":false,"start_time":"2023-07-17T05:59:51.416726","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/common-lit-sample-fold-embeds/Embeds/2/Val/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/2/Val/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/2/Val/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/2/Train/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/2/Train/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/2/Train/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/5/Val/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/5/Val/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/5/Val/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/5/Train/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/5/Train/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/5/Train/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/0/Val/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/0/Val/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/0/Val/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/0/Train/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/0/Train/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/0/Train/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/3/Val/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/3/Val/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/3/Val/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/3/Train/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/3/Train/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/3/Train/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/1/Val/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/1/Val/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/1/Val/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/1/Train/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/1/Train/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/1/Train/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/4/Val/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/4/Val/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/4/Val/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/4/Train/Content.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/4/Train/Embeds.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Embeds/4/Train/Wording.npy\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Val/Val_2.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Val/Val_1.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Val/Val_5.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Val/Val_3.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Val/Val_4.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Val/Val_0.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Train/Train_3.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Train/Train_4.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Train/Train_5.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Train/Train_2.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Train/Train_0.csv\n","/kaggle/input/common-lit-sample-fold-embeds/Bags/Train/Train_1.csv\n","/kaggle/input/commonlit-evaluate-student-summaries/sample_submission.csv\n","/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\n","/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv\n","/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\n","/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv\n"]}],"source":["import pandas as pd \n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"markdown","id":"53152db9","metadata":{"papermill":{"duration":0.012922,"end_time":"2023-07-17T05:59:51.533207","exception":false,"start_time":"2023-07-17T05:59:51.520285","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","## $3.1$ $|$ $Train$\n"," \n","We have our training data in two different directories prompts_train/summaries_train"]},{"cell_type":"code","execution_count":2,"id":"12cc168a","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:51.561262Z","iopub.status.busy":"2023-07-17T05:59:51.560514Z","iopub.status.idle":"2023-07-17T05:59:51.59499Z","shell.execute_reply":"2023-07-17T05:59:51.59372Z"},"papermill":{"duration":0.05052,"end_time":"2023-07-17T05:59:51.597203","exception":false,"start_time":"2023-07-17T05:59:51.546683","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_id</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3b9047</td>\n","      <td>In complete sentences, summarize the structure...</td>\n","      <td>Egyptian Social Structure</td>\n","      <td>Egyptian society was structured like a pyramid...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>814d6b</td>\n","      <td>Summarize how the Third Wave developed over su...</td>\n","      <td>The Third Wave</td>\n","      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ebad26</td>\n","      <td>Summarize the various ways the factory would u...</td>\n","      <td>Excerpt from The Jungle</td>\n","      <td>With one member trimming beef in a cannery, an...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  prompt_id                                    prompt_question  \\\n","0    39c16e  Summarize at least 3 elements of an ideal trag...   \n","1    3b9047  In complete sentences, summarize the structure...   \n","2    814d6b  Summarize how the Third Wave developed over su...   \n","3    ebad26  Summarize the various ways the factory would u...   \n","\n","                prompt_title  \\\n","0                 On Tragedy   \n","1  Egyptian Social Structure   \n","2             The Third Wave   \n","3    Excerpt from The Jungle   \n","\n","                                         prompt_text  \n","0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n","1  Egyptian society was structured like a pyramid...  \n","2  Background \\r\\nThe Third Wave experiment took ...  \n","3  With one member trimming beef in a cannery, an...  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train_pro = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\")\n","train_pro"]},{"cell_type":"markdown","id":"4f52a6ef","metadata":{"papermill":{"duration":0.013985,"end_time":"2023-07-17T05:59:51.624723","exception":false,"start_time":"2023-07-17T05:59:51.610738","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","This file contains the actual text values given by the children as the answers to the prompt"]},{"cell_type":"code","execution_count":3,"id":"c6c431f1","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:51.654131Z","iopub.status.busy":"2023-07-17T05:59:51.653618Z","iopub.status.idle":"2023-07-17T05:59:51.768266Z","shell.execute_reply":"2023-07-17T05:59:51.767204Z"},"papermill":{"duration":0.132719,"end_time":"2023-07-17T05:59:51.771244","exception":false,"start_time":"2023-07-17T05:59:51.638525","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e8c3c7ddb</td>\n","      <td>814d6b</td>\n","      <td>The third wave was an experimentto see how peo...</td>\n","      <td>0.205683</td>\n","      <td>0.380538</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0020ae56ffbf</td>\n","      <td>ebad26</td>\n","      <td>They would rub it up with soda to make the sme...</td>\n","      <td>-0.548304</td>\n","      <td>0.506755</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004e978e639e</td>\n","      <td>3b9047</td>\n","      <td>In Egypt, there were many occupations and soci...</td>\n","      <td>3.128928</td>\n","      <td>4.231226</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005ab0199905</td>\n","      <td>3b9047</td>\n","      <td>The highest class was Pharaohs these people we...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0070c9e7af47</td>\n","      <td>814d6b</td>\n","      <td>The Third Wave developed  rapidly because the ...</td>\n","      <td>3.272894</td>\n","      <td>3.219757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id prompt_id                                               text  \\\n","0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n","1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n","2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n","3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n","4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n","\n","    content   wording  \n","0  0.205683  0.380538  \n","1 -0.548304  0.506755  \n","2  3.128928  4.231226  \n","3 -0.210614 -0.471415  \n","4  3.272894  3.219757  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["train_sum = pd.read_csv(\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\")\n","train_sum.head()"]},{"cell_type":"markdown","id":"546c24a4","metadata":{"papermill":{"duration":0.013186,"end_time":"2023-07-17T05:59:51.798115","exception":false,"start_time":"2023-07-17T05:59:51.784929","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#800080; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #800080\">4 | Data Preperations üìÑÔ∏è</p>\n","\n","<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = \"https://media.makeameme.org/created/preparation-is-the.jpg\" width = 300>\n","\n","We will first combine the $2$ dataframes to get the actual `Training Set`"]},{"cell_type":"code","execution_count":4,"id":"59757f39","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-17T05:59:51.826009Z","iopub.status.busy":"2023-07-17T05:59:51.825583Z","iopub.status.idle":"2023-07-17T05:59:53.160008Z","shell.execute_reply":"2023-07-17T05:59:53.158253Z"},"papermill":{"duration":1.351368,"end_time":"2023-07-17T05:59:53.162754","exception":false,"start_time":"2023-07-17T05:59:51.811386","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import tqdm\n","from sklearn.model_selection import StratifiedKFold"]},{"cell_type":"code","execution_count":5,"id":"d311e6b5","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.191663Z","iopub.status.busy":"2023-07-17T05:59:53.191189Z","iopub.status.idle":"2023-07-17T05:59:53.224822Z","shell.execute_reply":"2023-07-17T05:59:53.22361Z"},"papermill":{"duration":0.050799,"end_time":"2023-07-17T05:59:53.227291","exception":false,"start_time":"2023-07-17T05:59:53.176492","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_id</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","      <th>student_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00791789cc1f</td>\n","      <td>1 element of an ideal tragedy is that it shoul...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>0086ef22de8f</td>\n","      <td>The three elements of an ideal tragedy are:  H...</td>\n","      <td>-0.970237</td>\n","      <td>-0.417058</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>0094589c7a22</td>\n","      <td>Aristotle states that an ideal tragedy should ...</td>\n","      <td>-0.387791</td>\n","      <td>-0.584181</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00cd5736026a</td>\n","      <td>One element of an Ideal tragedy is having a co...</td>\n","      <td>0.088882</td>\n","      <td>-0.594710</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00d98b8ff756</td>\n","      <td>The 3 ideal of tragedy is how complex you need...</td>\n","      <td>-0.687288</td>\n","      <td>-0.460886</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  prompt_id                                    prompt_question prompt_title  \\\n","0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","2    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","3    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","4    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n","\n","                                         prompt_text    student_id  \\\n","0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n","1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n","2  Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22   \n","3  Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a   \n","4  Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756   \n","\n","                                                text   content   wording  \n","0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n","1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n","2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  \n","3  One element of an Ideal tragedy is having a co...  0.088882 -0.594710  \n","4  The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train = train_pro.merge(train_sum , on = \"prompt_id\")\n","train.head()"]},{"cell_type":"markdown","id":"89f3a37b","metadata":{"papermill":{"duration":0.012946,"end_time":"2023-07-17T05:59:53.253599","exception":false,"start_time":"2023-07-17T05:59:53.240653","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets make a function, cause we will be using that afterwards"]},{"cell_type":"code","execution_count":6,"id":"9a7dc294","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.282553Z","iopub.status.busy":"2023-07-17T05:59:53.282155Z","iopub.status.idle":"2023-07-17T05:59:53.287151Z","shell.execute_reply":"2023-07-17T05:59:53.285926Z"},"papermill":{"duration":0.022839,"end_time":"2023-07-17T05:59:53.289692","exception":false,"start_time":"2023-07-17T05:59:53.266853","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap():pass"]},{"cell_type":"markdown","id":"f1d9502d","metadata":{"papermill":{"duration":0.013883,"end_time":"2023-07-17T05:59:53.318274","exception":false,"start_time":"2023-07-17T05:59:53.304391","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets make a sample of dataframe to work on "]},{"cell_type":"code","execution_count":7,"id":"1956d6a8","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.349372Z","iopub.status.busy":"2023-07-17T05:59:53.348957Z","iopub.status.idle":"2023-07-17T05:59:53.353866Z","shell.execute_reply":"2023-07-17T05:59:53.352689Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.024556,"end_time":"2023-07-17T05:59:53.356885","exception":false,"start_time":"2023-07-17T05:59:53.332329","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap():\n","\n","    sample_train = train.sample(n = train.shape[0] , replace = True)"]},{"cell_type":"markdown","id":"76391a0f","metadata":{"papermill":{"duration":0.014015,"end_time":"2023-07-17T05:59:53.38541","exception":false,"start_time":"2023-07-17T05:59:53.371395","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will make a sample validation set for this specific training data "]},{"cell_type":"code","execution_count":8,"id":"8ad87567","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.414864Z","iopub.status.busy":"2023-07-17T05:59:53.414423Z","iopub.status.idle":"2023-07-17T05:59:53.420627Z","shell.execute_reply":"2023-07-17T05:59:53.419296Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.023981,"end_time":"2023-07-17T05:59:53.423279","exception":false,"start_time":"2023-07-17T05:59:53.399298","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap():\n","\n","    sample_train = train.sample(n = train.shape[0] , replace = True)\n","    \n","    sample_val = train[~train[\"student_id\"].isin(sample_train[\"student_id\"])]"]},{"cell_type":"markdown","id":"be3899f3","metadata":{"papermill":{"duration":0.013959,"end_time":"2023-07-17T05:59:53.450537","exception":false,"start_time":"2023-07-17T05:59:53.436578","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets save these files in output dir"]},{"cell_type":"code","execution_count":9,"id":"33027695","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.48231Z","iopub.status.busy":"2023-07-17T05:59:53.481926Z","iopub.status.idle":"2023-07-17T05:59:53.489146Z","shell.execute_reply":"2023-07-17T05:59:53.487531Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.026285,"end_time":"2023-07-17T05:59:53.491983","exception":false,"start_time":"2023-07-17T05:59:53.465698","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap():\n","\n","    sample_train = train.sample(n = train.shape[0] , replace = True)\n","    \n","    sample_val = train[~train[\"student_id\"].isin(sample_train[\"student_id\"])]\n","    \n","    sample_train.to_csv(\"/kaggle/working/PseudoDir/Sample_train\")\n","    sample_val.to_csv(\"/kaggle/working/PseudoDir/Sample_val\")"]},{"cell_type":"markdown","id":"bc0a771f","metadata":{"papermill":{"duration":0.013335,"end_time":"2023-07-17T05:59:53.519762","exception":false,"start_time":"2023-07-17T05:59:53.506427","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will make bins for data for better efficiency\n","Lets make $5$ bins for sample"]},{"cell_type":"code","execution_count":10,"id":"b37eca13","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.548622Z","iopub.status.busy":"2023-07-17T05:59:53.548181Z","iopub.status.idle":"2023-07-17T05:59:53.555962Z","shell.execute_reply":"2023-07-17T05:59:53.554255Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.025258,"end_time":"2023-07-17T05:59:53.558274","exception":false,"start_time":"2023-07-17T05:59:53.533016","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap():\n","\n","    sample_train = train.sample(n = train.shape[0] , replace = True)\n","    \n","    sample_val = train[~train[\"student_id\"].isin(sample_train[\"student_id\"])]\n","    \n","    sample_train.to_csv(\"/kaggle/working/PseudoDir/Sample_train\")\n","    sample_val.to_csv(\"/kaggle/working/PseudoDir/Sample_val\")\n","    \n","    train[\"bins\"] = pd.cut(train[\"target\"] , 5 , labels = [bins for bins in range(5)])"]},{"cell_type":"markdown","id":"c1f9fc38","metadata":{"papermill":{"duration":0.012899,"end_time":"2023-07-17T05:59:53.584542","exception":false,"start_time":"2023-07-17T05:59:53.571643","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will make different `Folds` for the data so that we can understand different unique information from every fold "]},{"cell_type":"code","execution_count":11,"id":"d14127fa","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.613897Z","iopub.status.busy":"2023-07-17T05:59:53.613483Z","iopub.status.idle":"2023-07-17T05:59:53.621887Z","shell.execute_reply":"2023-07-17T05:59:53.620367Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.025686,"end_time":"2023-07-17T05:59:53.624537","exception":false,"start_time":"2023-07-17T05:59:53.598851","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap():\n","\n","    sample_train = train.sample(n = train.shape[0] , replace = True)\n","    \n","    sample_val = train[~train[\"student_id\"].isin(sample_train[\"student_id\"])]\n","    \n","    sample_train.to_csv(\"/kaggle/working/PseudoDir/Sample_train\")\n","    sample_val.to_csv(\"/kaggle/working/PseudoDir/Sample_val\")\n","    \n","    train[\"bins\"] = pd.cut(train[\"target\"] , 5 , labels = [bins for bins in range(5)])\n","    \n","    skf = StrattifiedKFold(n_splits = 5 , shuffle = True)\n","    gen_skf = skf.split(train[\"student_id\"] , y = train[\"bins\"])"]},{"cell_type":"markdown","id":"23c88ebf","metadata":{"papermill":{"duration":0.01297,"end_time":"2023-07-17T05:59:53.650901","exception":false,"start_time":"2023-07-17T05:59:53.637931","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will $2$ different versions of the data, the first one will compare all the values in the bin except $1$, and the second one will contain all the samples from that $1$ left overclass"]},{"cell_type":"code","execution_count":12,"id":"d5d1d760","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.679228Z","iopub.status.busy":"2023-07-17T05:59:53.678869Z","iopub.status.idle":"2023-07-17T05:59:53.687154Z","shell.execute_reply":"2023-07-17T05:59:53.685871Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.025653,"end_time":"2023-07-17T05:59:53.689815","exception":false,"start_time":"2023-07-17T05:59:53.664162","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap():\n","\n","    sample_train = train.sample(n = train.shape[0] , replace = True)\n","    \n","    sample_val = train[~train[\"student_id\"].isin(sample_train[\"student_id\"])]\n","    \n","    sample_train.to_csv(\"/kaggle/working/PseudoDir/Sample_train\")\n","    sample_val.to_csv(\"/kaggle/working/PseudoDir/Sample_val\")\n","    \n","    train[\"bins\"] = pd.cut(train[\"target\"] , 5 , labels = [bins for bins in range(5)])\n","    \n","    skf = StrattifiedKFold(n_splits = 5 , shuffle = True)\n","    gen_skf = skf.split(train[\"student_id\"] , y = train[\"bins\"])\n","    \n","    for index , (train_idx , val_idx) in tqdm.tqdm(enumerate(gen_skf) , total = 5):\n","\n","        train[\"fold\"][val_idx] = index\n","\n","    for fold in tqdm.tqdm(range(n_bags) , total = n_bags):\n","\n","        sample_train = train[train[\"fold\"] != fold]\n","        sample_val = train[train[\"fold\"] == fold]"]},{"cell_type":"markdown","id":"6e4a5da9","metadata":{"papermill":{"duration":0.013039,"end_time":"2023-07-17T05:59:53.718729","exception":false,"start_time":"2023-07-17T05:59:53.70569","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will do the first thing \n","```\n","def bootstrap():\n","\n","    sample_train = train.sample(n = train.shape[0] , replace = True)\n","    \n","    sample_val = train[~train[\"student_id\"].isin(sample_train[\"student_id\"])]\n","    \n","    sample_train.to_csv(\"/kaggle/working/PseudoDir/Sample_train\")\n","    sample_val.to_csv(\"/kaggle/working/PseudoDir/Sample_val\")\n","```\n","in a for loop so that we can have different variations of the dataset "]},{"cell_type":"code","execution_count":13,"id":"6593c225","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.747882Z","iopub.status.busy":"2023-07-17T05:59:53.747476Z","iopub.status.idle":"2023-07-17T05:59:53.756201Z","shell.execute_reply":"2023-07-17T05:59:53.755017Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.02604,"end_time":"2023-07-17T05:59:53.75872","exception":false,"start_time":"2023-07-17T05:59:53.73268","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap():\n","    \n","    for i in range(5):\n","\n","        sample_train = train.sample(n = train.shape[0] , replace = True)\n","\n","        sample_val = train[~train[\"student_id\"].isin(sample_train[\"student_id\"])]\n","\n","        sample_train.to_csv(\"/kaggle/working/PseudoDir/Sample_train\")\n","        sample_val.to_csv(\"/kaggle/working/PseudoDir/Sample_val\")\n","    \n","    train[\"bins\"] = pd.cut(train[\"target\"] , 5 , labels = [bins for bins in range(5)])\n","    \n","    skf = StrattifiedKFold(n_splits = 5 , shuffle = True)\n","    gen_skf = skf.split(train[\"student_id\"] , y = train[\"bins\"])\n","    \n","    for index , (train_idx , val_idx) in tqdm.tqdm(enumerate(gen_skf) , total = 5):\n","\n","        train[\"fold\"][val_idx] = index\n","\n","    for fold in tqdm.tqdm(range(n_bags) , total = n_bags):\n","\n","        sample_train = train[train[\"fold\"] != fold]\n","        sample_val = train[train[\"fold\"] == fold]"]},{"cell_type":"markdown","id":"866d7190","metadata":{"papermill":{"duration":0.013808,"end_time":"2023-07-17T05:59:53.786522","exception":false,"start_time":"2023-07-17T05:59:53.772714","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now lets rename this function a little bit "]},{"cell_type":"code","execution_count":14,"id":"b5ed4f08","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.818375Z","iopub.status.busy":"2023-07-17T05:59:53.817936Z","iopub.status.idle":"2023-07-17T05:59:53.827696Z","shell.execute_reply":"2023-07-17T05:59:53.82642Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.029376,"end_time":"2023-07-17T05:59:53.830202","exception":false,"start_time":"2023-07-17T05:59:53.800826","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap(n_bags):\n","\n","    for bag_number in tqdm.tqdm(range(n_bags) , total = n_bags):\n","\n","        bag = train.sample(n = train.shape[0] , replace = True)\n","\n","        bag_val = train[~train[\"student_id\"].isin(bag[\"student_id\"])]\n","\n","        bag.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Bags/Train/Bag_\" + str(bag_number) + \".csv\")\n","        bag_val.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Bags/Validation/Bag_\" + str(bag_number) + \".csv\")\n","\n","    train[\"bins\"] = pd.cut(train[\"target\"] , n_bags , labels = [i for i in range(n_bags)])\n","    train[\"fold\"] = 0\n","\n","    skf = StratifiedKFold(n_splits = 5 , shuffle = True)\n","    gen_skf = skf.split(train[\"student_id\"] , y = train[\"bins\"])\n","\n","    for index , (train_idx , val_idx) in tqdm.tqdm(enumerate(gen_skf) , total = 5):\n","\n","        train[\"fold\"][val_idx] = index\n","\n","    for fold in tqdm.tqdm(range(n_bags) , total = n_bags):\n","\n","        sample_train = train[train[\"fold\"] != fold]\n","        sample_val = train[train[\"fold\"] == fold]\n","\n","        sample_train.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Folds/Train/Train_\" + str(fold) + \".csv\")\n","        sample_train.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Val/Val_\" + str(fold) + \".csv\")"]},{"cell_type":"markdown","id":"99fff08d","metadata":{"papermill":{"duration":0.013813,"end_time":"2023-07-17T05:59:53.857263","exception":false,"start_time":"2023-07-17T05:59:53.84345","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#800080 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Running this function at this stage will give the following error\n","```\n","In [1]: bootstrap(6)\n","\n","Out [1]: \n","0%|          | 0/6 [00:00<?, ?it/s]\n","---------------------------------------------------------------------------\n","OSError                                   Traceback (most recent call last)\n","Cell In[24], line 1\n","----> 1 bootstrap(6)\n","\n","Cell In[23], line 9, in bootstrap(n_bags)\n","      5     bag = train.sample(n = train.shape[0] , replace = True)\n","      7     bag_val = train[~train[\"student_id\"].isin(bag[\"student_id\"])]\n","----> 9     bag.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Bags/Train/Bag_\" + str(bag_number) + \".csv\")\n","     10     bag_val.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Bags/Validation/Bag_\" + str(bag_number) + \".csv\")\n","     12 train[\"bins\"] = pd.cut(train[\"target\"] , n_bags , labels = [i for i in range(n_bags)])\n","\n","File /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)\n","    209     else:\n","    210         kwargs[new_arg_name] = new_arg_value\n","--> 211 return func(*args, **kwargs)\n","\n","File /opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:3720, in NDFrame.to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\n","   3709 df = self if isinstance(self, ABCDataFrame) else self.to_frame()\n","   3711 formatter = DataFrameFormatter(\n","   3712     frame=df,\n","   3713     header=header,\n","   (...)\n","   3717     decimal=decimal,\n","   3718 )\n","-> 3720 return DataFrameRenderer(formatter).to_csv(\n","   3721     path_or_buf,\n","   3722     lineterminator=lineterminator,\n","   3723     sep=sep,\n","   3724     encoding=encoding,\n","   3725     errors=errors,\n","   3726     compression=compression,\n","   3727     quoting=quoting,\n","   3728     columns=columns,\n","   3729     index_label=index_label,\n","   3730     mode=mode,\n","   3731     chunksize=chunksize,\n","   3732     quotechar=quotechar,\n","   3733     date_format=date_format,\n","   3734     doublequote=doublequote,\n","   3735     escapechar=escapechar,\n","   3736     storage_options=storage_options,\n","   3737 )\n","\n","File /opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)\n","    209     else:\n","    210         kwargs[new_arg_name] = new_arg_value\n","--> 211 return func(*args, **kwargs)\n","\n","File /opt/conda/lib/python3.10/site-packages/pandas/io/formats/format.py:1189, in DataFrameRenderer.to_csv(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\n","   1168     created_buffer = False\n","   1170 csv_formatter = CSVFormatter(\n","   1171     path_or_buf=path_or_buf,\n","   1172     lineterminator=lineterminator,\n","   (...)\n","   1187     formatter=self.fmt,\n","   1188 )\n","-> 1189 csv_formatter.save()\n","   1191 if created_buffer:\n","   1192     assert isinstance(path_or_buf, StringIO)\n","\n","File /opt/conda/lib/python3.10/site-packages/pandas/io/formats/csvs.py:241, in CSVFormatter.save(self)\n","    237 \"\"\"\n","    238 Create the writer & save.\n","    239 \"\"\"\n","    240 # apply compression and byte/text conversion\n","--> 241 with get_handle(\n","    242     self.filepath_or_buffer,\n","    243     self.mode,\n","    244     encoding=self.encoding,\n","    245     errors=self.errors,\n","    246     compression=self.compression,\n","    247     storage_options=self.storage_options,\n","    248 ) as handles:\n","    249 \n","    250     # Note: self.encoding is irrelevant here\n","    251     self.writer = csvlib.writer(\n","    252         handles.handle,\n","    253         lineterminator=self.lineterminator,\n","   (...)\n","    258         quotechar=self.quotechar,\n","    259     )\n","    261     self._save()\n","\n","File /opt/conda/lib/python3.10/site-packages/pandas/io/common.py:734, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n","    732 # Only for write methods\n","    733 if \"r\" not in mode and is_path:\n","--> 734     check_parent_directory(str(handle))\n","    736 if compression:\n","    737     if compression != \"zstd\":\n","    738         # compression libraries do not like an explicit text-mode\n","\n","File /opt/conda/lib/python3.10/site-packages/pandas/io/common.py:597, in check_parent_directory(path)\n","    595 parent = Path(path).parent\n","    596 if not parent.is_dir():\n","--> 597     raise OSError(rf\"Cannot save file into a non-existent directory: '{parent}'\")\n","\n","OSError: Cannot save file into a non-existent directory: '/kaggle/working/Pseudo Dir/K Folds/Bags/Train'\n","```\n","\n","This is beacause that Kaggle do not know which directoreis to save the files. so fist we have to make dirs"]},{"cell_type":"code","execution_count":15,"id":"5c0436ef","metadata":{"execution":{"iopub.execute_input":"2023-07-17T05:59:53.890139Z","iopub.status.busy":"2023-07-17T05:59:53.88968Z","iopub.status.idle":"2023-07-17T05:59:53.900029Z","shell.execute_reply":"2023-07-17T05:59:53.898967Z"},"papermill":{"duration":0.029724,"end_time":"2023-07-17T05:59:53.902545","exception":false,"start_time":"2023-07-17T05:59:53.872821","status":"completed"},"tags":[]},"outputs":[],"source":["def bootstrap(n_bags):\n","    \n","    os.makedirs(\"/kaggle/working/Pseudo Dir/K Folds/Bags/Train\")\n","    os.makedirs(\"/kaggle/working/Pseudo Dir/K Folds/Bags/Validation\")\n","\n","    for bag_number in tqdm.tqdm(range(n_bags) , total = n_bags):\n","\n","        bag = train.sample(n = train.shape[0] , replace = True)\n","\n","        bag_val = train[~train[\"student_id\"].isin(bag[\"student_id\"])]\n","\n","        bag.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Bags/Train/Bag_\" + str(bag_number) + \".csv\")\n","        bag_val.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Bags/Validation/Bag_\" + str(bag_number) + \".csv\")\n","\n","    train[\"bins\"] = pd.cut(train[\"content\"] , n_bags , labels = [i for i in range(n_bags)])\n","    train[\"fold\"] = 0\n","\n","    skf = StratifiedKFold(n_splits = 5 , shuffle = True)\n","    gen_skf = skf.split(train[\"student_id\"] , y = train[\"bins\"])\n","\n","    for index , (train_idx , val_idx) in tqdm.tqdm(enumerate(gen_skf) , total = 5):\n","\n","        train[\"fold\"][val_idx] = index\n","        \n","    os.makedirs(\"/kaggle/working/Pseudo Dir/K Folds/Folds/Train\")\n","    os.makedirs(\"/kaggle/working/Pseudo Dir/K Folds/Val\")\n","\n","    for fold in tqdm.tqdm(range(n_bags) , total = n_bags):\n","\n","        sample_train = train[train[\"fold\"] != fold]\n","        sample_val = train[train[\"fold\"] == fold]\n","\n","        sample_train.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Folds/Train/Train_\" + str(fold) + \".csv\")\n","        sample_train.to_csv(\"/kaggle/working/Pseudo Dir/K Folds/Val/Val_\" + str(fold) + \".csv\")"]},{"cell_type":"code","execution_count":16,"id":"bc386b2e","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-17T05:59:53.931286Z","iopub.status.busy":"2023-07-17T05:59:53.93091Z","iopub.status.idle":"2023-07-17T06:00:12.332033Z","shell.execute_reply":"2023-07-17T06:00:12.330616Z"},"papermill":{"duration":18.418527,"end_time":"2023-07-17T06:00:12.334353","exception":false,"start_time":"2023-07-17T05:59:53.915826","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:08<00:00,  1.38s/it]\n","  0%|          | 0/5 [00:00<?, ?it/s]/tmp/ipykernel_21/2791606803.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train[\"fold\"][val_idx] = index\n","/tmp/ipykernel_21/2791606803.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train[\"fold\"][val_idx] = index\n","/tmp/ipykernel_21/2791606803.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train[\"fold\"][val_idx] = index\n","/tmp/ipykernel_21/2791606803.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train[\"fold\"][val_idx] = index\n","/tmp/ipykernel_21/2791606803.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train[\"fold\"][val_idx] = index\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 415.21it/s]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:10<00:00,  1.68s/it]\n"]}],"source":["bootstrap(n_bags = 6)"]},{"cell_type":"markdown","id":"498a0c8c","metadata":{"papermill":{"duration":0.014677,"end_time":"2023-07-17T06:00:12.363804","exception":false,"start_time":"2023-07-17T06:00:12.349127","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FFC0CB; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FFC0CB\">5 | Tokenization + Embeddings üî±</p>\n","\n","<div style=\"border-radius:10px; border:#FFC0CB solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = \"https://kratikal.com/blog/wp-content/uploads/2022/01/tokens-image.png\" width = 400>\n","\n","## $RoBERTa$  \n","\n","$RoBERTa$ $Robustly$ $Optimized$ $BERT$ $Pretraining$ $Approach$ is a $Natural$ $Language$ $Processing$ $Model$ that was introduced in the paper **[RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/pdf/1907.11692.pdf)** by `Yinhan Liu` et al. in $2019$. It is based on the $BERT$ $Model$, but it makes a number of modifications to the pretraining procedure that improve its performance.\n","\n","One of the key differences between $RoBERTa$ and $BERT$ is that $RoBERTa$ uses a `larger batch size` and a `higher learning rate` during pretraining. This allows $RoBERTa$ to learn `more effectively` from the training data. Additionally, $RoBERTa$ removes the `next sentence prediction task` from the pretraining procedure. This task was originally used in BERT to help the model learn the relationship between sentences, but $RoBERTa$ found that it was `not necessary` for `good performance`.\n","\n","$RoBERTa$ has been shown to outperform $BERT$ on a number of $Natural$ $Language$ $Processing$ $Tasks$, including \n","* $Question$ $Answering$\n","* $Natural$ $Language$ $Inference$\n","* $Text$ $Summarization$\n","\n","<img src = \"https://www.researchgate.net/publication/352642553/figure/fig2/AS:1037416861282304@1624350862022/The-RoBERTa-model-architecture.ppm\" width = 400>\n","    \n","I dont know why but, I am kind of facing a glitch in Kaggle GPU, Cuda goes out of memory, Thus I made the embedings on Colab and imported the dataset. the files can be found on \n","```\n","/kaggle/input/common-lit-sample-fold-embeds\n","```"]},{"cell_type":"markdown","id":"037a4e6a","metadata":{"papermill":{"duration":0.014189,"end_time":"2023-07-17T06:00:12.393076","exception":false,"start_time":"2023-07-17T06:00:12.378887","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#00FFFF; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #00FFFF\">6 | DataLoader üìÇ</p>\n","\n","<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","<img src = \"https://jacobwgillespie.com/from-rest-to-graphql-3.jpg\" width = 400>\n","Now we will make a $2$ Data Loader class that will load datasets in particular batch sizes for the training of the model\n"]},{"cell_type":"code","execution_count":17,"id":"e79ddbe7","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:12.424403Z","iopub.status.busy":"2023-07-17T06:00:12.423675Z","iopub.status.idle":"2023-07-17T06:00:16.03751Z","shell.execute_reply":"2023-07-17T06:00:16.036285Z"},"papermill":{"duration":3.63367,"end_time":"2023-07-17T06:00:16.041326","exception":false,"start_time":"2023-07-17T06:00:12.407656","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import torch\n","from torch.utils.data import Dataset"]},{"cell_type":"markdown","id":"a9591837","metadata":{"papermill":{"duration":0.016064,"end_time":"2023-07-17T06:00:16.072726","exception":false,"start_time":"2023-07-17T06:00:16.056662","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Lets first make a simple class"]},{"cell_type":"code","execution_count":18,"id":"4b91d7bb","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:16.10782Z","iopub.status.busy":"2023-07-17T06:00:16.107128Z","iopub.status.idle":"2023-07-17T06:00:16.113088Z","shell.execute_reply":"2023-07-17T06:00:16.111982Z"},"papermill":{"duration":0.025896,"end_time":"2023-07-17T06:00:16.115422","exception":false,"start_time":"2023-07-17T06:00:16.089526","status":"completed"},"tags":[]},"outputs":[],"source":["class load_train(Dataset):pass"]},{"cell_type":"markdown","id":"c839c9cd","metadata":{"papermill":{"duration":0.014757,"end_time":"2023-07-17T06:00:16.146061","exception":false,"start_time":"2023-07-17T06:00:16.131304","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now lets make the `constructor`, our constructor will take $2$ `Directories` to load `specific folds` of `training`/`val` data"]},{"cell_type":"code","execution_count":19,"id":"04131ee2","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:16.179805Z","iopub.status.busy":"2023-07-17T06:00:16.179218Z","iopub.status.idle":"2023-07-17T06:00:16.186205Z","shell.execute_reply":"2023-07-17T06:00:16.184349Z"},"papermill":{"duration":0.028015,"end_time":"2023-07-17T06:00:16.189078","exception":false,"start_time":"2023-07-17T06:00:16.161063","status":"completed"},"tags":[]},"outputs":[],"source":["class load_train(Dataset):\n","    \n","    def __init__(self , x_train_dir , y_train_dir):\n","        \n","        self.x_train_dir = x_train_dir\n","        self.y_train_dir = y_train_dir"]},{"cell_type":"markdown","id":"efbf55ee","metadata":{"papermill":{"duration":0.015342,"end_time":"2023-07-17T06:00:16.219464","exception":false,"start_time":"2023-07-17T06:00:16.204122","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will load Emebeddings from these Dirs"]},{"cell_type":"code","execution_count":20,"id":"c639637e","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:16.252784Z","iopub.status.busy":"2023-07-17T06:00:16.252334Z","iopub.status.idle":"2023-07-17T06:00:16.258306Z","shell.execute_reply":"2023-07-17T06:00:16.257289Z"},"papermill":{"duration":0.025462,"end_time":"2023-07-17T06:00:16.260502","exception":false,"start_time":"2023-07-17T06:00:16.23504","status":"completed"},"tags":[]},"outputs":[],"source":["class load_train(Dataset):\n","    \n","    def __init__(self , x_train_dir , y_train , \n","                 x_val_dir , y_val_dir):\n","        \n","        self.x_train_dir = x_train_dir\n","        self.y_train_dir = y_train_dir\n","        \n","        self.x_train = np.load(self.x_train_dir)\n","        self.y_train = np.load(self.y_train_dir)"]},{"cell_type":"markdown","id":"e2895cbf","metadata":{"papermill":{"duration":0.014384,"end_time":"2023-07-17T06:00:16.29007","exception":false,"start_time":"2023-07-17T06:00:16.275686","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will just add some getters to the class"]},{"cell_type":"code","execution_count":21,"id":"e6ec7dbd","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:16.322845Z","iopub.status.busy":"2023-07-17T06:00:16.322432Z","iopub.status.idle":"2023-07-17T06:00:16.329163Z","shell.execute_reply":"2023-07-17T06:00:16.327981Z"},"papermill":{"duration":0.025446,"end_time":"2023-07-17T06:00:16.331433","exception":false,"start_time":"2023-07-17T06:00:16.305987","status":"completed"},"tags":[]},"outputs":[],"source":["class load_train(Dataset):\n","    \n","    def __init__(self , x_train_dir , y_train):\n","        \n","        self.x_train_dir = x_train_dir\n","        self.y_train_dir = y_train_dir\n","        \n","        self.x_train = np.load(self.x_train_dir)\n","        self.y_train = np.load(self.y_train_dir)\n","        \n","    def __len__(self):return self.x_train.shape[0]\n","    \n","    def __getitem__(self , index):\n","        \n","        embeds = torch.tensor(self.x_train[index] , dtype = torch.float32)\n","        targets = torch.tensor(self.y_train[index] , dtype = torch.float32)\n","        \n","        return embeds , targets"]},{"cell_type":"markdown","id":"3b68589b","metadata":{"papermill":{"duration":0.014198,"end_time":"2023-07-17T06:00:16.360511","exception":false,"start_time":"2023-07-17T06:00:16.346313","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","The same way now we will load the `Val Data`"]},{"cell_type":"code","execution_count":22,"id":"78461d1c","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:16.392331Z","iopub.status.busy":"2023-07-17T06:00:16.391899Z","iopub.status.idle":"2023-07-17T06:00:16.399821Z","shell.execute_reply":"2023-07-17T06:00:16.398558Z"},"papermill":{"duration":0.026805,"end_time":"2023-07-17T06:00:16.401988","exception":false,"start_time":"2023-07-17T06:00:16.375183","status":"completed"},"tags":[]},"outputs":[],"source":["class load_val(Dataset):\n","    \n","    def __init__(self , x_val_dir , y_val_dir):\n","        \n","        self.x_val_dir = x_train_dir\n","        self.y_val_dir = y_train_dir\n","        \n","        self.x_val = np.load(self.x_val_dir)\n","        self.y_val = np.load(self.y_val_dir)\n","        \n","    def __len__(self):return self.x_val.shape[0]\n","    \n","    def __getitem__(self , index):\n","        \n","        embeds = torch.tensor(self.x_val[index] , dtype = torch.float32)\n","        targets = torch.tensor(self.y_val[index] , dtype = torch.float32)\n","        \n","        return embeds , targets"]},{"cell_type":"markdown","id":"eb4d217a","metadata":{"papermill":{"duration":0.014329,"end_time":"2023-07-17T06:00:16.431946","exception":false,"start_time":"2023-07-17T06:00:16.417617","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#8B8000; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #8B8000\">7 | Model Setup üî®</p>\n","\n","<div style=\"border-radius:10px; border:#FFFF00 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = \"https://miro.medium.com/v2/resize:fit:500/1*qHbAsMNmdWQJkzm2SUA-8w.jpeg\" width = 400>\n","    \n","This time we will be training multiple models\n","\n","* $AlBERT$ $XX$ $Large$ $V2$\n"," "]},{"cell_type":"code","execution_count":23,"id":"7ee46fd9","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:16.463386Z","iopub.status.busy":"2023-07-17T06:00:16.462967Z","iopub.status.idle":"2023-07-17T06:00:28.28829Z","shell.execute_reply":"2023-07-17T06:00:28.286628Z"},"papermill":{"duration":11.844472,"end_time":"2023-07-17T06:00:28.291335","exception":false,"start_time":"2023-07-17T06:00:16.446863","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["from transformers import AutoConfig , AutoModelForSequenceClassification , TrainingArguments , Trainer\n","import torch "]},{"cell_type":"markdown","id":"44cd3890","metadata":{"papermill":{"duration":0.015154,"end_time":"2023-07-17T06:00:28.322897","exception":false,"start_time":"2023-07-17T06:00:28.307743","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#FFFF00 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\"> \n","    \n","## $7.1$ $|$ $AlBERT$ $XX$ $Large$ $V2$\n","    \n","$Albert$ $XX$ $Large$ $v2$ is a $Large$ $Language$ $Model$ $(LLM)$ that has been `pretrained` on a `massive corpus` of `English Data`. It was introduced in the paper **[ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/pdf/1909.11942.pdf)** by `Lan` et al. $2019$.\n","\n","$Albert$ $XX$ $Large$ $v2$ is a $Masked$ $Language$ $Modeling$ $(MLM)$ model, which means that it was `trained` to `predict masked words` in a sentence. This type of `training` helps the model to `learn the relationships` between `words` in a sentence, which makes it better at understanding and generating text. $Albert$ $XX$ $Large$ $v2$ has a $137B$ `parameter size`, which makes it one of the $largest$ $LLMs$ available. It is also uncased, which means that it does not make a difference between the words \"english\" and \"English\". $Albert$ $XX$ $Large$ $v2$ can be used for a variety of $Natural$ $Language$ $Processing$ $(NLP)$ tasks, including:\n","* $Question$ $Answering$\n","* $Machine$ $Translation$\n","* $Text$ $Summarization$\n","* $Text$ $Classification$\n","* $Natural$ $Language$ $Inference$\n","    \n","Now lets load the `Training Arguments`\n","    \n","`TrainingArguments` will create an `instance of the TrainingArguments` class from the `transformers library`.\n","    \n","* `output_dir` - The `directory` where the `model predictions` and `checkpoints will be written`.\n","* `num_train_epochs` - The `number` of `training epochs`.\n","* `per_device_train_batch_size` - The `batch size` for `training` on each `GPU`.\n","* `per_device_eval_batch_size` - The `batch size` for `evaluation` on each `GPU`.\n","* `weight_decay` - The `weight decay coefficient`.\n","* `learning_rate` - The `learning rate`.\n","* `save_strategy`: The `strategy` for `saving checkpoints`."]},{"cell_type":"code","execution_count":24,"id":"df05f8f3","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:28.358925Z","iopub.status.busy":"2023-07-17T06:00:28.358053Z","iopub.status.idle":"2023-07-17T06:00:29.929971Z","shell.execute_reply":"2023-07-17T06:00:29.928977Z"},"papermill":{"duration":1.592577,"end_time":"2023-07-17T06:00:29.932261","exception":false,"start_time":"2023-07-17T06:00:28.339684","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c39e8c4829c14b0dae67ae0f3f69fd2c","version_major":2,"version_minor":0},"text/plain":["Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34067630524747a2bb43f325b7867873","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.bias']\n","- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["config = AutoConfig.from_pretrained(\"albert-base-v2\", num_labels = 1,\n","                                    hidden_dropout_prob = 0.07,\n","                                    attention_probs_dropout_prob = 0.1)\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels = 1)\n","optimizer = torch.optim.AdamW(model.parameters() , lr  = 9e-6)\n","\n","training_args = TrainingArguments(\n","    output_dir = \"/kaggle/working/model/AlBERT XX Large V2\" , \n","    num_train_epochs = 5 , \n","    per_device_train_batch_size = 3 , \n","    per_device_eval_batch_size = 1 , \n","    logging_dir = \"/tmp/logs\" , \n","    logging_steps = 60 , \n","    weight_decay = 0.01 , \n","    learning_rate = 9e-6 , \n","    save_strategy = \"no\"\n",")"]},{"cell_type":"markdown","id":"0d873dca","metadata":{"papermill":{"duration":0.016862,"end_time":"2023-07-17T06:00:29.966321","exception":false,"start_time":"2023-07-17T06:00:29.949459","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#00FFFF; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #00FFFF\">8 | Training Loop ‚û∞</p>\n","\n","<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = \"https://media.makeameme.org/created/let-the-training.jpg\" width = 400>\n","\n","Now lets construct a function for training \n","    \n","**I have not tested the function yet, it might not work properly, will surely update in the upcoming version**"]},{"cell_type":"code","execution_count":25,"id":"065c75c5","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:30.001058Z","iopub.status.busy":"2023-07-17T06:00:30.00061Z","iopub.status.idle":"2023-07-17T06:00:30.007497Z","shell.execute_reply":"2023-07-17T06:00:30.005802Z"},"papermill":{"duration":0.027871,"end_time":"2023-07-17T06:00:30.010608","exception":false,"start_time":"2023-07-17T06:00:29.982737","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model():pass"]},{"cell_type":"markdown","id":"3c5bb627","metadata":{"papermill":{"duration":0.015559,"end_time":"2023-07-17T06:00:30.04346","exception":false,"start_time":"2023-07-17T06:00:30.027901","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now lets load the training Data Loader and their corresponding Dirs\n","    \n","`torch.utils.data.DataLoader(train, shuffle=True, batch_size=None)` will create a `PyTorch DataLoader object` for the `train dataset`. The DataLoader object will be used to `load the data` in `batches for training a model`."]},{"cell_type":"code","execution_count":26,"id":"15f0a588","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:30.078906Z","iopub.status.busy":"2023-07-17T06:00:30.078479Z","iopub.status.idle":"2023-07-17T06:00:30.08521Z","shell.execute_reply":"2023-07-17T06:00:30.08408Z"},"papermill":{"duration":0.027335,"end_time":"2023-07-17T06:00:30.087973","exception":false,"start_time":"2023-07-17T06:00:30.060638","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(base_dir , batch , n_folds = 6):\n","    \n","    for fold in range(n_folds):\n","        \n","        x_train_dir = base_dir + str(fold)\n","        y_train_dir = base_dir + str(fold)\n","        \n","        train = load_train(x_train_dir , y_train_dir)\n","        \n","        train_dataloader = torch.utils.Data.DataLoader(train , shuffle = True , batch_size = batch)"]},{"cell_type":"markdown","id":"5e3166c2","metadata":{"papermill":{"duration":0.016303,"end_time":"2023-07-17T06:00:30.121628","exception":false,"start_time":"2023-07-17T06:00:30.105325","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will load the trainer "]},{"cell_type":"code","execution_count":27,"id":"bb356636","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:30.156563Z","iopub.status.busy":"2023-07-17T06:00:30.156184Z","iopub.status.idle":"2023-07-17T06:00:30.163201Z","shell.execute_reply":"2023-07-17T06:00:30.162307Z"},"papermill":{"duration":0.027239,"end_time":"2023-07-17T06:00:30.165313","exception":false,"start_time":"2023-07-17T06:00:30.138074","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(hyperparams , model , base_dir , training_args , batch , n_folds = 6):\n","    \n","    for fold in range(n_folds):\n","        \n","        x_train_dir = base_dir + str(fold)\n","        y_train_dir = base_dir + str(fold)\n","        \n","        train = load_train(x_train_dir , y_train_dir)\n","        \n","        train_dataloader = torch.utils.Data.DataLoader(train , shuffle = True , batch_size = batch)\n","        \n","        trainer = Trainer(\n","            model = model,                         \n","            args = training_args,                  \n","            train_dataset = train_dataset,         \n","            optimizers = optimizer\n","        )"]},{"cell_type":"markdown","id":"05b43409","metadata":{"papermill":{"duration":0.0146,"end_time":"2023-07-17T06:00:30.194996","exception":false,"start_time":"2023-07-17T06:00:30.180396","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will put the model on training "]},{"cell_type":"code","execution_count":28,"id":"4a8a67b4","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:30.229094Z","iopub.status.busy":"2023-07-17T06:00:30.227978Z","iopub.status.idle":"2023-07-17T06:00:30.234788Z","shell.execute_reply":"2023-07-17T06:00:30.233841Z"},"papermill":{"duration":0.026007,"end_time":"2023-07-17T06:00:30.237186","exception":false,"start_time":"2023-07-17T06:00:30.211179","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(hyperparams , model , base_dir , training_args , batch , n_folds = 6 , ):\n","    \n","    for fold in range(n_folds):\n","        \n","        x_train_dir = base_dir + str(fold)\n","        y_train_dir = base_dir + str(fold)\n","        \n","        train = load_train(x_train_dir , y_train_dir)\n","        \n","        train_dataloader = torch.utils.Data.DataLoader(train , shuffle = True , batch_size = batch)\n","        \n","        trainer = Trainer(\n","            model = model,                         \n","            args = training_args,                  \n","            train_dataset = train_dataset,         \n","            optimizers = optimizer\n","        )\n","        \n","        trainer.train()"]},{"cell_type":"markdown","id":"9ced0a5f","metadata":{"papermill":{"duration":0.015969,"end_time":"2023-07-17T06:00:30.268207","exception":false,"start_time":"2023-07-17T06:00:30.252238","status":"completed"},"tags":[]},"source":["<div style=\"border-radius:10px; border:#00FFFF solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","Now we will save this model at some dir"]},{"cell_type":"code","execution_count":29,"id":"f2d2bd3d","metadata":{"execution":{"iopub.execute_input":"2023-07-17T06:00:30.301635Z","iopub.status.busy":"2023-07-17T06:00:30.300747Z","iopub.status.idle":"2023-07-17T06:00:30.308869Z","shell.execute_reply":"2023-07-17T06:00:30.30737Z"},"papermill":{"duration":0.028232,"end_time":"2023-07-17T06:00:30.311539","exception":false,"start_time":"2023-07-17T06:00:30.283307","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(hyperparams , model , base_dir , out_dir , training_args , batch , n_folds = 6 , ):\n","    \n","    for fold in range(n_folds):\n","        \n","        x_train_dir = base_dir + str(fold)\n","        y_train_dir = base_dir + str(fold)\n","        \n","        train = load_train(x_train_dir , y_train_dir)\n","        \n","        train_dataloader = torch.utils.Data.DataLoader(train , shuffle = True , batch_size = batch)\n","        \n","        trainer = Trainer(\n","            model = model,                         \n","            args = training_args,                  \n","            train_dataset = train_dataset,         \n","            optimizers = optimizer\n","        )\n","        \n","        trainer.train()\n","\n","        model.save_pretrained(out_dir + str(fold))"]},{"cell_type":"markdown","id":"059d616b","metadata":{"papermill":{"duration":0.014682,"end_time":"2023-07-17T06:00:30.342182","exception":false,"start_time":"2023-07-17T06:00:30.3275","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FFC0CB; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FFC0CB\">9 | TO DO LIST üìù</p>\n","\n","<div style=\"border-radius:10px; border:#FFC0CB solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","    \n","<img src = \"https://i.imgflip.com/43iacv.jpg\" width = 400>\n","    \n","* $TO$ $DO$ $1$ $:$ $TRAIN$ $THE$ $MODEL$\n","* $TO$ $DO$ $2$ $:$ $ADD$ $MORE$ $MODELS$\n","* $TO$ $DO$ $3$ $:$ $ADD$ $SCRAPED$ $DATA$\n","* $TO$ $DO$ $4$ $:$ $ADD$ $EVALUATION$ $CALLBACKS$\n","* $TO$ $DO$ $5$ $:$ $ADD$ $WANDB$ $SUPPORT$\n","* $TO$ $DO$ $6$ $:$ $ADD$ $MORE$ $FUNCTIONALITIES$\n","* $TO$ $DO$ $7$ $:$ $DANCE$"]},{"cell_type":"markdown","id":"be07e588","metadata":{"papermill":{"duration":0.015553,"end_time":"2023-07-17T06:00:30.373076","exception":false,"start_time":"2023-07-17T06:00:30.357523","status":"completed"},"tags":[]},"source":["# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#FFA500; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #FFA500\">10 | Ending üèÅ</p>\n","\n","<div style=\"border-radius:10px; border:#FFA500 solid; padding: 15px; background-color: #F3f9ed; font-size:100%; text-align:left\">\n","\n","**THIS IS NOT THE FULL IMPLEMENTATION, IT STILL LACKS MANY FUNCTIONALITIES AND IS VULENRABLE TO MANY EDGE CASES, WE WILL IMPROVE THIS IN THE UPCOMING VERSIONS**\n","\n","**PLEASE COMMENT DOWN IF I DID ANY MISTAKES, OR IF CAN MAKE THIS MORE CONNECTED TO THE GROUND, OR SUGGESTIONS. YOUR ASSISTS ARE HIGHLY APPRECIABLE**\n","\n","**THATS IT FOR TODAY GUYS**\n","\n","**HOPE YOU UNDERSTOOD AND LIKED MY WORK**\n","\n","**DONT FORGET TO MAKE AN UPVOTE $:)$**\n","    \n","<img src = \"https://i.imgflip.com/19aadg.jpg\">\n","   \n","**PEACE OUT**"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":53.672517,"end_time":"2023-07-17T06:00:33.528099","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-17T05:59:39.855582","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0175256838a248b0a8615a8034d62ad9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c013a44243741549eeeccdef6cfba3f","placeholder":"‚Äã","style":"IPY_MODEL_047efb68e66f4784b7738f275a64ba06","value":" 684/684 [00:00&lt;00:00, 39.0kB/s]"}},"047efb68e66f4784b7738f275a64ba06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08f482e4abee4714b34edc84e228a7ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bcb42ce58c34c1498a56807807ccd65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"224c9ca0891a4a8bae468916a2346eb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34067630524747a2bb43f325b7867873":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95f5b4891529492fa79cfa0d0cdc74a9","IPY_MODEL_425e08025b5d430292be390aa1bf6866","IPY_MODEL_79b8768c6a3047efb221d86f54be45ad"],"layout":"IPY_MODEL_865a1b5a91c04605b3699e792ba0839a"}},"3c013a44243741549eeeccdef6cfba3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"425e08025b5d430292be390aa1bf6866":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c553e08ec6443e38cf7ae35fd277e1a","max":47372894.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_224c9ca0891a4a8bae468916a2346eb7","value":47372894.0}},"4e15173fe3ff452a96f5cd4fe2da3b09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5601cd4f7b34578a5137e43597f96e7","max":684.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_f2a3e9f5451a4780a45d9bb21f2f4509","value":684.0}},"6f5c08c66d3e49508e1137c8a1829d2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79b8768c6a3047efb221d86f54be45ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fff91870320846679f68d05704549a39","placeholder":"‚Äã","style":"IPY_MODEL_08f482e4abee4714b34edc84e228a7ca","value":" 47.4M/47.4M [00:00&lt;00:00, 88.5MB/s]"}},"7c553e08ec6443e38cf7ae35fd277e1a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"865a1b5a91c04605b3699e792ba0839a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95f5b4891529492fa79cfa0d0cdc74a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca00b1078eae43649d92af772c773224","placeholder":"‚Äã","style":"IPY_MODEL_6f5c08c66d3e49508e1137c8a1829d2e","value":"Downloading model.safetensors: 100%"}},"b102bcbaf1804dcdabe76f8ab4d60744":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bcb42ce58c34c1498a56807807ccd65","placeholder":"‚Äã","style":"IPY_MODEL_b7cda4a69e194a978e1f1da4731ac7cb","value":"Downloading (‚Ä¶)lve/main/config.json: 100%"}},"b7cda4a69e194a978e1f1da4731ac7cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c39e8c4829c14b0dae67ae0f3f69fd2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b102bcbaf1804dcdabe76f8ab4d60744","IPY_MODEL_4e15173fe3ff452a96f5cd4fe2da3b09","IPY_MODEL_0175256838a248b0a8615a8034d62ad9"],"layout":"IPY_MODEL_dddb1e7fb6684714a33eea29459e4eaa"}},"c5601cd4f7b34578a5137e43597f96e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca00b1078eae43649d92af772c773224":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dddb1e7fb6684714a33eea29459e4eaa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2a3e9f5451a4780a45d9bb21f2f4509":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fff91870320846679f68d05704549a39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}